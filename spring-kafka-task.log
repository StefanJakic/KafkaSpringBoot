2023-03-17T00:02:14.381+01:00  INFO 12504 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T00:02:14.626+01:00  INFO 12504 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T00:02:39.462+01:00  INFO 12504 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient   : [Producer clientId=producer-1] Node -1 disconnected.
2023-03-17T00:04:34.424+01:00  INFO 16904 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 16904 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T00:04:34.427+01:00  INFO 16904 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T00:04:34.895+01:00  INFO 16904 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T00:04:34.916+01:00  INFO 16904 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T00:04:35.960+01:00  INFO 16904 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T00:04:36.107+01:00  INFO 16904 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:04:36.108+01:00  INFO 16904 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:04:36.108+01:00  INFO 16904 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679007876105
2023-03-17T00:04:36.354+01:00  INFO 16904 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T00:04:36.358+01:00  INFO 16904 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T00:04:36.358+01:00  INFO 16904 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T00:04:36.358+01:00  INFO 16904 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T00:04:36.363+01:00  INFO 16904 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T00:04:36.364+01:00  INFO 16904 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T00:04:36.365+01:00  INFO 16904 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T00:04:36.387+01:00  INFO 16904 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T00:04:36.420+01:00  INFO 16904 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:04:36.420+01:00  INFO 16904 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:04:36.420+01:00  INFO 16904 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679007876419
2023-03-17T00:04:36.421+01:00  INFO 16904 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T00:04:36.428+01:00  INFO 16904 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T00:04:36.434+01:00  INFO 16904 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:04:36.435+01:00  INFO 16904 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:04:36.435+01:00  INFO 16904 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679007876434
2023-03-17T00:04:36.436+01:00  INFO 16904 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T00:04:36.450+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:04:36.450+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T00:04:36.450+01:00  INFO 16904 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.425 seconds (process running for 2.767)
2023-03-17T00:04:36.451+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:04:36.452+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:04:36.452+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:04:36.454+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:04:36.454+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:04:36.457+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:04:36.457+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:04:36.475+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-ef3e8a8c-5200-465d-b52b-7daccee661fe
2023-03-17T00:04:36.475+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-80162b53-eadc-4f3c-8a2f-3af440503608
2023-03-17T00:04:36.476+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T00:04:36.476+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T00:04:36.476+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:04:36.476+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:05:13.946+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=11, memberId='consumer-springkafkatask33;-1-80162b53-eadc-4f3c-8a2f-3af440503608', protocol='range'}
2023-03-17T00:05:13.946+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=11, memberId='consumer-springkafkatask33;-2-ef3e8a8c-5200-465d-b52b-7daccee661fe', protocol='range'}
2023-03-17T00:05:13.951+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T00:05:13.955+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Finished assignment for group at generation 11: {consumer-springkafkatask33;-2-ef3e8a8c-5200-465d-b52b-7daccee661fe=Assignment(partitions=[topicTask1-0, topicTask1-1]), consumer-springkafkatask33;-1-80162b53-eadc-4f3c-8a2f-3af440503608=Assignment(partitions=[topicTask2-0])}
2023-03-17T00:05:13.960+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=11, memberId='consumer-springkafkatask33;-2-ef3e8a8c-5200-465d-b52b-7daccee661fe', protocol='range'}
2023-03-17T00:05:13.960+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=11, memberId='consumer-springkafkatask33;-1-80162b53-eadc-4f3c-8a2f-3af440503608', protocol='range'}
2023-03-17T00:05:13.961+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T00:05:13.961+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T00:05:13.969+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T00:05:13.969+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T00:05:13.979+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=39, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:05:13.979+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:05:13.980+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=28, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:05:13.981+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T00:05:13.981+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T00:05:14.010+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 28, CreateTime = 1679007887110, serialized key size = -1, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e3)
2023-03-17T00:05:14.019+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:05:14.019+01:00 ERROR 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:05:14.024+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-03-17T00:05:14.032+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-03-17T00:05:14.047+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:05:14.048+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:05:14.048+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679007914047
2023-03-17T00:05:14.053+01:00  INFO 16904 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:05:14.053+01:00  INFO 16904 --- [kafka-producer-network-thread | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 9 with epoch 0
2023-03-17T00:05:14.057+01:00  INFO 16904 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T00:05:14.064+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 29, CreateTime = 1679007891327, serialized key size = -1, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e4)
2023-03-17T00:05:14.065+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:05:14.065+01:00 ERROR 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:05:14.073+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 39, CreateTime = 1679007914059, serialized key size = 5, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = e3)
2023-03-17T00:05:14.076+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 40, CreateTime = 1679007914065, serialized key size = 5, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = e4)
2023-03-17T00:11:26.896+01:00  INFO 13432 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 13432 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T00:11:26.898+01:00  INFO 13432 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T00:11:27.357+01:00  INFO 13432 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T00:11:27.376+01:00  INFO 13432 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T00:11:28.371+01:00  INFO 13432 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T00:11:28.528+01:00  INFO 13432 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:11:28.530+01:00  INFO 13432 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:11:28.530+01:00  INFO 13432 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679008288527
2023-03-17T00:11:28.783+01:00  INFO 13432 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T00:11:28.787+01:00  INFO 13432 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T00:11:28.787+01:00  INFO 13432 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T00:11:28.787+01:00  INFO 13432 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T00:11:28.793+01:00  INFO 13432 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T00:11:28.793+01:00  INFO 13432 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T00:11:28.794+01:00  INFO 13432 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T00:11:28.820+01:00  INFO 13432 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T00:11:28.870+01:00  INFO 13432 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:11:28.871+01:00  INFO 13432 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:11:28.871+01:00  INFO 13432 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679008288870
2023-03-17T00:11:28.873+01:00  INFO 13432 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T00:11:28.886+01:00  INFO 13432 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T00:11:28.892+01:00  INFO 13432 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:11:28.893+01:00  INFO 13432 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:11:28.893+01:00  INFO 13432 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679008288892
2023-03-17T00:11:28.894+01:00  INFO 13432 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T00:11:28.905+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T00:11:28.905+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:11:28.906+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:11:28.909+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:11:28.909+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:11:28.910+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:11:28.910+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:11:28.910+01:00  INFO 13432 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.414 seconds (process running for 2.773)
2023-03-17T00:11:28.913+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:11:28.913+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:11:28.931+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-69707598-e678-4ce9-9256-00329c819ee7
2023-03-17T00:11:28.931+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-b84629d7-f4d4-407f-8f26-75d22818c21e
2023-03-17T00:11:28.932+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T00:11:28.932+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T00:11:28.932+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:11:28.932+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:11:35.874+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=12, memberId='consumer-springkafkatask33;-1-69707598-e678-4ce9-9256-00329c819ee7', protocol='range'}
2023-03-17T00:11:35.874+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=12, memberId='consumer-springkafkatask33;-2-b84629d7-f4d4-407f-8f26-75d22818c21e', protocol='range'}
2023-03-17T00:11:35.879+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T00:11:35.882+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Finished assignment for group at generation 12: {consumer-springkafkatask33;-1-69707598-e678-4ce9-9256-00329c819ee7=Assignment(partitions=[topicTask1-0, topicTask1-1]), consumer-springkafkatask33;-2-b84629d7-f4d4-407f-8f26-75d22818c21e=Assignment(partitions=[topicTask2-0])}
2023-03-17T00:11:35.887+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=12, memberId='consumer-springkafkatask33;-1-69707598-e678-4ce9-9256-00329c819ee7', protocol='range'}
2023-03-17T00:11:35.887+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=12, memberId='consumer-springkafkatask33;-2-b84629d7-f4d4-407f-8f26-75d22818c21e', protocol='range'}
2023-03-17T00:11:35.888+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T00:11:35.888+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T00:11:35.891+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T00:11:35.891+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T00:11:35.899+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=41, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:11:35.899+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:11:35.900+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=30, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:11:35.901+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T00:11:35.901+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T00:11:38.994+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 30, CreateTime = 1679008297964, serialized key size = -1, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e6)
2023-03-17T00:11:39.003+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:11:39.003+01:00 ERROR 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:11:39.008+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-03-17T00:11:39.017+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-03-17T00:11:39.028+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:11:39.028+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:11:39.028+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679008299028
2023-03-17T00:11:39.036+01:00  INFO 13432 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T00:11:39.036+01:00  INFO 13432 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:11:39.037+01:00  INFO 13432 --- [kafka-producer-network-thread | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 10 with epoch 0
2023-03-17T00:11:39.059+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 41, CreateTime = 1679008299037, serialized key size = 5, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = e6)
2023-03-17T00:11:46.797+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 31, CreateTime = 1679008305787, serialized key size = -1, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 67)
2023-03-17T00:11:46.825+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:11:46.825+01:00 ERROR 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:11:46.829+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 42, CreateTime = 1679008306825, serialized key size = 5, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = 67)
2023-03-17T00:15:43.114+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 32, CreateTime = 1679008542099, serialized key size = -1, serialized value size = 73, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "-50", "callId" : "nesto777777777"})
2023-03-17T00:15:43.116+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:15:43.116+01:00 ERROR 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:15:43.120+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 43, CreateTime = 1679008543116, serialized key size = 5, serialized value size = 73, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = {"callStatus": "START", "timestamp" : "-50", "callId" : "nesto777777777"})
2023-03-17T00:17:06.427+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 33, CreateTime = 1679008625416, serialized key size = -1, serialized value size = 69, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "660", "callId" : "nesto88888"})
2023-03-17T00:17:06.428+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:17:06.432+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 44, CreateTime = 1679008626428, serialized key size = 5, serialized value size = 69, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = {"callStatus": "START", "timestamp" : "660", "callId" : "nesto88888"})
2023-03-17T00:19:14.466+01:00  INFO 4928 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 4928 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T00:19:14.469+01:00  INFO 4928 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T00:19:14.932+01:00  INFO 4928 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T00:19:14.952+01:00  INFO 4928 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T00:19:15.963+01:00  INFO 4928 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T00:19:16.111+01:00  INFO 4928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:19:16.112+01:00  INFO 4928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:19:16.112+01:00  INFO 4928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679008756110
2023-03-17T00:19:16.368+01:00  INFO 4928 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T00:19:16.372+01:00  INFO 4928 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T00:19:16.373+01:00  INFO 4928 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T00:19:16.373+01:00  INFO 4928 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T00:19:16.377+01:00  INFO 4928 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T00:19:16.378+01:00  INFO 4928 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T00:19:16.378+01:00  INFO 4928 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T00:19:16.402+01:00  INFO 4928 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T00:19:16.438+01:00  INFO 4928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:19:16.438+01:00  INFO 4928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:19:16.438+01:00  INFO 4928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679008756438
2023-03-17T00:19:16.440+01:00  INFO 4928 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T00:19:16.449+01:00  INFO 4928 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T00:19:16.457+01:00  INFO 4928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:19:16.458+01:00  INFO 4928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:19:16.458+01:00  INFO 4928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679008756457
2023-03-17T00:19:16.458+01:00  INFO 4928 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T00:19:16.468+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:19:16.468+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T00:19:16.469+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:19:16.471+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:19:16.471+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:19:16.474+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:19:16.474+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:19:16.478+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:19:16.478+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:19:16.479+01:00  INFO 4928 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.404 seconds (process running for 2.754)
2023-03-17T00:19:16.501+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-73a6d5e4-70b1-4642-b09b-f1944a693525
2023-03-17T00:19:16.502+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-bf335151-0c8d-42c2-a7fa-c7b28854bb23
2023-03-17T00:19:16.502+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T00:19:16.502+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T00:19:16.502+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:19:16.502+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:19:33.908+01:00  INFO 9132 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 9132 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T00:19:33.910+01:00  INFO 9132 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T00:19:34.402+01:00  INFO 9132 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T00:19:34.424+01:00  INFO 9132 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T00:19:35.453+01:00  INFO 9132 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T00:19:35.617+01:00  INFO 9132 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:19:35.619+01:00  INFO 9132 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:19:35.619+01:00  INFO 9132 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679008775616
2023-03-17T00:19:35.879+01:00  INFO 9132 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T00:19:35.882+01:00  INFO 9132 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T00:19:35.882+01:00  INFO 9132 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T00:19:35.882+01:00  INFO 9132 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T00:19:35.887+01:00  INFO 9132 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T00:19:35.888+01:00  INFO 9132 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T00:19:35.888+01:00  INFO 9132 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T00:19:35.912+01:00  INFO 9132 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T00:19:35.947+01:00  INFO 9132 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:19:35.947+01:00  INFO 9132 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:19:35.947+01:00  INFO 9132 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679008775947
2023-03-17T00:19:35.949+01:00  INFO 9132 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T00:19:35.957+01:00  INFO 9132 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T00:19:35.964+01:00  INFO 9132 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:19:35.964+01:00  INFO 9132 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:19:35.965+01:00  INFO 9132 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679008775964
2023-03-17T00:19:35.966+01:00  INFO 9132 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T00:19:35.972+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T00:19:35.972+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:19:35.973+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:19:35.974+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:19:35.974+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:19:35.975+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:19:35.976+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:19:35.979+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:19:35.979+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:19:35.980+01:00  INFO 9132 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.48 seconds (process running for 2.819)
2023-03-17T00:19:36.000+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-3435bd85-2229-4e3c-83a5-a802f289be98
2023-03-17T00:19:36.001+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-41d1e74e-f500-4666-b736-166c0bb58fcc
2023-03-17T00:19:36.001+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T00:19:36.001+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T00:19:36.001+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:19:36.001+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:19:49.154+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=13, memberId='consumer-springkafkatask33;-1-3435bd85-2229-4e3c-83a5-a802f289be98', protocol='range'}
2023-03-17T00:19:49.154+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=13, memberId='consumer-springkafkatask33;-2-41d1e74e-f500-4666-b736-166c0bb58fcc', protocol='range'}
2023-03-17T00:20:19.180+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Disconnecting from node 2147483647 due to request timeout.
2023-03-17T00:20:19.183+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cancelled in-flight SYNC_GROUP request with correlation id 6 due to node 2147483647 being disconnected (elapsed time since creation: 30025ms, elapsed time since send: 30025ms, request timeout: 30000ms)
2023-03-17T00:20:19.183+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 7 due to node 2147483647 being disconnected (elapsed time since creation: 27011ms, elapsed time since send: 27011ms, request timeout: 30000ms)
2023-03-17T00:20:19.183+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 8 due to node 2147483647 being disconnected (elapsed time since creation: 24000ms, elapsed time since send: 24000ms, request timeout: 30000ms)
2023-03-17T00:20:19.183+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 9 due to node 2147483647 being disconnected (elapsed time since creation: 20989ms, elapsed time since send: 20989ms, request timeout: 30000ms)
2023-03-17T00:20:19.184+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 10 due to node 2147483647 being disconnected (elapsed time since creation: 17982ms, elapsed time since send: 17982ms, request timeout: 30000ms)
2023-03-17T00:20:19.184+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 11 due to node 2147483647 being disconnected (elapsed time since creation: 14976ms, elapsed time since send: 14976ms, request timeout: 30000ms)
2023-03-17T00:20:19.184+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 12 due to node 2147483647 being disconnected (elapsed time since creation: 11961ms, elapsed time since send: 11961ms, request timeout: 30000ms)
2023-03-17T00:20:19.185+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 13 due to node 2147483647 being disconnected (elapsed time since creation: 8952ms, elapsed time since send: 8952ms, request timeout: 30000ms)
2023-03-17T00:20:19.185+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 14 due to node 2147483647 being disconnected (elapsed time since creation: 5936ms, elapsed time since send: 5936ms, request timeout: 30000ms)
2023-03-17T00:20:19.185+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 15 due to node 2147483647 being disconnected (elapsed time since creation: 2935ms, elapsed time since send: 2935ms, request timeout: 30000ms)
2023-03-17T00:20:19.188+01:00  INFO 9132 --- [kafka-coordinator-heartbeat-thread | springkafkatask33;] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: null. isDisconnected: true. Rediscovery will be attempted.
2023-03-17T00:20:19.191+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:20:19.191+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
2023-03-17T00:20:19.192+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Requesting disconnect from last known coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:20:19.196+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Disconnecting from node 2147483647 due to request timeout.
2023-03-17T00:20:19.196+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cancelled in-flight SYNC_GROUP request with correlation id 6 due to node 2147483647 being disconnected (elapsed time since creation: 30041ms, elapsed time since send: 30040ms, request timeout: 30000ms)
2023-03-17T00:20:19.196+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 7 due to node 2147483647 being disconnected (elapsed time since creation: 27027ms, elapsed time since send: 27027ms, request timeout: 30000ms)
2023-03-17T00:20:19.197+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 8 due to node 2147483647 being disconnected (elapsed time since creation: 24016ms, elapsed time since send: 24016ms, request timeout: 30000ms)
2023-03-17T00:20:19.197+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 9 due to node 2147483647 being disconnected (elapsed time since creation: 21005ms, elapsed time since send: 21005ms, request timeout: 30000ms)
2023-03-17T00:20:19.197+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 10 due to node 2147483647 being disconnected (elapsed time since creation: 17998ms, elapsed time since send: 17998ms, request timeout: 30000ms)
2023-03-17T00:20:19.197+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 11 due to node 2147483647 being disconnected (elapsed time since creation: 14992ms, elapsed time since send: 14992ms, request timeout: 30000ms)
2023-03-17T00:20:19.197+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 12 due to node 2147483647 being disconnected (elapsed time since creation: 11977ms, elapsed time since send: 11977ms, request timeout: 30000ms)
2023-03-17T00:20:19.197+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 13 due to node 2147483647 being disconnected (elapsed time since creation: 8968ms, elapsed time since send: 8968ms, request timeout: 30000ms)
2023-03-17T00:20:19.198+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 14 due to node 2147483647 being disconnected (elapsed time since creation: 5952ms, elapsed time since send: 5952ms, request timeout: 30000ms)
2023-03-17T00:20:19.198+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 15 due to node 2147483647 being disconnected (elapsed time since creation: 2951ms, elapsed time since send: 2951ms, request timeout: 30000ms)
2023-03-17T00:20:19.199+01:00  INFO 9132 --- [kafka-coordinator-heartbeat-thread | springkafkatask33;] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: null. isDisconnected: true. Rediscovery will be attempted.
2023-03-17T00:20:19.202+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:20:19.202+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
2023-03-17T00:20:19.202+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Requesting disconnect from last known coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:20:19.307+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:20:19.307+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:20:19.308+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'null' (DisconnectException)
2023-03-17T00:20:19.308+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'null' (DisconnectException)
2023-03-17T00:20:19.308+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:20:19.308+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:20:19.311+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=13, memberId='consumer-springkafkatask33;-2-41d1e74e-f500-4666-b736-166c0bb58fcc', protocol='range'}
2023-03-17T00:20:19.311+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=13, memberId='consumer-springkafkatask33;-1-3435bd85-2229-4e3c-83a5-a802f289be98', protocol='range'}
2023-03-17T00:20:34.166+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=13, memberId='consumer-springkafkatask33;-1-3435bd85-2229-4e3c-83a5-a802f289be98', protocol='range'}
2023-03-17T00:20:34.166+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=13, memberId='consumer-springkafkatask33;-2-41d1e74e-f500-4666-b736-166c0bb58fcc', protocol='range'}
2023-03-17T00:20:34.166+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting generation due to: encountered REBALANCE_IN_PROGRESS from SYNC_GROUP response
2023-03-17T00:20:34.167+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting generation due to: encountered REBALANCE_IN_PROGRESS from SYNC_GROUP response
2023-03-17T00:20:34.167+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: encountered REBALANCE_IN_PROGRESS from SYNC_GROUP response
2023-03-17T00:20:34.167+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: encountered REBALANCE_IN_PROGRESS from SYNC_GROUP response
2023-03-17T00:20:34.167+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group is rebalancing, so a rejoin is needed.' (RebalanceInProgressException)
2023-03-17T00:20:34.167+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group is rebalancing, so a rejoin is needed.' (RebalanceInProgressException)
2023-03-17T00:20:34.167+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:20:34.168+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:20:34.169+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=14, memberId='consumer-springkafkatask33;-1-3435bd85-2229-4e3c-83a5-a802f289be98', protocol='range'}
2023-03-17T00:20:34.169+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=14, memberId='consumer-springkafkatask33;-2-41d1e74e-f500-4666-b736-166c0bb58fcc', protocol='range'}
2023-03-17T00:20:34.171+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:20:34.171+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:20:34.178+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Finished assignment for group at generation 14: {consumer-springkafkatask33;-2-41d1e74e-f500-4666-b736-166c0bb58fcc=Assignment(partitions=[topicTask2-0]), consumer-springkafkatask33;-1-3435bd85-2229-4e3c-83a5-a802f289be98=Assignment(partitions=[topicTask1-0, topicTask1-1])}
2023-03-17T00:20:34.183+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=14, memberId='consumer-springkafkatask33;-1-3435bd85-2229-4e3c-83a5-a802f289be98', protocol='range'}
2023-03-17T00:20:34.183+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=14, memberId='consumer-springkafkatask33;-2-41d1e74e-f500-4666-b736-166c0bb58fcc', protocol='range'}
2023-03-17T00:20:34.183+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T00:20:34.183+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T00:20:34.186+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T00:20:34.186+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T00:20:34.195+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:20:34.195+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=45, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:20:34.195+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:20:34.196+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T00:20:34.196+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T00:20:34.225+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 34, CreateTime = 1679008783433, serialized key size = -1, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e1)
2023-03-17T00:20:34.234+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:20:34.235+01:00 ERROR 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:20:34.239+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-03-17T00:20:34.246+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-03-17T00:20:34.257+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:20:34.257+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:20:34.258+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679008834257
2023-03-17T00:20:34.263+01:00  INFO 9132 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T00:20:34.264+01:00  INFO 9132 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:20:34.264+01:00  INFO 9132 --- [kafka-producer-network-thread | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 11 with epoch 0
2023-03-17T00:20:34.269+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 35, CreateTime = 1679008791522, serialized key size = -1, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e2)
2023-03-17T00:20:34.270+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:20:34.270+01:00 ERROR 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:20:34.270+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 36, CreateTime = 1679008823350, serialized key size = -1, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e4)
2023-03-17T00:20:34.271+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:20:34.271+01:00 ERROR 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:20:34.280+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 45, CreateTime = 1679008834264, serialized key size = 5, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = e1)
2023-03-17T00:20:34.280+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 46, CreateTime = 1679008834270, serialized key size = 5, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = e2)
2023-03-17T00:20:34.280+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 47, CreateTime = 1679008834271, serialized key size = 5, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = e4)
2023-03-17T00:20:34.452+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 37, CreateTime = 1679008833444, serialized key size = -1, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e5)
2023-03-17T00:20:34.452+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:20:34.453+01:00 ERROR 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:20:34.455+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 48, CreateTime = 1679008834453, serialized key size = 5, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = e5)
2023-03-17T00:21:05.211+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 38, CreateTime = 1679008864198, serialized key size = -1, serialized value size = 73, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "-50", "callId" : "nesto777777777"})
2023-03-17T00:21:05.239+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:21:05.239+01:00 ERROR 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:21:05.242+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 49, CreateTime = 1679008865240, serialized key size = 5, serialized value size = 73, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = {"callStatus": "START", "timestamp" : "-50", "callId" : "nesto777777777"})
2023-03-17T00:22:15.649+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 39, CreateTime = 1679008934645, serialized key size = -1, serialized value size = 61, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "50", "callId" : "100"})
2023-03-17T00:22:15.650+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:22:15.654+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 50, CreateTime = 1679008935651, serialized key size = 5, serialized value size = 61, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = {"callStatus": "START", "timestamp" : "50", "callId" : "100"})
2023-03-17T00:24:29.304+01:00  INFO 7488 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 7488 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T00:24:29.307+01:00  INFO 7488 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T00:24:29.758+01:00  INFO 7488 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T00:24:29.778+01:00  INFO 7488 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T00:24:30.784+01:00  INFO 7488 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T00:24:30.947+01:00  INFO 7488 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:24:30.948+01:00  INFO 7488 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:24:30.948+01:00  INFO 7488 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679009070946
2023-03-17T00:24:31.195+01:00  INFO 7488 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T00:24:31.199+01:00  INFO 7488 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T00:24:31.199+01:00  INFO 7488 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T00:24:31.199+01:00  INFO 7488 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T00:24:31.203+01:00  INFO 7488 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T00:24:31.204+01:00  INFO 7488 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T00:24:31.205+01:00  INFO 7488 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T00:24:31.227+01:00  INFO 7488 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T00:24:31.265+01:00  INFO 7488 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:24:31.265+01:00  INFO 7488 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:24:31.265+01:00  INFO 7488 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679009071265
2023-03-17T00:24:31.266+01:00  INFO 7488 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T00:24:31.275+01:00  INFO 7488 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T00:24:31.282+01:00  INFO 7488 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:24:31.283+01:00  INFO 7488 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:24:31.283+01:00  INFO 7488 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679009071282
2023-03-17T00:24:31.285+01:00  INFO 7488 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T00:24:31.294+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T00:24:31.294+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:24:31.295+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:24:31.296+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:24:31.296+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:24:31.297+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:24:31.298+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:24:31.300+01:00  INFO 7488 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.396 seconds (process running for 2.748)
2023-03-17T00:24:31.300+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:24:31.300+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:24:31.318+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-1dcef807-b515-4c5e-9eeb-e2d36db42b71
2023-03-17T00:24:31.318+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-9121820d-e682-4299-b9b1-710db3bdcf5e
2023-03-17T00:24:31.319+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T00:24:31.319+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T00:24:31.319+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:24:31.319+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:24:58.862+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=15, memberId='consumer-springkafkatask33;-1-1dcef807-b515-4c5e-9eeb-e2d36db42b71', protocol='range'}
2023-03-17T00:24:58.862+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=15, memberId='consumer-springkafkatask33;-2-9121820d-e682-4299-b9b1-710db3bdcf5e', protocol='range'}
2023-03-17T00:24:58.866+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:24:58.867+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:24:58.871+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Finished assignment for group at generation 15: {consumer-springkafkatask33;-2-9121820d-e682-4299-b9b1-710db3bdcf5e=Assignment(partitions=[topicTask2-0]), consumer-springkafkatask33;-1-1dcef807-b515-4c5e-9eeb-e2d36db42b71=Assignment(partitions=[topicTask1-0, topicTask1-1])}
2023-03-17T00:24:58.876+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=15, memberId='consumer-springkafkatask33;-2-9121820d-e682-4299-b9b1-710db3bdcf5e', protocol='range'}
2023-03-17T00:24:58.876+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=15, memberId='consumer-springkafkatask33;-1-1dcef807-b515-4c5e-9eeb-e2d36db42b71', protocol='range'}
2023-03-17T00:24:58.877+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T00:24:58.877+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T00:24:58.879+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T00:24:58.879+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T00:24:58.889+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=51, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:24:58.889+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:24:58.889+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=40, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:24:58.890+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T00:24:58.890+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T00:24:58.919+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 40, CreateTime = 1679009078173, serialized key size = -1, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e3)
2023-03-17T00:24:58.927+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:24:58.928+01:00 ERROR 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:24:58.934+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-03-17T00:24:58.941+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-03-17T00:24:58.952+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:24:58.953+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:24:58.953+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679009098952
2023-03-17T00:24:58.958+01:00  INFO 7488 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T00:24:58.959+01:00  INFO 7488 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:24:58.959+01:00  INFO 7488 --- [kafka-producer-network-thread | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 12 with epoch 0
2023-03-17T00:24:58.965+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 41, CreateTime = 1679009085200, serialized key size = -1, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e4)
2023-03-17T00:24:58.965+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:24:58.965+01:00 ERROR 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:24:58.974+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 51, CreateTime = 1679009098959, serialized key size = 5, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = e3)
2023-03-17T00:24:58.975+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 52, CreateTime = 1679009098966, serialized key size = 5, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = e4)
2023-03-17T00:24:59.596+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 42, CreateTime = 1679009098587, serialized key size = -1, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e5)
2023-03-17T00:24:59.596+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:24:59.598+01:00 ERROR 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:24:59.602+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 53, CreateTime = 1679009099599, serialized key size = 5, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = e5)
2023-03-17T00:25:08.754+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 43, CreateTime = 1679009107736, serialized key size = -1, serialized value size = 73, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "-50", "callId" : "nesto777777777"})
2023-03-17T00:25:08.786+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:25:08.786+01:00 ERROR 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:25:08.789+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 54, CreateTime = 1679009108786, serialized key size = 5, serialized value size = 73, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = {"callStatus": "START", "timestamp" : "-50", "callId" : "nesto777777777"})
2023-03-17T00:25:26.782+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 44, CreateTime = 1679009125765, serialized key size = -1, serialized value size = 69, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "660", "callId" : "nesto88888"})
2023-03-17T00:25:26.784+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:25:26.787+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 55, CreateTime = 1679009126784, serialized key size = 5, serialized value size = 69, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = {"callStatus": "START", "timestamp" : "660", "callId" : "nesto88888"})
2023-03-17T00:33:31.700+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T00:33:31.778+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T10:36:49.377+01:00  INFO 11000 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 11000 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T10:36:49.379+01:00  INFO 11000 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T10:36:49.834+01:00  INFO 11000 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T10:36:49.852+01:00  INFO 11000 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T10:36:50.839+01:00  INFO 11000 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T10:36:50.996+01:00  INFO 11000 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T10:36:50.997+01:00  INFO 11000 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T10:36:50.997+01:00  INFO 11000 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679045810995
2023-03-17T10:36:51.239+01:00  INFO 11000 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T10:36:51.242+01:00  INFO 11000 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T10:36:51.243+01:00  INFO 11000 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T10:36:51.243+01:00  INFO 11000 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T10:36:51.247+01:00  INFO 11000 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T10:36:51.248+01:00  INFO 11000 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T10:36:51.248+01:00  INFO 11000 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T10:36:51.278+01:00  INFO 11000 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T10:36:51.318+01:00  INFO 11000 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T10:36:51.319+01:00  INFO 11000 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T10:36:51.319+01:00  INFO 11000 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679045811318
2023-03-17T10:36:51.320+01:00  INFO 11000 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T10:36:51.327+01:00  INFO 11000 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T10:36:51.334+01:00  INFO 11000 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T10:36:51.335+01:00  INFO 11000 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T10:36:51.335+01:00  INFO 11000 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679045811334
2023-03-17T10:36:51.335+01:00  INFO 11000 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T10:36:51.344+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T10:36:51.344+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T10:36:51.346+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T10:36:51.347+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T10:36:51.347+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T10:36:51.349+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T10:36:51.349+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T10:36:51.352+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T10:36:51.352+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T10:36:51.354+01:00  INFO 11000 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.367 seconds (process running for 2.716)
2023-03-17T10:36:51.372+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-fe8b8d18-5aca-4663-b360-a9e9ea161fd0
2023-03-17T10:36:51.372+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-8c198c18-6b95-4824-8d87-46c1271e9a4c
2023-03-17T10:36:51.373+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T10:36:51.373+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T10:36:51.373+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T10:36:51.373+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T10:36:51.378+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=17, memberId='consumer-springkafkatask33;-1-fe8b8d18-5aca-4663-b360-a9e9ea161fd0', protocol='range'}
2023-03-17T10:36:51.378+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=17, memberId='consumer-springkafkatask33;-2-8c198c18-6b95-4824-8d87-46c1271e9a4c', protocol='range'}
2023-03-17T10:36:51.383+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T10:36:51.384+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T10:36:51.388+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Finished assignment for group at generation 17: {consumer-springkafkatask33;-1-fe8b8d18-5aca-4663-b360-a9e9ea161fd0=Assignment(partitions=[topicTask2-0]), consumer-springkafkatask33;-2-8c198c18-6b95-4824-8d87-46c1271e9a4c=Assignment(partitions=[topicTask1-0, topicTask1-1])}
2023-03-17T10:36:51.398+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=17, memberId='consumer-springkafkatask33;-1-fe8b8d18-5aca-4663-b360-a9e9ea161fd0', protocol='range'}
2023-03-17T10:36:51.398+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=17, memberId='consumer-springkafkatask33;-2-8c198c18-6b95-4824-8d87-46c1271e9a4c', protocol='range'}
2023-03-17T10:36:51.398+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T10:36:51.398+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T10:36:51.402+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T10:36:51.402+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T10:36:51.420+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T10:36:51.420+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=56, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T10:36:51.420+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=45, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T10:36:51.422+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T10:36:51.422+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T10:37:05.824+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 45, CreateTime = 1679045824804, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e)
2023-03-17T10:37:05.834+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:37:05.834+01:00 ERROR 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T10:37:21.521+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 46, CreateTime = 1679045840509, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = w)
2023-03-17T10:37:21.522+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:37:21.522+01:00 ERROR 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T10:37:44.540+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 47, CreateTime = 1679045863537, serialized key size = -1, serialized value size = 63, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "660", "callId" : "8888"})
2023-03-17T10:37:44.572+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:37:44.572+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=660, callId=8888  ]
2023-03-17T10:37:44.573+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=START, timestamp=660, callId=8888  ]
2023-03-17T10:38:16.775+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 48, CreateTime = 1679045895772, serialized key size = -1, serialized value size = 61, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "8888"})
2023-03-17T10:38:16.777+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:38:16.777+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=8888  ]
2023-03-17T10:38:16.777+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T10:38:16.777+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=8888, callStartTimestamp=660, callEndTimestamp=700, callDuration=40]
2023-03-17T10:38:16.778+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 8888
2023-03-17T10:38:16.778+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : null
2023-03-17T10:38:16.788+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-03-17T10:38:16.797+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-03-17T10:38:16.809+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T10:38:16.810+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T10:38:16.810+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679045896809
2023-03-17T10:38:16.816+01:00  INFO 11000 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T10:38:16.817+01:00  INFO 11000 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T10:38:16.817+01:00  INFO 11000 --- [kafka-producer-network-thread | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 13 with epoch 0
2023-03-17T10:38:16.832+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 56, CreateTime = 1679045896817, serialized key size = -1, serialized value size = 88, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = ResponseMsg [callId=8888, callStartTimestamp=660, callEndTimestamp=700, callDuration=40])
2023-03-17T10:40:17.618+01:00  INFO 26960 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 26960 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T10:40:17.621+01:00  INFO 26960 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T10:40:18.078+01:00  INFO 26960 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T10:40:18.097+01:00  INFO 26960 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T10:40:19.151+01:00  INFO 26960 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T10:40:19.293+01:00  INFO 26960 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T10:40:19.294+01:00  INFO 26960 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T10:40:19.294+01:00  INFO 26960 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679046019292
2023-03-17T10:40:19.552+01:00  INFO 26960 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T10:40:19.555+01:00  INFO 26960 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T10:40:19.556+01:00  INFO 26960 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T10:40:19.556+01:00  INFO 26960 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T10:40:19.560+01:00  INFO 26960 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T10:40:19.560+01:00  INFO 26960 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T10:40:19.561+01:00  INFO 26960 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T10:40:19.586+01:00  INFO 26960 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T10:40:19.623+01:00  INFO 26960 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T10:40:19.623+01:00  INFO 26960 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T10:40:19.623+01:00  INFO 26960 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679046019623
2023-03-17T10:40:19.625+01:00  INFO 26960 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T10:40:19.632+01:00  INFO 26960 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T10:40:19.640+01:00  INFO 26960 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T10:40:19.640+01:00  INFO 26960 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T10:40:19.640+01:00  INFO 26960 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679046019640
2023-03-17T10:40:19.641+01:00  INFO 26960 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T10:40:19.645+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T10:40:19.646+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T10:40:19.646+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T10:40:19.648+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T10:40:19.648+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T10:40:19.649+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T10:40:19.649+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T10:40:19.652+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T10:40:19.652+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T10:40:19.653+01:00  INFO 26960 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.432 seconds (process running for 2.805)
2023-03-17T10:40:19.668+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-40c08228-61c5-4ec1-8caf-6bd2129f2948
2023-03-17T10:40:19.668+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-61127b1d-c920-4e25-ad63-c4cba1064fc9
2023-03-17T10:40:19.668+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T10:40:19.668+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T10:40:19.669+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T10:40:19.669+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T10:40:21.834+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=18, memberId='consumer-springkafkatask33;-2-61127b1d-c920-4e25-ad63-c4cba1064fc9', protocol='range'}
2023-03-17T10:40:21.834+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=18, memberId='consumer-springkafkatask33;-1-40c08228-61c5-4ec1-8caf-6bd2129f2948', protocol='range'}
2023-03-17T10:40:21.838+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T10:40:21.842+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Finished assignment for group at generation 18: {consumer-springkafkatask33;-1-40c08228-61c5-4ec1-8caf-6bd2129f2948=Assignment(partitions=[topicTask1-0, topicTask1-1]), consumer-springkafkatask33;-2-61127b1d-c920-4e25-ad63-c4cba1064fc9=Assignment(partitions=[topicTask2-0])}
2023-03-17T10:40:21.847+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=18, memberId='consumer-springkafkatask33;-1-40c08228-61c5-4ec1-8caf-6bd2129f2948', protocol='range'}
2023-03-17T10:40:21.847+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=18, memberId='consumer-springkafkatask33;-2-61127b1d-c920-4e25-ad63-c4cba1064fc9', protocol='range'}
2023-03-17T10:40:21.848+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T10:40:21.848+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T10:40:21.850+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T10:40:21.850+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T10:40:21.861+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T10:40:21.861+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=57, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T10:40:21.862+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=49, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T10:40:21.863+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T10:40:21.863+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T10:40:29.026+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 49, CreateTime = 1679046027999, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e)
2023-03-17T10:40:29.036+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:40:29.036+01:00 ERROR 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T10:40:40.441+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 50, CreateTime = 1679046039430, serialized key size = -1, serialized value size = 63, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "660", "callId" : "8888"})
2023-03-17T10:40:40.473+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:40:40.473+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=660, callId=8888  ]
2023-03-17T10:40:40.473+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=START, timestamp=660, callId=8888  ]
2023-03-17T10:40:52.139+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 51, CreateTime = 1679046051131, serialized key size = -1, serialized value size = 61, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "8888"})
2023-03-17T10:40:52.140+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:40:52.140+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=8888  ]
2023-03-17T10:40:52.140+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T10:40:52.141+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=8888, callStartTimestamp=660, callEndTimestamp=700, callDuration=40]
2023-03-17T10:40:52.141+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 8888
2023-03-17T10:40:52.141+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : ResponseMsg [callId=8888, callStartTimestamp=660, callEndTimestamp=700, callDuration=40]
2023-03-17T10:40:52.141+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:40:52.152+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T10:40:52.335+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection org.postgresql.jdbc.PgConnection@55ea3b5
2023-03-17T10:40:52.337+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2023-03-17T10:40:52.371+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-03-17T10:40:52.381+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-03-17T10:40:52.396+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T10:40:52.396+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T10:40:52.397+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679046052396
2023-03-17T10:40:52.403+01:00  INFO 26960 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T10:40:52.407+01:00  INFO 26960 --- [kafka-producer-network-thread | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 14 with epoch 0
2023-03-17T10:40:52.409+01:00  INFO 26960 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T10:40:52.431+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 57, CreateTime = 1679046052412, serialized key size = -1, serialized value size = 88, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = ResponseMsg [callId=8888, callStartTimestamp=660, callEndTimestamp=700, callDuration=40])
2023-03-17T10:43:42.205+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 52, CreateTime = 1679046221190, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e)
2023-03-17T10:43:42.206+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:43:42.206+01:00 ERROR 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T10:44:02.716+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 53, CreateTime = 1679046241713, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "200", "callId" : "100"})
2023-03-17T10:44:02.718+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:44:02.718+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=200, callId=100  ]
2023-03-17T10:44:02.718+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=START, timestamp=200, callId=100  ]
2023-03-17T10:44:10.823+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 54, CreateTime = 1679046249813, serialized key size = -1, serialized value size = 60, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "100"})
2023-03-17T10:44:10.824+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:44:10.824+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=100  ]
2023-03-17T10:44:10.825+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T10:44:10.825+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=100, callStartTimestamp=200, callEndTimestamp=700, callDuration=500]
2023-03-17T10:44:10.825+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 100
2023-03-17T10:44:10.825+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : ResponseMsg [callId=100, callStartTimestamp=200, callEndTimestamp=700, callDuration=500]
2023-03-17T10:44:10.825+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:44:10.830+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 58, CreateTime = 1679046250827, serialized key size = -1, serialized value size = 88, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = ResponseMsg [callId=100, callStartTimestamp=200, callEndTimestamp=700, callDuration=500])
2023-03-17T10:45:10.438+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 55, CreateTime = 1679046309426, serialized key size = -1, serialized value size = 60, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "101"})
2023-03-17T10:45:10.439+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:45:10.439+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=101  ]
2023-03-17T10:45:10.439+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : scheduleMessageDelete is called
2023-03-17T10:45:10.440+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=END, timestamp=700, callId=101  ]
2023-03-17T10:45:16.478+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 56, CreateTime = 1679046315468, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "200", "callId" : "101"})
2023-03-17T10:45:16.479+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:45:16.479+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=200, callId=101  ]
2023-03-17T10:45:16.480+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T10:45:16.480+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=101, callStartTimestamp=200, callEndTimestamp=700, callDuration=500]
2023-03-17T10:45:16.480+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 101
2023-03-17T10:45:16.480+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : ResponseMsg [callId=101, callStartTimestamp=200, callEndTimestamp=700, callDuration=500]
2023-03-17T10:45:16.480+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:45:16.486+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 59, CreateTime = 1679046316483, serialized key size = -1, serialized value size = 88, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = ResponseMsg [callId=101, callStartTimestamp=200, callEndTimestamp=700, callDuration=500])
2023-03-17T10:46:37.323+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 57, CreateTime = 1679046396319, serialized key size = -1, serialized value size = 60, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "102"})
2023-03-17T10:46:37.323+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:46:37.324+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=102  ]
2023-03-17T10:46:37.325+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : scheduleMessageDelete is called
2023-03-17T10:46:37.325+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=END, timestamp=700, callId=102  ]
2023-03-17T10:46:40.544+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 58, CreateTime = 1679046399528, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "200", "callId" : "102"})
2023-03-17T10:46:40.546+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:46:40.546+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=200, callId=102  ]
2023-03-17T10:46:40.546+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T10:46:40.546+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=102, callStartTimestamp=200, callEndTimestamp=700, callDuration=500]
2023-03-17T10:46:40.546+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 102
2023-03-17T10:46:40.546+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : ResponseMsg [callId=102, callStartTimestamp=200, callEndTimestamp=700, callDuration=500]
2023-03-17T10:46:40.546+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:46:40.550+01:00  WARN 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Failed to validate connection org.postgresql.jdbc.PgConnection@55ea3b5 (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2023-03-17T10:46:40.551+01:00  WARN 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Failed to validate connection org.postgresql.jdbc.PgConnection@4d802071 (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2023-03-17T10:46:40.552+01:00  WARN 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Failed to validate connection org.postgresql.jdbc.PgConnection@5dc5c5ea (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2023-03-17T10:46:40.553+01:00  WARN 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Failed to validate connection org.postgresql.jdbc.PgConnection@1630871 (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2023-03-17T10:46:40.553+01:00  WARN 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Failed to validate connection org.postgresql.jdbc.PgConnection@2e62ecc8 (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2023-03-17T10:46:40.554+01:00  WARN 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Failed to validate connection org.postgresql.jdbc.PgConnection@62add2dd (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2023-03-17T10:46:40.554+01:00  WARN 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Failed to validate connection org.postgresql.jdbc.PgConnection@11b4b1f7 (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2023-03-17T10:46:40.554+01:00  WARN 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Failed to validate connection org.postgresql.jdbc.PgConnection@88d1330 (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2023-03-17T10:46:40.554+01:00  WARN 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Failed to validate connection org.postgresql.jdbc.PgConnection@3130ba45 (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2023-03-17T10:46:40.555+01:00  WARN 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Failed to validate connection org.postgresql.jdbc.PgConnection@3d87ad84 (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2023-03-17T10:47:10.554+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Put message to Cache!
2023-03-17T10:47:10.555+01:00 ERROR 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Fail to send message to database Failed to obtain JDBC Connection
2023-03-17T10:47:10.558+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 60, CreateTime = 1679046430555, serialized key size = -1, serialized value size = 88, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = ResponseMsg [callId=102, callStartTimestamp=200, callEndTimestamp=700, callDuration=500])
2023-03-17T10:47:10.558+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 59, CreateTime = 1679046426470, serialized key size = -1, serialized value size = 60, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "103"})
2023-03-17T10:47:10.559+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:47:10.560+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=103  ]
2023-03-17T10:47:10.560+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : scheduleMessageDelete is called
2023-03-17T10:47:10.560+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=END, timestamp=700, callId=103  ]
2023-03-17T10:47:10.603+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 60, CreateTime = 1679046429595, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "200", "callId" : "103"})
2023-03-17T10:47:10.604+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:47:10.605+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=200, callId=103  ]
2023-03-17T10:47:10.605+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T10:47:10.605+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=103, callStartTimestamp=200, callEndTimestamp=700, callDuration=500]
2023-03-17T10:47:10.605+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 103
2023-03-17T10:47:10.605+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : ResponseMsg [callId=103, callStartTimestamp=200, callEndTimestamp=700, callDuration=500]
2023-03-17T10:47:10.605+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Put message to Cache!
2023-03-17T10:47:10.609+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 61, CreateTime = 1679046430605, serialized key size = -1, serialized value size = 88, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = ResponseMsg [callId=103, callStartTimestamp=200, callEndTimestamp=700, callDuration=500])
2023-03-17T10:47:13.744+01:00  INFO 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:47:16.544+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 61, CreateTime = 1679046435538, serialized key size = -1, serialized value size = 60, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "104"})
2023-03-17T10:47:16.545+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:47:16.545+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=104  ]
2023-03-17T10:47:16.546+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : scheduleMessageDelete is called
2023-03-17T10:47:16.546+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=END, timestamp=700, callId=104  ]
2023-03-17T10:47:19.093+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 62, CreateTime = 1679046438089, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "200", "callId" : "105"})
2023-03-17T10:47:19.094+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:47:19.094+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=200, callId=105  ]
2023-03-17T10:47:19.094+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=START, timestamp=200, callId=105  ]
2023-03-17T10:47:35.139+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 63, CreateTime = 1679046454135, serialized key size = -1, serialized value size = 60, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "106"})
2023-03-17T10:47:35.140+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:47:35.141+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=106  ]
2023-03-17T10:47:35.141+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : scheduleMessageDelete is called
2023-03-17T10:47:35.142+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=END, timestamp=700, callId=106  ]
2023-03-17T10:47:39.703+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 64, CreateTime = 1679046458695, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "200", "callId" : "106"})
2023-03-17T10:47:39.703+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:47:39.704+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=200, callId=106  ]
2023-03-17T10:47:39.704+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T10:47:39.704+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=106, callStartTimestamp=200, callEndTimestamp=700, callDuration=500]
2023-03-17T10:47:39.704+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 106
2023-03-17T10:47:39.705+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : ResponseMsg [callId=106, callStartTimestamp=200, callEndTimestamp=700, callDuration=500]
2023-03-17T10:47:39.705+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Put message to Cache!
2023-03-17T10:47:39.707+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 62, CreateTime = 1679046459705, serialized key size = -1, serialized value size = 88, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = ResponseMsg [callId=106, callStartTimestamp=200, callEndTimestamp=700, callDuration=500])
2023-03-17T10:47:43.752+01:00 ERROR 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:83) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:62) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$0(DatabaseMessageHandler.java:116) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: java.sql.SQLTransientConnectionException: HikariPool-1 - Connection is not available, request timed out after 30007ms.
	at com.zaxxer.hikari.pool.HikariPool.createTimeoutException(HikariPool.java:696) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:181) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:146) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:128) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	... 12 common frames omitted
Caused by: org.postgresql.util.PSQLException: Connection to localhost:5432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:319) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.Driver.makeConnection(Driver.java:434) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.Driver.connect(Driver.java:291) ~[postgresql-42.5.1.jar:42.5.1]
	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:138) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:359) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.newPoolEntry(PoolBase.java:201) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.createPoolEntry(HikariPool.java:470) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:733) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:712) ~[HikariCP-5.0.1.jar:na]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	... 3 common frames omitted
Caused by: java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method) ~[na:na]
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672) ~[na:na]
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542) ~[na:na]
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597) ~[na:na]
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327) ~[na:na]
	at java.base/java.net.Socket.connect(Socket.java:633) ~[na:na]
	at org.postgresql.core.PGStream.createSocket(PGStream.java:241) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.PGStream.<init>(PGStream.java:98) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:109) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235) ~[postgresql-42.5.1.jar:42.5.1]
	... 14 common frames omitted

2023-03-17T10:47:43.757+01:00  INFO 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:48:13.762+01:00 ERROR 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:83) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:62) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$0(DatabaseMessageHandler.java:116) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: java.sql.SQLTransientConnectionException: HikariPool-1 - Connection is not available, request timed out after 30003ms.
	at com.zaxxer.hikari.pool.HikariPool.createTimeoutException(HikariPool.java:696) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:181) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:146) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:128) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	... 12 common frames omitted
Caused by: org.postgresql.util.PSQLException: Connection to localhost:5432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:319) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.Driver.makeConnection(Driver.java:434) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.Driver.connect(Driver.java:291) ~[postgresql-42.5.1.jar:42.5.1]
	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:138) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:359) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.newPoolEntry(PoolBase.java:201) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.createPoolEntry(HikariPool.java:470) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:733) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:712) ~[HikariCP-5.0.1.jar:na]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	... 3 common frames omitted
Caused by: java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method) ~[na:na]
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672) ~[na:na]
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542) ~[na:na]
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597) ~[na:na]
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327) ~[na:na]
	at java.base/java.net.Socket.connect(Socket.java:633) ~[na:na]
	at org.postgresql.core.PGStream.createSocket(PGStream.java:241) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.PGStream.<init>(PGStream.java:98) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:109) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235) ~[postgresql-42.5.1.jar:42.5.1]
	... 14 common frames omitted

2023-03-17T10:48:13.762+01:00  INFO 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:48:16.560+01:00  INFO 26960 --- [pool-1-thread-3] c.s.task.cache.EventMessageCache         : Message schedule for delete: EventMessage: [ callStatus=END, timestamp=700, callId=104  ]
2023-03-17T10:48:43.775+01:00 ERROR 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:83) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:62) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$0(DatabaseMessageHandler.java:116) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: java.sql.SQLTransientConnectionException: HikariPool-1 - Connection is not available, request timed out after 30011ms.
	at com.zaxxer.hikari.pool.HikariPool.createTimeoutException(HikariPool.java:696) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:181) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:146) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:128) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	... 12 common frames omitted
Caused by: org.postgresql.util.PSQLException: Connection to localhost:5432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:319) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.Driver.makeConnection(Driver.java:434) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.Driver.connect(Driver.java:291) ~[postgresql-42.5.1.jar:42.5.1]
	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:138) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:359) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.newPoolEntry(PoolBase.java:201) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.createPoolEntry(HikariPool.java:470) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:733) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:712) ~[HikariCP-5.0.1.jar:na]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	... 3 common frames omitted
Caused by: java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method) ~[na:na]
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672) ~[na:na]
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542) ~[na:na]
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597) ~[na:na]
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327) ~[na:na]
	at java.base/java.net.Socket.connect(Socket.java:633) ~[na:na]
	at org.postgresql.core.PGStream.createSocket(PGStream.java:241) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.PGStream.<init>(PGStream.java:98) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:109) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235) ~[postgresql-42.5.1.jar:42.5.1]
	... 14 common frames omitted

2023-03-17T10:48:43.776+01:00  INFO 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:49:13.792+01:00 ERROR 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:83) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:62) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$0(DatabaseMessageHandler.java:116) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: java.sql.SQLTransientConnectionException: HikariPool-1 - Connection is not available, request timed out after 30015ms.
	at com.zaxxer.hikari.pool.HikariPool.createTimeoutException(HikariPool.java:696) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:181) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:146) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:128) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	... 12 common frames omitted
Caused by: org.postgresql.util.PSQLException: Connection to localhost:5432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:319) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.Driver.makeConnection(Driver.java:434) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.Driver.connect(Driver.java:291) ~[postgresql-42.5.1.jar:42.5.1]
	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:138) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:359) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.newPoolEntry(PoolBase.java:201) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.createPoolEntry(HikariPool.java:470) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:733) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:712) ~[HikariCP-5.0.1.jar:na]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	... 3 common frames omitted
Caused by: java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method) ~[na:na]
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672) ~[na:na]
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542) ~[na:na]
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597) ~[na:na]
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327) ~[na:na]
	at java.base/java.net.Socket.connect(Socket.java:633) ~[na:na]
	at org.postgresql.core.PGStream.createSocket(PGStream.java:241) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.PGStream.<init>(PGStream.java:98) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:109) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235) ~[postgresql-42.5.1.jar:42.5.1]
	... 14 common frames omitted

2023-03-17T10:49:13.796+01:00  INFO 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:49:19.903+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T10:49:19.903+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T10:49:43.803+01:00 ERROR 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:83) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:62) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$0(DatabaseMessageHandler.java:116) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: java.sql.SQLTransientConnectionException: HikariPool-1 - Connection is not available, request timed out after 30006ms.
	at com.zaxxer.hikari.pool.HikariPool.createTimeoutException(HikariPool.java:696) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:181) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:146) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:128) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	... 12 common frames omitted
Caused by: org.postgresql.util.PSQLException: Connection to localhost:5432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:319) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.Driver.makeConnection(Driver.java:434) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.Driver.connect(Driver.java:291) ~[postgresql-42.5.1.jar:42.5.1]
	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:138) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:359) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.newPoolEntry(PoolBase.java:201) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.createPoolEntry(HikariPool.java:470) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:733) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:712) ~[HikariCP-5.0.1.jar:na]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	... 3 common frames omitted
Caused by: java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method) ~[na:na]
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672) ~[na:na]
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542) ~[na:na]
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597) ~[na:na]
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327) ~[na:na]
	at java.base/java.net.Socket.connect(Socket.java:633) ~[na:na]
	at org.postgresql.core.PGStream.createSocket(PGStream.java:241) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.PGStream.<init>(PGStream.java:98) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:109) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235) ~[postgresql-42.5.1.jar:42.5.1]
	... 14 common frames omitted

2023-03-17T10:49:43.804+01:00  INFO 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:49:51.625+01:00  INFO 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:49:51.626+01:00  INFO 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:50:09.733+01:00  INFO 26960 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient   : [Producer clientId=producer-1] Node -1 disconnected.
2023-03-17T10:50:16.576+01:00  INFO 26960 --- [pool-1-thread-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 104
2023-03-17T10:50:16.576+01:00  INFO 26960 --- [pool-1-thread-1] c.s.task.cache.EventMessageCache         : Message is deleted via schedule
2023-03-17T11:27:18.134+01:00  INFO 28268 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 28268 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T11:27:18.137+01:00  INFO 28268 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T11:27:18.583+01:00  INFO 28268 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T11:27:18.602+01:00  INFO 28268 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T11:27:19.605+01:00  INFO 28268 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T11:27:19.738+01:00  INFO 28268 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:27:19.740+01:00  INFO 28268 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:27:19.740+01:00  INFO 28268 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679048839737
2023-03-17T11:27:20.008+01:00  INFO 28268 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T11:27:20.012+01:00  INFO 28268 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T11:27:20.013+01:00  INFO 28268 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T11:27:20.013+01:00  INFO 28268 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T11:27:20.018+01:00  INFO 28268 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T11:27:20.019+01:00  INFO 28268 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T11:27:20.020+01:00  INFO 28268 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T11:27:20.051+01:00  INFO 28268 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T11:27:20.099+01:00  INFO 28268 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:27:20.099+01:00  INFO 28268 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:27:20.099+01:00  INFO 28268 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679048840099
2023-03-17T11:27:20.102+01:00  INFO 28268 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T11:27:20.112+01:00  INFO 28268 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T11:27:20.121+01:00  INFO 28268 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:27:20.121+01:00  INFO 28268 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:27:20.121+01:00  INFO 28268 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679048840120
2023-03-17T11:27:20.122+01:00  INFO 28268 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T11:27:20.131+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T11:27:20.130+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T11:27:20.132+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T11:27:20.133+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T11:27:20.133+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T11:27:20.135+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T11:27:20.135+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T11:27:20.138+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:27:20.138+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:27:20.141+01:00  INFO 28268 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.412 seconds (process running for 2.754)
2023-03-17T11:27:20.162+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-9747d040-5d59-4483-9132-94b9ec588b94
2023-03-17T11:27:20.162+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-4ad14594-37df-4d82-a91e-bb4af211e309
2023-03-17T11:27:20.163+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T11:27:20.163+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T11:27:20.164+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:27:20.164+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:27:20.167+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=20, memberId='consumer-springkafkatask33;-1-9747d040-5d59-4483-9132-94b9ec588b94', protocol='range'}
2023-03-17T11:27:20.167+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=20, memberId='consumer-springkafkatask33;-2-4ad14594-37df-4d82-a91e-bb4af211e309', protocol='range'}
2023-03-17T11:27:20.172+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T11:27:20.173+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T11:27:20.177+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Finished assignment for group at generation 20: {consumer-springkafkatask33;-1-9747d040-5d59-4483-9132-94b9ec588b94=Assignment(partitions=[topicTask1-0, topicTask1-1]), consumer-springkafkatask33;-2-4ad14594-37df-4d82-a91e-bb4af211e309=Assignment(partitions=[topicTask2-0])}
2023-03-17T11:27:20.185+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=20, memberId='consumer-springkafkatask33;-1-9747d040-5d59-4483-9132-94b9ec588b94', protocol='range'}
2023-03-17T11:27:20.185+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=20, memberId='consumer-springkafkatask33;-2-4ad14594-37df-4d82-a91e-bb4af211e309', protocol='range'}
2023-03-17T11:27:20.186+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T11:27:20.186+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T11:27:20.188+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T11:27:20.188+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T11:27:20.201+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=63, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T11:27:20.201+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T11:27:20.202+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=65, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T11:27:20.203+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T11:27:20.203+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T11:27:32.104+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 65, CreateTime = 1679048851089, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e)
2023-03-17T11:27:32.111+01:00 ERROR 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : Message need be in JSON format! 
2023-03-17T11:27:32.111+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T11:27:32.111+01:00 ERROR 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T11:27:51.311+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 66, CreateTime = 1679048870300, serialized key size = -1, serialized value size = 63, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "-200", "callId" : "110"})
2023-03-17T11:27:51.339+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T11:27:51.340+01:00 ERROR 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T11:28:02.190+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 67, CreateTime = 1679048881173, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "300", "callId" : "110"})
2023-03-17T11:28:02.192+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T11:28:02.192+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=300, callId=110  ]
2023-03-17T11:28:02.192+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=START, timestamp=300, callId=110  ]
2023-03-17T11:28:23.016+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 68, CreateTime = 1679048902004, serialized key size = -1, serialized value size = 60, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "110"})
2023-03-17T11:28:23.017+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T11:28:23.018+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=110  ]
2023-03-17T11:28:23.018+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T11:28:23.018+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=110, callStartTimestamp=300, callEndTimestamp=700, callDuration=400]
2023-03-17T11:28:23.018+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 110
2023-03-17T11:28:23.018+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : ResponseMsg [callId=110, callStartTimestamp=300, callEndTimestamp=700, callDuration=400]
2023-03-17T11:28:23.018+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T11:28:23.022+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T11:28:23.201+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection org.postgresql.jdbc.PgConnection@875244f
2023-03-17T11:28:23.203+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2023-03-17T11:28:23.226+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-03-17T11:28:23.235+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-03-17T11:28:23.249+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:28:23.250+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:28:23.250+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679048903249
2023-03-17T11:28:23.257+01:00  INFO 28268 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T11:28:23.257+01:00  INFO 28268 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T11:28:23.258+01:00  INFO 28268 --- [kafka-producer-network-thread | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 15 with epoch 0
2023-03-17T11:28:23.276+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : Messages from topic 2 
2023-03-17T11:28:34.770+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 69, CreateTime = 1679048913763, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "300", "callId" : "111"})
2023-03-17T11:28:34.771+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T11:28:34.772+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=300, callId=111  ]
2023-03-17T11:28:34.772+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=START, timestamp=300, callId=111  ]
2023-03-17T11:28:42.346+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 70, CreateTime = 1679048921342, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "301", "callId" : "111"})
2023-03-17T11:28:42.347+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T11:28:42.347+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=301, callId=111  ]
2023-03-17T11:28:42.348+01:00 ERROR 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Receive duplicate event
2023-03-17T11:28:45.522+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 71, CreateTime = 1679048924508, serialized key size = -1, serialized value size = 60, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "111"})
2023-03-17T11:28:45.523+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T11:28:45.524+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=111  ]
2023-03-17T11:28:45.524+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T11:28:45.524+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=111, callStartTimestamp=301, callEndTimestamp=700, callDuration=399]
2023-03-17T11:28:45.524+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 111
2023-03-17T11:28:45.524+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : ResponseMsg [callId=111, callStartTimestamp=301, callEndTimestamp=700, callDuration=399]
2023-03-17T11:28:45.524+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T11:28:45.529+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : Messages from topic 2 
2023-03-17T11:37:22.866+01:00  INFO 8076 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 8076 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T11:37:22.869+01:00  INFO 8076 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T11:37:23.339+01:00  INFO 8076 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T11:37:23.359+01:00  INFO 8076 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T11:37:23.903+01:00  INFO 8076 --- [main] com.springkafka.task.EventKafkaFlow      : Message call status need be: [
2023-03-17T11:37:24.376+01:00  INFO 8076 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T11:37:24.512+01:00  INFO 8076 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:37:24.512+01:00  INFO 8076 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:37:24.512+01:00  INFO 8076 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679049444511
2023-03-17T11:37:24.764+01:00  INFO 8076 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T11:37:24.768+01:00  INFO 8076 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T11:37:24.768+01:00  INFO 8076 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T11:37:24.768+01:00  INFO 8076 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T11:37:24.772+01:00  INFO 8076 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T11:37:24.773+01:00  INFO 8076 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T11:37:24.773+01:00  INFO 8076 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T11:37:24.799+01:00  INFO 8076 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T11:37:24.834+01:00  INFO 8076 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:37:24.835+01:00  INFO 8076 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:37:24.835+01:00  INFO 8076 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679049444834
2023-03-17T11:37:24.837+01:00  INFO 8076 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T11:37:24.844+01:00  INFO 8076 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T11:37:24.851+01:00  INFO 8076 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:37:24.852+01:00  INFO 8076 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:37:24.852+01:00  INFO 8076 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679049444851
2023-03-17T11:37:24.853+01:00  INFO 8076 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T11:37:24.859+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T11:37:24.859+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T11:37:24.860+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T11:37:24.861+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T11:37:24.861+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T11:37:24.862+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T11:37:24.862+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T11:37:24.866+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:37:24.866+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:37:24.868+01:00  INFO 8076 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.39 seconds (process running for 2.736)
2023-03-17T11:37:24.887+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-2ec8ed41-df2d-45b3-bcc8-166b7b0294eb
2023-03-17T11:37:24.888+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-b471811d-e0b0-4cd5-83fd-e17dca20b89a
2023-03-17T11:37:24.888+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T11:37:24.888+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T11:37:24.888+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:37:24.888+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:37:24.891+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=22, memberId='consumer-springkafkatask33;-1-b471811d-e0b0-4cd5-83fd-e17dca20b89a', protocol='range'}
2023-03-17T11:37:24.891+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=22, memberId='consumer-springkafkatask33;-2-2ec8ed41-df2d-45b3-bcc8-166b7b0294eb', protocol='range'}
2023-03-17T11:37:24.896+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T11:37:24.899+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Finished assignment for group at generation 22: {consumer-springkafkatask33;-1-b471811d-e0b0-4cd5-83fd-e17dca20b89a=Assignment(partitions=[topicTask1-0, topicTask1-1]), consumer-springkafkatask33;-2-2ec8ed41-df2d-45b3-bcc8-166b7b0294eb=Assignment(partitions=[topicTask2-0])}
2023-03-17T11:37:24.904+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=22, memberId='consumer-springkafkatask33;-1-b471811d-e0b0-4cd5-83fd-e17dca20b89a', protocol='range'}
2023-03-17T11:37:24.904+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=22, memberId='consumer-springkafkatask33;-2-2ec8ed41-df2d-45b3-bcc8-166b7b0294eb', protocol='range'}
2023-03-17T11:37:24.905+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T11:37:24.905+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T11:37:24.907+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T11:37:24.907+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T11:37:24.922+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T11:37:24.922+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=65, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T11:37:24.922+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=72, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T11:37:24.923+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T11:37:24.923+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T11:39:28.607+01:00  INFO 29780 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 29780 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T11:39:28.609+01:00  INFO 29780 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T11:39:29.101+01:00  INFO 29780 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T11:39:29.122+01:00  INFO 29780 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T11:39:29.662+01:00  INFO 29780 --- [main] com.springkafka.task.EventKafkaFlow      : Message call status need be: [
2023-03-17T11:39:30.145+01:00  INFO 29780 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T11:39:30.283+01:00  INFO 29780 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:39:30.283+01:00  INFO 29780 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:39:30.283+01:00  INFO 29780 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679049570282
2023-03-17T11:39:30.531+01:00  INFO 29780 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T11:39:30.535+01:00  INFO 29780 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T11:39:30.535+01:00  INFO 29780 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T11:39:30.536+01:00  INFO 29780 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T11:39:30.544+01:00  INFO 29780 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T11:39:30.545+01:00  INFO 29780 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T11:39:30.546+01:00  INFO 29780 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T11:39:30.569+01:00  INFO 29780 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T11:39:30.607+01:00  INFO 29780 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:39:30.608+01:00  INFO 29780 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:39:30.608+01:00  INFO 29780 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679049570607
2023-03-17T11:39:30.610+01:00  INFO 29780 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T11:39:30.617+01:00  INFO 29780 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T11:39:30.624+01:00  INFO 29780 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:39:30.625+01:00  INFO 29780 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:39:30.626+01:00  INFO 29780 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679049570624
2023-03-17T11:39:30.626+01:00  INFO 29780 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T11:39:30.633+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T11:39:30.633+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T11:39:30.634+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T11:39:30.635+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T11:39:30.635+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T11:39:30.637+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T11:39:30.637+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T11:39:30.640+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:39:30.640+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:39:30.640+01:00  INFO 29780 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.446 seconds (process running for 2.806)
2023-03-17T11:39:30.655+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-21fa16d6-0085-48af-98d5-afffaa544962
2023-03-17T11:39:30.655+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-364d96e9-6f06-4a32-88b3-3c77d95bea6f
2023-03-17T11:39:30.656+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T11:39:30.656+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T11:39:30.656+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:39:30.656+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:40:03.169+01:00  INFO 30436 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 30436 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T11:40:03.172+01:00  INFO 30436 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T11:40:03.635+01:00  INFO 30436 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T11:40:03.655+01:00  INFO 30436 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T11:40:04.673+01:00  INFO 30436 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T11:40:04.813+01:00  INFO 30436 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:40:04.815+01:00  INFO 30436 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:40:04.815+01:00  INFO 30436 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679049604812
2023-03-17T11:40:05.056+01:00  INFO 30436 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T11:40:05.059+01:00  INFO 30436 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T11:40:05.060+01:00  INFO 30436 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T11:40:05.060+01:00  INFO 30436 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T11:40:05.063+01:00  INFO 30436 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T11:40:05.064+01:00  INFO 30436 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T11:40:05.064+01:00  INFO 30436 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T11:40:05.087+01:00  INFO 30436 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T11:40:05.121+01:00  INFO 30436 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:40:05.122+01:00  INFO 30436 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:40:05.122+01:00  INFO 30436 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679049605121
2023-03-17T11:40:05.123+01:00  INFO 30436 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T11:40:05.131+01:00  INFO 30436 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T11:40:05.138+01:00  INFO 30436 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:40:05.139+01:00  INFO 30436 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:40:05.139+01:00  INFO 30436 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679049605138
2023-03-17T11:40:05.140+01:00  INFO 30436 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T11:40:05.145+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T11:40:05.146+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T11:40:05.147+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T11:40:05.147+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T11:40:05.147+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T11:40:05.148+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T11:40:05.148+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T11:40:05.151+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:40:05.151+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:40:05.156+01:00  INFO 30436 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.408 seconds (process running for 2.772)
2023-03-17T11:40:05.172+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-1ee6d71d-c5dc-4950-a9f2-4453731d5ccd
2023-03-17T11:40:05.172+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-e4de796e-52ce-4f30-9d11-2ec9daf98043
2023-03-17T11:40:05.172+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T11:40:05.172+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T11:40:05.173+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:40:05.173+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:40:10.213+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=23, memberId='consumer-springkafkatask33;-2-e4de796e-52ce-4f30-9d11-2ec9daf98043', protocol='range'}
2023-03-17T11:40:10.213+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=23, memberId='consumer-springkafkatask33;-1-1ee6d71d-c5dc-4950-a9f2-4453731d5ccd', protocol='range'}
2023-03-17T11:40:10.217+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T11:40:10.222+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Finished assignment for group at generation 23: {consumer-springkafkatask33;-2-e4de796e-52ce-4f30-9d11-2ec9daf98043=Assignment(partitions=[topicTask1-1]), consumer-springkafkatask33;-1-364d96e9-6f06-4a32-88b3-3c77d95bea6f=Assignment(partitions=[topicTask1-0]), consumer-springkafkatask33;-2-21fa16d6-0085-48af-98d5-afffaa544962=Assignment(partitions=[]), consumer-springkafkatask33;-1-1ee6d71d-c5dc-4950-a9f2-4453731d5ccd=Assignment(partitions=[topicTask2-0])}
2023-03-17T11:40:10.227+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=23, memberId='consumer-springkafkatask33;-1-1ee6d71d-c5dc-4950-a9f2-4453731d5ccd', protocol='range'}
2023-03-17T11:40:10.227+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=23, memberId='consumer-springkafkatask33;-2-e4de796e-52ce-4f30-9d11-2ec9daf98043', protocol='range'}
2023-03-17T11:40:10.228+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T11:40:10.228+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-1])
2023-03-17T11:40:10.231+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-1
2023-03-17T11:40:10.231+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T11:40:10.240+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=72, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T11:40:10.240+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=65, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T11:40:10.242+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T11:40:10.242+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-1]
2023-03-17T11:40:15.870+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 72, CreateTime = 1679049614846, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e)
2023-03-17T11:40:15.878+01:00 ERROR 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : Message need be in JSON format! 
2023-03-17T11:40:15.879+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T11:40:15.879+01:00 ERROR 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T11:40:23.602+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 73, CreateTime = 1679049622589, serialized key size = -1, serialized value size = 60, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "112"})
2023-03-17T11:40:23.631+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T11:40:23.631+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=112  ]
2023-03-17T11:40:23.632+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.cache.EventMessageCache         : scheduleMessageDelete is called
2023-03-17T11:40:23.632+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=END, timestamp=700, callId=112  ]
2023-03-17T11:40:27.176+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 74, CreateTime = 1679049626162, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "301", "callId" : "112"})
2023-03-17T11:40:27.177+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T11:40:27.177+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=301, callId=112  ]
2023-03-17T11:40:27.178+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T11:40:27.178+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=112, callStartTimestamp=301, callEndTimestamp=700, callDuration=399]
2023-03-17T11:40:27.178+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 112
2023-03-17T11:40:27.178+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : ResponseMsg [callId=112, callStartTimestamp=301, callEndTimestamp=700, callDuration=399]
2023-03-17T11:40:27.178+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T11:40:27.183+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T11:40:27.360+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection org.postgresql.jdbc.PgConnection@74725aac
2023-03-17T11:40:27.362+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2023-03-17T11:40:27.388+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-03-17T11:40:27.397+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-03-17T11:40:27.412+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:40:27.412+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:40:27.412+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679049627411
2023-03-17T11:40:27.418+01:00  INFO 30436 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T11:40:27.419+01:00  INFO 30436 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T11:40:27.420+01:00  INFO 30436 --- [kafka-producer-network-thread | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 16 with epoch 0
2023-03-17T11:40:27.435+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : Messages from topic 2 
2023-03-17T11:40:55.328+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: group is already rebalancing
2023-03-17T11:40:55.328+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: group is already rebalancing
2023-03-17T11:40:55.329+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Revoke previously assigned partitions topicTask2-0
2023-03-17T11:40:55.329+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Revoke previously assigned partitions topicTask1-1
2023-03-17T11:40:55.330+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions revoked: [topicTask2-0]
2023-03-17T11:40:55.330+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions revoked: [topicTask1-1]
2023-03-17T11:40:55.331+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:40:55.331+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:40:55.333+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=24, memberId='consumer-springkafkatask33;-1-1ee6d71d-c5dc-4950-a9f2-4453731d5ccd', protocol='range'}
2023-03-17T11:40:55.333+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=24, memberId='consumer-springkafkatask33;-2-e4de796e-52ce-4f30-9d11-2ec9daf98043', protocol='range'}
2023-03-17T11:40:55.829+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Finished assignment for group at generation 24: {consumer-springkafkatask33;-2-e4de796e-52ce-4f30-9d11-2ec9daf98043=Assignment(partitions=[topicTask1-0, topicTask1-1]), consumer-springkafkatask33;-1-1ee6d71d-c5dc-4950-a9f2-4453731d5ccd=Assignment(partitions=[topicTask2-0])}
2023-03-17T11:40:55.831+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=24, memberId='consumer-springkafkatask33;-2-e4de796e-52ce-4f30-9d11-2ec9daf98043', protocol='range'}
2023-03-17T11:40:55.831+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=24, memberId='consumer-springkafkatask33;-1-1ee6d71d-c5dc-4950-a9f2-4453731d5ccd', protocol='range'}
2023-03-17T11:40:55.832+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T11:40:55.832+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T11:40:55.832+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T11:40:55.832+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T11:40:55.833+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T11:40:55.833+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=66, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T11:40:55.833+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=75, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T11:40:55.833+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T11:40:55.833+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T12:24:04.348+01:00  INFO 28424 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 28424 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T12:24:04.351+01:00  INFO 28424 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T12:24:04.813+01:00  INFO 28424 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T12:24:04.832+01:00  INFO 28424 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T12:24:05.866+01:00  INFO 28424 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T12:24:06.015+01:00  INFO 28424 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T12:24:06.016+01:00  INFO 28424 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T12:24:06.016+01:00  INFO 28424 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679052246014
2023-03-17T12:24:06.274+01:00  INFO 28424 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T12:24:06.277+01:00  INFO 28424 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T12:24:06.278+01:00  INFO 28424 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T12:24:06.278+01:00  INFO 28424 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T12:24:06.282+01:00  INFO 28424 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T12:24:06.283+01:00  INFO 28424 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T12:24:06.283+01:00  INFO 28424 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T12:24:06.307+01:00  INFO 28424 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T12:24:06.356+01:00  INFO 28424 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T12:24:06.356+01:00  INFO 28424 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T12:24:06.356+01:00  INFO 28424 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679052246356
2023-03-17T12:24:06.358+01:00  INFO 28424 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T12:24:06.369+01:00  INFO 28424 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T12:24:06.376+01:00  INFO 28424 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T12:24:06.376+01:00  INFO 28424 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T12:24:06.376+01:00  INFO 28424 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679052246376
2023-03-17T12:24:06.377+01:00  INFO 28424 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T12:24:06.390+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T12:24:06.390+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T12:24:06.391+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T12:24:06.392+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T12:24:06.392+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T12:24:06.393+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T12:24:06.393+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T12:24:06.393+01:00  INFO 28424 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.451 seconds (process running for 2.798)
2023-03-17T12:24:06.396+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:24:06.396+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:24:06.414+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-ca8482f7-7ce1-4453-8c28-34addb73d68f
2023-03-17T12:24:06.414+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-ffaaa0bd-a6a0-4bb7-8547-4aab41bc5987
2023-03-17T12:24:06.415+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T12:24:06.415+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T12:24:06.415+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:24:06.415+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:24:06.418+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=26, memberId='consumer-springkafkatask33;-2-ca8482f7-7ce1-4453-8c28-34addb73d68f', protocol='range'}
2023-03-17T12:24:06.418+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=26, memberId='consumer-springkafkatask33;-1-ffaaa0bd-a6a0-4bb7-8547-4aab41bc5987', protocol='range'}
2023-03-17T12:24:06.423+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T12:24:06.427+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Finished assignment for group at generation 26: {consumer-springkafkatask33;-1-ffaaa0bd-a6a0-4bb7-8547-4aab41bc5987=Assignment(partitions=[topicTask1-0, topicTask1-1]), consumer-springkafkatask33;-2-ca8482f7-7ce1-4453-8c28-34addb73d68f=Assignment(partitions=[topicTask2-0])}
2023-03-17T12:24:06.434+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=26, memberId='consumer-springkafkatask33;-1-ffaaa0bd-a6a0-4bb7-8547-4aab41bc5987', protocol='range'}
2023-03-17T12:24:06.434+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=26, memberId='consumer-springkafkatask33;-2-ca8482f7-7ce1-4453-8c28-34addb73d68f', protocol='range'}
2023-03-17T12:24:06.435+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T12:24:06.435+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T12:24:06.439+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T12:24:06.439+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T12:24:06.454+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T12:24:06.454+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=66, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T12:24:06.454+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=75, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T12:24:06.456+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T12:24:06.456+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T12:24:16.028+01:00  INFO 30624 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 30624 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T12:24:16.030+01:00  INFO 30624 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T12:24:16.523+01:00  INFO 30624 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T12:24:16.547+01:00  INFO 30624 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T12:24:17.572+01:00  INFO 30624 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T12:24:17.718+01:00  INFO 30624 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T12:24:17.720+01:00  INFO 30624 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T12:24:17.720+01:00  INFO 30624 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679052257717
2023-03-17T12:24:18.006+01:00  INFO 30624 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T12:24:18.011+01:00  INFO 30624 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T12:24:18.012+01:00  INFO 30624 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T12:24:18.012+01:00  INFO 30624 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T12:24:18.016+01:00  INFO 30624 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T12:24:18.017+01:00  INFO 30624 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T12:24:18.018+01:00  INFO 30624 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T12:24:18.047+01:00  INFO 30624 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T12:24:18.099+01:00  INFO 30624 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T12:24:18.099+01:00  INFO 30624 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T12:24:18.099+01:00  INFO 30624 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679052258099
2023-03-17T12:24:18.101+01:00  INFO 30624 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T12:24:18.108+01:00  INFO 30624 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T12:24:18.115+01:00  INFO 30624 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T12:24:18.115+01:00  INFO 30624 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T12:24:18.115+01:00  INFO 30624 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679052258115
2023-03-17T12:24:18.116+01:00  INFO 30624 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T12:24:18.127+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T12:24:18.127+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T12:24:18.128+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T12:24:18.130+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T12:24:18.130+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T12:24:18.131+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T12:24:18.131+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T12:24:18.134+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:24:18.134+01:00  INFO 30624 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.51 seconds (process running for 2.87)
2023-03-17T12:24:18.134+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:24:18.157+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-27c4f741-a230-4b06-9e9e-69fdaa49b3c4
2023-03-17T12:24:18.157+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-818934d9-bfed-4b08-b0f0-794bd21ea8a5
2023-03-17T12:24:18.158+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T12:24:18.158+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T12:24:18.159+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:24:18.159+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:26:02.187+01:00  INFO 29996 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 29996 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T12:26:02.189+01:00  INFO 29996 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T12:26:02.680+01:00  INFO 29996 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T12:26:02.701+01:00  INFO 29996 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T12:26:03.743+01:00  INFO 29996 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T12:26:03.891+01:00  INFO 29996 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T12:26:03.892+01:00  INFO 29996 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T12:26:03.892+01:00  INFO 29996 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679052363890
2023-03-17T12:26:04.149+01:00  INFO 29996 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T12:26:04.152+01:00  INFO 29996 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T12:26:04.153+01:00  INFO 29996 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T12:26:04.153+01:00  INFO 29996 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T12:26:04.157+01:00  INFO 29996 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T12:26:04.158+01:00  INFO 29996 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T12:26:04.159+01:00  INFO 29996 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T12:26:04.182+01:00  INFO 29996 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T12:26:04.216+01:00  INFO 29996 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T12:26:04.217+01:00  INFO 29996 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T12:26:04.217+01:00  INFO 29996 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679052364216
2023-03-17T12:26:04.218+01:00  INFO 29996 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T12:26:04.226+01:00  INFO 29996 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T12:26:04.232+01:00  INFO 29996 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T12:26:04.233+01:00  INFO 29996 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T12:26:04.233+01:00  INFO 29996 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679052364232
2023-03-17T12:26:04.234+01:00  INFO 29996 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T12:26:04.242+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T12:26:04.242+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T12:26:04.242+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T12:26:04.243+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T12:26:04.243+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T12:26:04.244+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T12:26:04.245+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T12:26:04.246+01:00  INFO 29996 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.482 seconds (process running for 2.887)
2023-03-17T12:26:04.247+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:26:04.247+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:26:04.268+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-d55b2cd4-3e77-4f52-8405-95fa4b4d3745
2023-03-17T12:26:04.268+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-42a00d09-af82-467e-9e73-32c426ac65b7
2023-03-17T12:26:04.269+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T12:26:04.269+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:26:04.269+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T12:26:04.269+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:26:04.271+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=29, memberId='consumer-springkafkatask33;-1-d55b2cd4-3e77-4f52-8405-95fa4b4d3745', protocol='range'}
2023-03-17T12:26:04.271+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=29, memberId='consumer-springkafkatask33;-2-42a00d09-af82-467e-9e73-32c426ac65b7', protocol='range'}
2023-03-17T12:26:04.276+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T12:26:04.276+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T12:26:04.279+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Finished assignment for group at generation 29: {consumer-springkafkatask33;-1-d55b2cd4-3e77-4f52-8405-95fa4b4d3745=Assignment(partitions=[topicTask1-0, topicTask1-1]), consumer-springkafkatask33;-2-42a00d09-af82-467e-9e73-32c426ac65b7=Assignment(partitions=[topicTask2-0])}
2023-03-17T12:26:04.284+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=29, memberId='consumer-springkafkatask33;-2-42a00d09-af82-467e-9e73-32c426ac65b7', protocol='range'}
2023-03-17T12:26:04.284+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=29, memberId='consumer-springkafkatask33;-1-d55b2cd4-3e77-4f52-8405-95fa4b4d3745', protocol='range'}
2023-03-17T12:26:04.285+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T12:26:04.285+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T12:26:04.287+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T12:26:04.287+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T12:26:04.302+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=66, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T12:26:04.302+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T12:26:04.303+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=75, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T12:26:04.305+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T12:26:04.305+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T12:26:11.472+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 75, CreateTime = 1679052370447, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e)
2023-03-17T12:26:11.480+01:00 ERROR 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : Message need be in JSON format! 
2023-03-17T12:26:11.481+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T12:26:11.481+01:00 ERROR 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T12:26:26.854+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 76, CreateTime = 1679052385843, serialized key size = -1, serialized value size = 60, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "200"})
2023-03-17T12:26:26.886+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T12:26:26.886+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=200  ]
2023-03-17T12:26:26.886+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : scheduleMessageDelete is called
2023-03-17T12:26:26.887+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=END, timestamp=700, callId=200  ]
2023-03-17T12:26:30.592+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 77, CreateTime = 1679052389575, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "301", "callId" : "200"})
2023-03-17T12:26:30.594+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T12:26:30.594+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=301, callId=200  ]
2023-03-17T12:26:30.594+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T12:26:30.595+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=200, callStartTimestamp=301, callEndTimestamp=700, callDuration=399]
2023-03-17T12:26:30.595+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 200
2023-03-17T12:26:30.595+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : ResponseMsg [callId=200, callStartTimestamp=301, callEndTimestamp=700, callDuration=399]
2023-03-17T12:26:30.595+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T12:26:30.599+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T12:26:30.784+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection org.postgresql.jdbc.PgConnection@39faa4a4
2023-03-17T12:26:30.788+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2023-03-17T12:26:30.811+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-03-17T12:26:30.820+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-03-17T12:26:30.834+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T12:26:30.834+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T12:26:30.834+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679052390834
2023-03-17T12:26:30.842+01:00  INFO 29996 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T12:26:30.843+01:00  INFO 29996 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T12:26:30.843+01:00  INFO 29996 --- [kafka-producer-network-thread | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 17 with epoch 0
2023-03-17T12:26:30.864+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : Messages from topic 2 
2023-03-17T14:47:19.926+01:00  INFO 33052 --- [main] c.s.t.SpringKafkaTaskApplicationTests    : Starting SpringKafkaTaskApplicationTests using Java 19.0.1 with PID 33052 (started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T14:47:19.929+01:00  INFO 33052 --- [main] c.s.t.SpringKafkaTaskApplicationTests    : No active profile set, falling back to 1 default profile: "default"
2023-03-17T14:47:20.321+01:00  INFO 33052 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T14:47:20.335+01:00  INFO 33052 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T14:47:21.353+01:00  INFO 33052 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T14:47:21.521+01:00  INFO 33052 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T14:47:21.521+01:00  INFO 33052 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T14:47:21.522+01:00  INFO 33052 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679060841520
2023-03-17T14:47:21.541+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:21.543+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:21.654+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:21.654+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:21.876+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:21.876+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:22.097+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:22.097+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:22.533+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:22.533+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:23.407+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:23.408+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:24.510+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:24.510+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:25.513+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:25.514+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:26.722+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:26.722+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:27.596+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:27.598+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:28.572+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:28.573+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:29.778+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:29.778+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:30.868+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:30.869+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:31.741+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:31.741+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:32.946+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:32.947+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:34.038+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:34.039+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:35.131+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:35.131+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:36.237+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:36.238+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:37.437+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:37.438+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:38.522+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:38.525+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:39.398+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:39.398+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:40.599+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:40.600+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:41.579+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:41.580+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:42.799+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:42.800+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:43.782+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:43.783+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:44.988+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:44.989+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:46.193+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:46.193+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:47.069+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:47.070+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:48.068+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:48.069+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:49.048+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:49.049+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:50.252+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:50.252+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:51.345+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:51.345+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:51.531+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] o.a.k.c.a.i.AdminMetadataManager         : [AdminClient clientId=adminclient-1] Metadata update failed

org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment. Call: fetchMetadata

2023-03-17T14:47:51.531+01:00 ERROR 33052 --- [main] o.springframework.kafka.core.KafkaAdmin  : Could not configure topics

java.util.concurrent.TimeoutException: null
	at java.base/java.util.concurrent.CompletableFuture.timedGet(CompletableFuture.java:1960) ~[na:na]
	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2095) ~[na:na]
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:180) ~[kafka-clients-3.3.1.jar:na]
	at org.springframework.kafka.core.KafkaAdmin.initialize(KafkaAdmin.java:205) ~[spring-kafka-3.0.1.jar:3.0.1]
	at org.springframework.kafka.core.KafkaAdmin.afterSingletonsInstantiated(KafkaAdmin.java:174) ~[spring-kafka-3.0.1.jar:3.0.1]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:972) ~[spring-beans-6.0.3.jar:6.0.3]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:915) ~[spring-context-6.0.3.jar:6.0.3]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:584) ~[spring-context-6.0.3.jar:6.0.3]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:730) ~[spring-boot-3.0.1.jar:3.0.1]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:432) ~[spring-boot-3.0.1.jar:3.0.1]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:308) ~[spring-boot-3.0.1.jar:3.0.1]
	at org.springframework.boot.test.context.SpringBootContextLoader.lambda$loadContext$3(SpringBootContextLoader.java:137) ~[spring-boot-test-3.0.1.jar:3.0.1]
	at org.springframework.util.function.ThrowingSupplier.get(ThrowingSupplier.java:59) ~[spring-core-6.0.3.jar:6.0.3]
	at org.springframework.util.function.ThrowingSupplier.get(ThrowingSupplier.java:47) ~[spring-core-6.0.3.jar:6.0.3]
	at org.springframework.boot.SpringApplication.withHook(SpringApplication.java:1386) ~[spring-boot-3.0.1.jar:3.0.1]
	at org.springframework.boot.test.context.SpringBootContextLoader$ContextLoaderHook.run(SpringBootContextLoader.java:543) ~[spring-boot-test-3.0.1.jar:3.0.1]
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:137) ~[spring-boot-test-3.0.1.jar:3.0.1]
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:108) ~[spring-boot-test-3.0.1.jar:3.0.1]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:184) ~[spring-test-6.0.3.jar:6.0.3]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:118) ~[spring-test-6.0.3.jar:6.0.3]
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:127) ~[spring-test-6.0.3.jar:6.0.3]
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:141) ~[spring-test-6.0.3.jar:6.0.3]
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:97) ~[spring-test-6.0.3.jar:6.0.3]
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:241) ~[spring-test-6.0.3.jar:6.0.3]
	at org.springframework.test.context.junit.jupiter.SpringExtension.postProcessTestInstance(SpringExtension.java:138) ~[spring-test-6.0.3.jar:6.0.3]
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeTestInstancePostProcessors$10(ClassBasedTestDescriptor.java:377) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.executeAndMaskThrowable(ClassBasedTestDescriptor.java:382) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeTestInstancePostProcessors$11(ClassBasedTestDescriptor.java:377) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197) ~[na:na]
	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:179) ~[na:na]
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1625) ~[na:na]
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509) ~[na:na]
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499) ~[na:na]
	at java.base/java.util.stream.StreamSpliterators$WrappingSpliterator.forEachRemaining(StreamSpliterators.java:310) ~[na:na]
	at java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:735) ~[na:na]
	at java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734) ~[na:na]
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762) ~[na:na]
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeTestInstancePostProcessors(ClassBasedTestDescriptor.java:376) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$instantiateAndPostProcessTestInstance$6(ClassBasedTestDescriptor.java:289) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.instantiateAndPostProcessTestInstance(ClassBasedTestDescriptor.java:288) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$4(ClassBasedTestDescriptor.java:278) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]
	at java.base/java.util.Optional.orElseGet(Optional.java:364) ~[na:na]
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$5(ClassBasedTestDescriptor.java:277) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]
	at org.junit.jupiter.engine.execution.TestInstancesProvider.getTestInstances(TestInstancesProvider.java:31) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$prepare$0(TestMethodTestDescriptor.java:105) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.prepare(TestMethodTestDescriptor.java:104) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.prepare(TestMethodTestDescriptor.java:68) ~[junit-jupiter-engine-5.9.1.jar:5.9.1]
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$prepare$2(NodeTestTask.java:123) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.prepare(NodeTestTask.java:123) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:90) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511) ~[na:na]
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511) ~[na:na]
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54) ~[junit-platform-engine-1.9.1.jar:1.9.1]
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:147) ~[junit-platform-launcher-1.9.1.jar:1.9.1]
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:127) ~[junit-platform-launcher-1.9.1.jar:1.9.1]
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:90) ~[junit-platform-launcher-1.9.1.jar:1.9.1]
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:55) ~[junit-platform-launcher-1.9.1.jar:1.9.1]
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:102) ~[junit-platform-launcher-1.9.1.jar:1.9.1]
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:54) ~[junit-platform-launcher-1.9.1.jar:1.9.1]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114) ~[junit-platform-launcher-1.9.1.jar:1.9.1]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86) ~[junit-platform-launcher-1.9.1.jar:1.9.1]
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86) ~[junit-platform-launcher-1.9.1.jar:1.9.1]
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53) ~[junit-platform-launcher-1.9.1.jar:1.9.1]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150) ~[surefire-junit-platform-2.22.2.jar:2.22.2]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124) ~[surefire-junit-platform-2.22.2.jar:2.22.2]
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384) ~[surefire-booter-2.22.2.jar:2.22.2]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345) ~[surefire-booter-2.22.2.jar:2.22.2]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126) ~[surefire-booter-2.22.2.jar:2.22.2]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418) ~[surefire-booter-2.22.2.jar:2.22.2]

2023-03-17T14:47:52.401+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:52.401+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:53.401+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:53.402+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:54.484+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:54.485+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:55.356+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:55.356+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:56.462+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:56.463+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:57.678+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:57.679+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:58.550+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:58.551+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:47:59.533+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:47:59.534+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:00.623+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-17T14:48:00.624+01:00  WARN 33052 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:01.545+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] o.a.k.clients.admin.KafkaAdminClient     : [AdminClient clientId=adminclient-1] Forcing a hard I/O thread shutdown. Requests in progress will be aborted.
2023-03-17T14:48:01.546+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T14:48:01.547+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] o.a.k.c.a.i.AdminMetadataManager         : [AdminClient clientId=adminclient-1] Metadata update failed

org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

2023-03-17T14:48:01.547+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] o.a.k.clients.admin.KafkaAdminClient     : [AdminClient clientId=adminclient-1] Timed out 2 remaining operation(s) during close.
2023-03-17T14:48:01.551+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T14:48:01.552+01:00  INFO 33052 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T14:48:01.553+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T14:48:01.554+01:00  INFO 33052 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T14:48:01.554+01:00  INFO 33052 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T14:48:01.555+01:00  INFO 33052 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T14:48:01.578+01:00  INFO 33052 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T14:48:01.617+01:00  INFO 33052 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T14:48:01.618+01:00  INFO 33052 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T14:48:01.618+01:00  INFO 33052 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679060881617
2023-03-17T14:48:01.620+01:00  INFO 33052 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T14:48:01.627+01:00  INFO 33052 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T14:48:01.634+01:00  INFO 33052 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T14:48:01.635+01:00  INFO 33052 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T14:48:01.636+01:00  INFO 33052 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679060881634
2023-03-17T14:48:01.637+01:00  INFO 33052 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T14:48:01.648+01:00  INFO 33052 --- [main] c.s.t.SpringKafkaTaskApplicationTests    : Started SpringKafkaTaskApplicationTests in 42.007 seconds (process running for 43.505)
2023-03-17T14:48:01.861+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:01.861+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:01.862+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:01.862+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:01.863+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:01.863+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:01.975+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:01.976+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:01.976+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:01.990+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:01.991+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:01.991+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:02.085+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:02.085+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:02.086+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:02.161+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:02.162+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:02.163+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:02.332+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:02.333+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:02.334+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:02.411+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:02.411+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:02.412+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:02.769+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:02.770+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:02.771+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:02.815+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:02.816+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:02.817+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:03.503+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:03.504+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:03.505+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:03.816+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:03.817+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:03.817+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:04.552+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:04.553+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:04.554+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:04.816+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:04.817+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:04.817+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:05.657+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:05.658+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:05.658+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:06.052+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:06.052+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:06.053+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:06.724+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:06.725+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:06.726+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:06.976+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:06.977+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:06.978+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:07.646+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:07.647+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:07.647+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:08.084+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:08.085+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:08.085+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:08.816+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:08.817+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:08.818+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:09.254+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:09.255+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:09.256+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:09.738+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:09.739+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:09.740+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:10.361+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:10.362+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:10.363+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:10.736+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:10.736+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:10.737+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:11.237+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:11.237+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:11.237+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:11.718+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:11.719+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:11.720+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:12.284+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:12.284+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:12.285+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:12.892+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:12.892+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:12.893+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:13.468+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:13.469+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:13.470+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:13.816+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:13.816+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:13.817+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:14.329+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:14.329+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:14.330+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:14.922+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:14.923+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:14.923+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:15.500+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:15.501+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:15.502+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:15.923+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:15.924+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:15.925+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:16.657+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:16.657+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:16.658+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:16.983+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:16.984+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:16.984+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:17.639+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:17.640+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:17.641+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:48:18.217+01:00  INFO 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T14:48:18.218+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2023-03-17T14:48:18.219+01:00  WARN 33052 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2023-03-17T14:54:42.496+01:00  INFO 24372 --- [main] c.s.t.SpringKafkaTaskApplicationTests    : Starting SpringKafkaTaskApplicationTests using Java 19.0.1 with PID 24372 (started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T14:54:42.498+01:00  INFO 24372 --- [main] c.s.t.SpringKafkaTaskApplicationTests    : No active profile set, falling back to 1 default profile: "default"
2023-03-17T14:54:42.889+01:00  INFO 24372 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T14:54:42.907+01:00  INFO 24372 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T14:54:43.963+01:00  INFO 24372 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T14:54:44.126+01:00  INFO 24372 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T14:54:44.126+01:00  INFO 24372 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T14:54:44.127+01:00  INFO 24372 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679061284125
2023-03-17T14:54:44.509+01:00  INFO 24372 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T14:54:44.513+01:00  INFO 24372 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T14:54:44.513+01:00  INFO 24372 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T14:54:44.513+01:00  INFO 24372 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T14:54:44.518+01:00  INFO 24372 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T14:54:44.519+01:00  INFO 24372 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T14:54:44.519+01:00  INFO 24372 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T14:54:44.543+01:00  INFO 24372 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T14:54:44.589+01:00  INFO 24372 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T14:54:44.590+01:00  INFO 24372 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T14:54:44.590+01:00  INFO 24372 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679061284589
2023-03-17T14:54:44.593+01:00  INFO 24372 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T14:54:44.604+01:00  INFO 24372 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T14:54:44.612+01:00  INFO 24372 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T14:54:44.613+01:00  INFO 24372 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T14:54:44.614+01:00  INFO 24372 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679061284612
2023-03-17T14:54:44.615+01:00  INFO 24372 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T14:54:44.633+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T14:54:44.633+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T14:54:44.634+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T14:54:44.635+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T14:54:44.635+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T14:54:44.637+01:00  INFO 24372 --- [main] c.s.t.SpringKafkaTaskApplicationTests    : Started SpringKafkaTaskApplicationTests in 2.429 seconds (process running for 3.92)
2023-03-17T14:54:44.638+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T14:54:44.638+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T14:54:44.642+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T14:54:44.642+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T14:54:44.687+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-5c89bd9c-928e-4a0a-b671-e377cfab64a7
2023-03-17T14:54:44.687+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T14:54:44.687+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T14:54:44.690+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-f9eab4b9-655b-40b5-be2f-98be29d2e1b2
2023-03-17T14:54:44.691+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T14:54:44.694+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T14:54:44.704+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Member consumer-springkafkatask33;-2-5c89bd9c-928e-4a0a-b671-e377cfab64a7 sending LeaveGroup request to coordinator host.docker.internal:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-03-17T14:54:44.705+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-03-17T14:54:44.704+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Member consumer-springkafkatask33;-1-f9eab4b9-655b-40b5-be2f-98be29d2e1b2 sending LeaveGroup request to coordinator host.docker.internal:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-03-17T14:54:44.705+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: consumer pro-actively leaving the group
2023-03-17T14:54:44.706+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Unsubscribed all topics or patterns and assigned partitions
2023-03-17T14:54:44.706+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-03-17T14:54:44.707+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: consumer pro-actively leaving the group
2023-03-17T14:54:44.707+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-03-17T14:54:44.707+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: consumer pro-actively leaving the group
2023-03-17T14:54:44.707+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Unsubscribed all topics or patterns and assigned partitions
2023-03-17T14:54:44.713+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-03-17T14:54:44.714+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: consumer pro-actively leaving the group
2023-03-17T14:54:44.734+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T14:54:44.734+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T14:54:44.734+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T14:54:44.737+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-springkafkatask33;-1 unregistered
2023-03-17T14:54:44.738+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: Consumer stopped
2023-03-17T14:54:44.773+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T14:54:44.774+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T14:54:44.774+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T14:54:44.776+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-springkafkatask33;-2 unregistered
2023-03-17T14:54:44.776+01:00  INFO 24372 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: Consumer stopped
2023-03-17T14:54:44.777+01:00  INFO 24372 --- [SpringApplicationShutdownHook] o.s.i.endpoint.EventDrivenConsumer       : Removing {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T14:54:44.778+01:00  INFO 24372 --- [SpringApplicationShutdownHook] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 0 subscriber(s).
2023-03-17T14:54:44.780+01:00  INFO 24372 --- [SpringApplicationShutdownHook] o.s.i.endpoint.EventDrivenConsumer       : stopped bean '_org.springframework.integration.errorLogger'
2023-03-17T14:56:43.505+01:00  INFO 35356 --- [main] c.s.t.SpringKafkaTaskApplicationTests    : Starting SpringKafkaTaskApplicationTests using Java 17.0.4.1 with PID 35356 (started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T14:56:43.507+01:00  INFO 35356 --- [main] c.s.t.SpringKafkaTaskApplicationTests    : No active profile set, falling back to 1 default profile: "default"
2023-03-17T14:56:43.976+01:00  INFO 35356 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T14:56:43.994+01:00  INFO 35356 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T14:56:45.001+01:00  INFO 35356 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T14:56:45.179+01:00  INFO 35356 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T14:56:45.181+01:00  INFO 35356 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T14:56:45.181+01:00  INFO 35356 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679061405178
2023-03-17T14:56:45.446+01:00  INFO 35356 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T14:56:45.450+01:00  INFO 35356 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T14:56:45.450+01:00  INFO 35356 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T14:56:45.451+01:00  INFO 35356 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T14:56:45.455+01:00  INFO 35356 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T14:56:45.456+01:00  INFO 35356 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T14:56:45.457+01:00  INFO 35356 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T14:56:45.478+01:00  INFO 35356 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T14:56:45.518+01:00  INFO 35356 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T14:56:45.519+01:00  INFO 35356 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T14:56:45.519+01:00  INFO 35356 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679061405518
2023-03-17T14:56:45.520+01:00  INFO 35356 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T14:56:45.527+01:00  INFO 35356 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T14:56:45.532+01:00  INFO 35356 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T14:56:45.533+01:00  INFO 35356 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T14:56:45.533+01:00  INFO 35356 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679061405532
2023-03-17T14:56:45.534+01:00  INFO 35356 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T14:56:45.543+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T14:56:45.543+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T14:56:45.546+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T14:56:45.549+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T14:56:45.550+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T14:56:45.550+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T14:56:45.551+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T14:56:45.553+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T14:56:45.553+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T14:56:45.554+01:00  INFO 35356 --- [main] c.s.t.SpringKafkaTaskApplicationTests    : Started SpringKafkaTaskApplicationTests in 2.395 seconds (process running for 3.348)
2023-03-17T14:56:45.582+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-9211ef4c-cf0e-4bd3-8b44-f99b269c65c7
2023-03-17T14:56:45.583+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T14:56:45.583+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T14:56:45.584+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-a168cd19-73fd-4f3b-b71b-7bb6062741bf
2023-03-17T14:56:45.585+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T14:56:45.585+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T14:56:45.590+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=33, memberId='consumer-springkafkatask33;-2-9211ef4c-cf0e-4bd3-8b44-f99b269c65c7', protocol='range'}
2023-03-17T14:56:45.593+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Finished assignment for group at generation 33: {consumer-springkafkatask33;-2-9211ef4c-cf0e-4bd3-8b44-f99b269c65c7=Assignment(partitions=[topicTask2-0])}
2023-03-17T14:56:45.608+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=33, memberId='consumer-springkafkatask33;-2-9211ef4c-cf0e-4bd3-8b44-f99b269c65c7', protocol='range'}
2023-03-17T14:56:45.608+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting generation due to: encountered REBALANCE_IN_PROGRESS from SYNC_GROUP response
2023-03-17T14:56:45.608+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: encountered REBALANCE_IN_PROGRESS from SYNC_GROUP response
2023-03-17T14:56:45.609+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group is rebalancing, so a rejoin is needed.' (RebalanceInProgressException)
2023-03-17T14:56:45.609+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T14:56:45.614+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=34, memberId='consumer-springkafkatask33;-1-a168cd19-73fd-4f3b-b71b-7bb6062741bf', protocol='range'}
2023-03-17T14:56:45.615+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=34, memberId='consumer-springkafkatask33;-2-9211ef4c-cf0e-4bd3-8b44-f99b269c65c7', protocol='range'}
2023-03-17T14:56:45.624+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T14:56:45.625+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T14:56:45.625+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Finished assignment for group at generation 34: {consumer-springkafkatask33;-1-a168cd19-73fd-4f3b-b71b-7bb6062741bf=Assignment(partitions=[topicTask1-0, topicTask1-1]), consumer-springkafkatask33;-2-9211ef4c-cf0e-4bd3-8b44-f99b269c65c7=Assignment(partitions=[topicTask2-0])}
2023-03-17T14:56:45.637+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=34, memberId='consumer-springkafkatask33;-1-a168cd19-73fd-4f3b-b71b-7bb6062741bf', protocol='range'}
2023-03-17T14:56:45.637+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=34, memberId='consumer-springkafkatask33;-2-9211ef4c-cf0e-4bd3-8b44-f99b269c65c7', protocol='range'}
2023-03-17T14:56:45.638+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T14:56:45.638+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T14:56:45.644+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T14:56:45.644+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T14:56:45.668+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T14:56:45.668+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=67, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T14:56:45.669+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=78, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T14:56:45.672+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T14:56:45.672+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T14:56:46.098+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Revoke previously assigned partitions topicTask2-0
2023-03-17T14:56:46.098+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Revoke previously assigned partitions topicTask1-0, topicTask1-1
2023-03-17T14:56:46.099+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions revoked: [topicTask1-0, topicTask1-1]
2023-03-17T14:56:46.099+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions revoked: [topicTask2-0]
2023-03-17T14:56:46.100+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Member consumer-springkafkatask33;-2-9211ef4c-cf0e-4bd3-8b44-f99b269c65c7 sending LeaveGroup request to coordinator host.docker.internal:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-03-17T14:56:46.100+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Member consumer-springkafkatask33;-1-a168cd19-73fd-4f3b-b71b-7bb6062741bf sending LeaveGroup request to coordinator host.docker.internal:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-03-17T14:56:46.101+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-03-17T14:56:46.101+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-03-17T14:56:46.101+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: consumer pro-actively leaving the group
2023-03-17T14:56:46.101+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: consumer pro-actively leaving the group
2023-03-17T14:56:46.101+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Unsubscribed all topics or patterns and assigned partitions
2023-03-17T14:56:46.101+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Unsubscribed all topics or patterns and assigned partitions
2023-03-17T14:56:46.102+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-03-17T14:56:46.102+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-03-17T14:56:46.102+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: consumer pro-actively leaving the group
2023-03-17T14:56:46.102+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: consumer pro-actively leaving the group
2023-03-17T14:56:46.107+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T14:56:46.107+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T14:56:46.107+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T14:56:46.108+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T14:56:46.109+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T14:56:46.110+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T14:56:46.110+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-springkafkatask33;-2 unregistered
2023-03-17T14:56:46.112+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: Consumer stopped
2023-03-17T14:56:46.112+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-springkafkatask33;-1 unregistered
2023-03-17T14:56:46.112+01:00  INFO 35356 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: Consumer stopped
2023-03-17T14:56:46.114+01:00  INFO 35356 --- [SpringApplicationShutdownHook] o.s.i.endpoint.EventDrivenConsumer       : Removing {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T14:56:46.115+01:00  INFO 35356 --- [SpringApplicationShutdownHook] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 0 subscriber(s).
2023-03-17T14:56:46.115+01:00  INFO 35356 --- [SpringApplicationShutdownHook] o.s.i.endpoint.EventDrivenConsumer       : stopped bean '_org.springframework.integration.errorLogger'
2023-03-17T14:56:51.918+01:00  INFO 33864 --- [main] c.s.t.SpringKafkaTaskApplicationTests    : Starting SpringKafkaTaskApplicationTests using Java 17.0.4.1 with PID 33864 (started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T14:56:51.919+01:00  INFO 33864 --- [main] c.s.t.SpringKafkaTaskApplicationTests    : No active profile set, falling back to 1 default profile: "default"
2023-03-17T14:56:52.331+01:00  INFO 33864 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T14:56:52.352+01:00  INFO 33864 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T14:56:53.355+01:00  INFO 33864 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T14:56:53.498+01:00  INFO 33864 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T14:56:53.500+01:00  INFO 33864 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T14:56:53.500+01:00  INFO 33864 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679061413497
2023-03-17T14:56:53.761+01:00  INFO 33864 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T14:56:53.766+01:00  INFO 33864 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T14:56:53.766+01:00  INFO 33864 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T14:56:53.766+01:00  INFO 33864 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T14:56:53.771+01:00  INFO 33864 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T14:56:53.773+01:00  INFO 33864 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T14:56:53.773+01:00  INFO 33864 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T14:56:53.798+01:00  INFO 33864 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T14:56:53.852+01:00  INFO 33864 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T14:56:53.852+01:00  INFO 33864 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T14:56:53.852+01:00  INFO 33864 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679061413852
2023-03-17T14:56:53.854+01:00  INFO 33864 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T14:56:53.863+01:00  INFO 33864 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T14:56:53.870+01:00  INFO 33864 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T14:56:53.870+01:00  INFO 33864 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T14:56:53.871+01:00  INFO 33864 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679061413870
2023-03-17T14:56:53.872+01:00  INFO 33864 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T14:56:53.882+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T14:56:53.882+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T14:56:53.883+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T14:56:53.884+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T14:56:53.884+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T14:56:53.885+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T14:56:53.885+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T14:56:53.891+01:00  INFO 33864 --- [main] c.s.t.SpringKafkaTaskApplicationTests    : Started SpringKafkaTaskApplicationTests in 2.316 seconds (process running for 3.224)
2023-03-17T14:56:53.894+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T14:56:53.894+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T14:56:53.920+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-ffab855b-72c7-4a58-82cb-bf50c9114ae2
2023-03-17T14:56:53.920+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-db9d7bb6-cfb1-4894-bfe4-0b54c39f4b54
2023-03-17T14:56:53.921+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T14:56:53.921+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T14:56:53.921+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T14:56:53.921+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T14:56:53.925+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=36, memberId='consumer-springkafkatask33;-1-db9d7bb6-cfb1-4894-bfe4-0b54c39f4b54', protocol='range'}
2023-03-17T14:56:53.925+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=36, memberId='consumer-springkafkatask33;-2-ffab855b-72c7-4a58-82cb-bf50c9114ae2', protocol='range'}
2023-03-17T14:56:53.931+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T14:56:53.931+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T14:56:53.934+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Finished assignment for group at generation 36: {consumer-springkafkatask33;-2-ffab855b-72c7-4a58-82cb-bf50c9114ae2=Assignment(partitions=[topicTask2-0]), consumer-springkafkatask33;-1-db9d7bb6-cfb1-4894-bfe4-0b54c39f4b54=Assignment(partitions=[topicTask1-0, topicTask1-1])}
2023-03-17T14:56:53.941+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=36, memberId='consumer-springkafkatask33;-2-ffab855b-72c7-4a58-82cb-bf50c9114ae2', protocol='range'}
2023-03-17T14:56:53.941+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=36, memberId='consumer-springkafkatask33;-1-db9d7bb6-cfb1-4894-bfe4-0b54c39f4b54', protocol='range'}
2023-03-17T14:56:53.942+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T14:56:53.942+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T14:56:53.944+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T14:56:53.944+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T14:56:53.956+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T14:56:53.956+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=67, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T14:56:53.957+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=78, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T14:56:53.958+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T14:56:53.958+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T14:56:54.377+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Revoke previously assigned partitions topicTask2-0
2023-03-17T14:56:54.377+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Revoke previously assigned partitions topicTask1-0, topicTask1-1
2023-03-17T14:56:54.379+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions revoked: [topicTask1-0, topicTask1-1]
2023-03-17T14:56:54.379+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions revoked: [topicTask2-0]
2023-03-17T14:56:54.380+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Member consumer-springkafkatask33;-1-db9d7bb6-cfb1-4894-bfe4-0b54c39f4b54 sending LeaveGroup request to coordinator host.docker.internal:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-03-17T14:56:54.380+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Member consumer-springkafkatask33;-2-ffab855b-72c7-4a58-82cb-bf50c9114ae2 sending LeaveGroup request to coordinator host.docker.internal:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-03-17T14:56:54.381+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-03-17T14:56:54.381+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-03-17T14:56:54.382+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: consumer pro-actively leaving the group
2023-03-17T14:56:54.382+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: consumer pro-actively leaving the group
2023-03-17T14:56:54.382+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Unsubscribed all topics or patterns and assigned partitions
2023-03-17T14:56:54.382+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Unsubscribed all topics or patterns and assigned partitions
2023-03-17T14:56:54.382+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-03-17T14:56:54.382+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-03-17T14:56:54.382+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: consumer pro-actively leaving the group
2023-03-17T14:56:54.382+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: consumer pro-actively leaving the group
2023-03-17T14:56:54.387+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T14:56:54.388+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T14:56:54.388+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T14:56:54.388+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T14:56:54.388+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T14:56:54.389+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T14:56:54.392+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-springkafkatask33;-1 unregistered
2023-03-17T14:56:54.393+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-springkafkatask33;-2 unregistered
2023-03-17T14:56:54.394+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: Consumer stopped
2023-03-17T14:56:54.394+01:00  INFO 33864 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: Consumer stopped
2023-03-17T14:56:54.396+01:00  INFO 33864 --- [SpringApplicationShutdownHook] o.s.i.endpoint.EventDrivenConsumer       : Removing {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T14:56:54.396+01:00  INFO 33864 --- [SpringApplicationShutdownHook] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 0 subscriber(s).
2023-03-17T14:56:54.397+01:00  INFO 33864 --- [SpringApplicationShutdownHook] o.s.i.endpoint.EventDrivenConsumer       : stopped bean '_org.springframework.integration.errorLogger'
2023-03-17T14:57:17.647+01:00  INFO 31656 --- [main] c.s.t.SpringKafkaTaskApplicationTests    : Starting SpringKafkaTaskApplicationTests using Java 19.0.1 with PID 31656 (started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T14:57:17.649+01:00  INFO 31656 --- [main] c.s.t.SpringKafkaTaskApplicationTests    : No active profile set, falling back to 1 default profile: "default"
2023-03-17T14:57:18.094+01:00  INFO 31656 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T14:57:18.113+01:00  INFO 31656 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T14:57:19.123+01:00  INFO 31656 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T14:57:19.303+01:00  INFO 31656 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T14:57:19.304+01:00  INFO 31656 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T14:57:19.305+01:00  INFO 31656 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679061439302
2023-03-17T14:57:19.583+01:00  INFO 31656 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T14:57:19.587+01:00  INFO 31656 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T14:57:19.588+01:00  INFO 31656 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T14:57:19.589+01:00  INFO 31656 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T14:57:19.593+01:00  INFO 31656 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T14:57:19.593+01:00  INFO 31656 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T14:57:19.594+01:00  INFO 31656 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T14:57:19.616+01:00  INFO 31656 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T14:57:19.654+01:00  INFO 31656 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T14:57:19.654+01:00  INFO 31656 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T14:57:19.655+01:00  INFO 31656 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679061439654
2023-03-17T14:57:19.656+01:00  INFO 31656 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T14:57:19.663+01:00  INFO 31656 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T14:57:19.669+01:00  INFO 31656 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T14:57:19.669+01:00  INFO 31656 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T14:57:19.670+01:00  INFO 31656 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679061439669
2023-03-17T14:57:19.670+01:00  INFO 31656 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T14:57:19.676+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T14:57:19.676+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T14:57:19.679+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T14:57:19.679+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T14:57:19.680+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T14:57:19.681+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T14:57:19.682+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T14:57:19.683+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T14:57:19.684+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T14:57:19.686+01:00  INFO 31656 --- [main] c.s.t.SpringKafkaTaskApplicationTests    : Started SpringKafkaTaskApplicationTests in 2.321 seconds (process running for 3.231)
2023-03-17T14:57:19.714+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-f2d23459-f7fc-413a-9a09-cb24f9cad8ff
2023-03-17T14:57:19.714+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-49723815-2b29-48f8-a93c-966e78c30249
2023-03-17T14:57:19.715+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T14:57:19.715+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T14:57:19.716+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T14:57:19.716+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T14:57:19.721+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=38, memberId='consumer-springkafkatask33;-1-49723815-2b29-48f8-a93c-966e78c30249', protocol='range'}
2023-03-17T14:57:19.721+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=38, memberId='consumer-springkafkatask33;-2-f2d23459-f7fc-413a-9a09-cb24f9cad8ff', protocol='range'}
2023-03-17T14:57:19.730+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T14:57:19.733+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Finished assignment for group at generation 38: {consumer-springkafkatask33;-1-49723815-2b29-48f8-a93c-966e78c30249=Assignment(partitions=[topicTask1-0, topicTask1-1]), consumer-springkafkatask33;-2-f2d23459-f7fc-413a-9a09-cb24f9cad8ff=Assignment(partitions=[topicTask2-0])}
2023-03-17T14:57:19.741+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=38, memberId='consumer-springkafkatask33;-1-49723815-2b29-48f8-a93c-966e78c30249', protocol='range'}
2023-03-17T14:57:19.741+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=38, memberId='consumer-springkafkatask33;-2-f2d23459-f7fc-413a-9a09-cb24f9cad8ff', protocol='range'}
2023-03-17T14:57:19.742+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T14:57:19.742+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T14:57:19.747+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T14:57:19.747+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T14:57:19.761+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=67, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T14:57:19.761+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T14:57:19.762+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=78, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T14:57:19.764+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T14:57:19.764+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T14:57:20.207+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Revoke previously assigned partitions topicTask2-0
2023-03-17T14:57:20.207+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Revoke previously assigned partitions topicTask1-0, topicTask1-1
2023-03-17T14:57:20.208+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions revoked: [topicTask2-0]
2023-03-17T14:57:20.209+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions revoked: [topicTask1-0, topicTask1-1]
2023-03-17T14:57:20.209+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Member consumer-springkafkatask33;-2-f2d23459-f7fc-413a-9a09-cb24f9cad8ff sending LeaveGroup request to coordinator host.docker.internal:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-03-17T14:57:20.211+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-03-17T14:57:20.211+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: consumer pro-actively leaving the group
2023-03-17T14:57:20.211+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Member consumer-springkafkatask33;-1-49723815-2b29-48f8-a93c-966e78c30249 sending LeaveGroup request to coordinator host.docker.internal:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-03-17T14:57:20.212+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Unsubscribed all topics or patterns and assigned partitions
2023-03-17T14:57:20.212+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-03-17T14:57:20.212+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-03-17T14:57:20.213+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: consumer pro-actively leaving the group
2023-03-17T14:57:20.214+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: consumer pro-actively leaving the group
2023-03-17T14:57:20.214+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Unsubscribed all topics or patterns and assigned partitions
2023-03-17T14:57:20.214+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-03-17T14:57:20.215+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: consumer pro-actively leaving the group
2023-03-17T14:57:20.220+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T14:57:20.220+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T14:57:20.221+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T14:57:20.223+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-springkafkatask33;-2 unregistered
2023-03-17T14:57:20.225+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: Consumer stopped
2023-03-17T14:57:20.226+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T14:57:20.227+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T14:57:20.228+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T14:57:20.232+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-springkafkatask33;-1 unregistered
2023-03-17T14:57:20.233+01:00  INFO 31656 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: Consumer stopped
2023-03-17T14:57:20.235+01:00  INFO 31656 --- [SpringApplicationShutdownHook] o.s.i.endpoint.EventDrivenConsumer       : Removing {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T14:57:20.237+01:00  INFO 31656 --- [SpringApplicationShutdownHook] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 0 subscriber(s).
2023-03-17T14:57:20.238+01:00  INFO 31656 --- [SpringApplicationShutdownHook] o.s.i.endpoint.EventDrivenConsumer       : stopped bean '_org.springframework.integration.errorLogger'
2023-03-17T17:31:12.985+01:00  INFO 23412 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 23412 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T17:31:12.993+01:00  INFO 23412 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T17:31:14.140+01:00  INFO 23412 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T17:31:14.174+01:00  INFO 23412 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T17:31:16.045+01:00  INFO 23412 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T17:31:16.353+01:00  INFO 23412 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T17:31:16.355+01:00  INFO 23412 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T17:31:16.355+01:00  INFO 23412 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679070676351
2023-03-17T17:31:16.952+01:00  INFO 23412 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T17:31:16.968+01:00  INFO 23412 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T17:31:16.969+01:00  INFO 23412 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T17:31:16.969+01:00  INFO 23412 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T17:31:16.976+01:00  INFO 23412 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T17:31:16.977+01:00  INFO 23412 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T17:31:16.978+01:00  INFO 23412 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T17:31:17.049+01:00  INFO 23412 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T17:31:17.143+01:00  INFO 23412 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T17:31:17.143+01:00  INFO 23412 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T17:31:17.143+01:00  INFO 23412 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679070677143
2023-03-17T17:31:17.147+01:00  INFO 23412 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T17:31:17.163+01:00  INFO 23412 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T17:31:17.178+01:00  INFO 23412 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T17:31:17.179+01:00  INFO 23412 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T17:31:17.180+01:00  INFO 23412 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679070677178
2023-03-17T17:31:17.184+01:00  INFO 23412 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T17:31:17.195+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T17:31:17.198+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T17:31:17.199+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T17:31:17.201+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T17:31:17.205+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T17:31:17.213+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T17:31:17.216+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T17:31:17.217+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T17:31:17.219+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T17:31:17.220+01:00  INFO 23412 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 4.966 seconds (process running for 5.542)
2023-03-17T17:31:17.250+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-27c3767a-9f48-4ce5-a41e-9c7a08306f55
2023-03-17T17:31:17.252+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T17:31:17.252+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T17:31:17.252+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-84f5bfc7-068c-4a51-abf2-5f3ff7ba500c
2023-03-17T17:31:17.253+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T17:31:17.253+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T17:31:17.258+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=40, memberId='consumer-springkafkatask33;-1-27c3767a-9f48-4ce5-a41e-9c7a08306f55', protocol='range'}
2023-03-17T17:31:17.258+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=40, memberId='consumer-springkafkatask33;-2-84f5bfc7-068c-4a51-abf2-5f3ff7ba500c', protocol='range'}
2023-03-17T17:31:17.266+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T17:31:17.271+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Finished assignment for group at generation 40: {consumer-springkafkatask33;-1-27c3767a-9f48-4ce5-a41e-9c7a08306f55=Assignment(partitions=[topicTask1-0, topicTask1-1]), consumer-springkafkatask33;-2-84f5bfc7-068c-4a51-abf2-5f3ff7ba500c=Assignment(partitions=[topicTask2-0])}
2023-03-17T17:31:17.280+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=40, memberId='consumer-springkafkatask33;-2-84f5bfc7-068c-4a51-abf2-5f3ff7ba500c', protocol='range'}
2023-03-17T17:31:17.281+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=40, memberId='consumer-springkafkatask33;-1-27c3767a-9f48-4ce5-a41e-9c7a08306f55', protocol='range'}
2023-03-17T17:31:17.282+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T17:31:17.282+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T17:31:17.286+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T17:31:17.286+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T17:31:17.330+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=67, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T17:31:17.330+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T17:31:17.331+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=78, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T17:31:17.334+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T17:31:17.334+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T17:31:17.427+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 0, leaderEpoch = 0, offset = 11, CreateTime = 1679070637715, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e)
2023-03-17T17:31:17.440+01:00 ERROR 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : Message need be in JSON format! 
2023-03-17T17:31:17.441+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 0, leaderEpoch = 0, offset = 12, CreateTime = 1679070645278, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = w)
2023-03-17T17:31:17.441+01:00 ERROR 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : Message need be in JSON format! 
2023-03-17T17:32:49.156+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 0, leaderEpoch = 0, offset = 13, CreateTime = 1679070768147, serialized key size = -1, serialized value size = 61, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "50", "callId" : "100"})
2023-03-17T17:32:49.218+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T17:32:49.219+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=50, callId=100  ]
2023-03-17T17:32:49.220+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=START, timestamp=50, callId=100  ]
2023-03-17T17:33:20.663+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 0, leaderEpoch = 0, offset = 14, CreateTime = 1679070799657, serialized key size = -1, serialized value size = 60, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "250", "callId" : "100"})
2023-03-17T17:33:20.665+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T17:33:20.665+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=250, callId=100  ]
2023-03-17T17:33:20.665+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T17:33:20.670+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=100, callStartTimestamp=50, callEndTimestamp=250, callDuration=200]
2023-03-17T17:33:20.671+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 100
2023-03-17T17:33:20.671+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : ResponseMsg [callId=100, callStartTimestamp=50, callEndTimestamp=250, callDuration=200]
2023-03-17T17:33:20.671+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T17:33:20.679+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T17:33:20.691+01:00  WARN 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.postgresql.util.PGPropertyUtil       : JDBC URL invalid port number: ${DATABASE_PORT}
2023-03-17T17:33:20.692+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Put message to Cache!
2023-03-17T17:33:20.693+01:00 ERROR 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Fail to send message to database Driver org.postgresql.Driver claims to not accept jdbcUrl, jdbc:postgresql://${DATABASE_HOST}:${DATABASE_PORT}/Kafka
2023-03-17T17:33:20.702+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-03-17T17:33:20.717+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-03-17T17:33:20.739+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T17:33:20.740+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T17:33:20.740+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679070800739
2023-03-17T17:33:20.751+01:00  INFO 23412 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T17:33:20.751+01:00  INFO 23412 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T17:33:20.752+01:00  INFO 23412 --- [kafka-producer-network-thread | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 1001 with epoch 0
2023-03-17T17:33:20.780+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : Messages from topic 2 
2023-03-17T17:33:25.289+01:00  INFO 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T17:33:25.290+01:00  INFO 23412 --- [pool-2-thread-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T17:33:25.290+01:00  WARN 23412 --- [pool-2-thread-1] org.postgresql.util.PGPropertyUtil       : JDBC URL invalid port number: ${DATABASE_PORT}
2023-03-17T17:33:25.291+01:00 ERROR 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

java.lang.RuntimeException: Driver org.postgresql.Driver claims to not accept jdbcUrl, jdbc:postgresql://${DATABASE_HOST}:${DATABASE_PORT}/Kafka
	at com.zaxxer.hikari.util.DriverDataSource.<init>(DriverDataSource.java:110) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.initializeDataSource(PoolBase.java:326) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.<init>(PoolBase.java:112) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:93) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:112) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:60) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$scheduleSendingMessagesFromCache$0(DatabaseMessageHandler.java:114) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]

2023-03-17T17:33:30.294+01:00  INFO 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T17:33:30.294+01:00  INFO 23412 --- [pool-2-thread-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T17:33:30.295+01:00  WARN 23412 --- [pool-2-thread-1] org.postgresql.util.PGPropertyUtil       : JDBC URL invalid port number: ${DATABASE_PORT}
2023-03-17T17:33:30.295+01:00 ERROR 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

java.lang.RuntimeException: Driver org.postgresql.Driver claims to not accept jdbcUrl, jdbc:postgresql://${DATABASE_HOST}:${DATABASE_PORT}/Kafka
	at com.zaxxer.hikari.util.DriverDataSource.<init>(DriverDataSource.java:110) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.initializeDataSource(PoolBase.java:326) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.<init>(PoolBase.java:112) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:93) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:112) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:60) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$scheduleSendingMessagesFromCache$0(DatabaseMessageHandler.java:114) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]

2023-03-17T17:33:35.285+01:00  INFO 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T17:33:35.285+01:00  INFO 23412 --- [pool-2-thread-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T17:33:35.286+01:00  WARN 23412 --- [pool-2-thread-1] org.postgresql.util.PGPropertyUtil       : JDBC URL invalid port number: ${DATABASE_PORT}
2023-03-17T17:33:35.286+01:00 ERROR 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

java.lang.RuntimeException: Driver org.postgresql.Driver claims to not accept jdbcUrl, jdbc:postgresql://${DATABASE_HOST}:${DATABASE_PORT}/Kafka
	at com.zaxxer.hikari.util.DriverDataSource.<init>(DriverDataSource.java:110) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.initializeDataSource(PoolBase.java:326) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.<init>(PoolBase.java:112) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:93) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:112) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:60) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$scheduleSendingMessagesFromCache$0(DatabaseMessageHandler.java:114) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]

2023-03-17T17:33:40.290+01:00  INFO 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T17:33:40.290+01:00  INFO 23412 --- [pool-2-thread-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T17:33:40.291+01:00  WARN 23412 --- [pool-2-thread-1] org.postgresql.util.PGPropertyUtil       : JDBC URL invalid port number: ${DATABASE_PORT}
2023-03-17T17:33:40.291+01:00 ERROR 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

java.lang.RuntimeException: Driver org.postgresql.Driver claims to not accept jdbcUrl, jdbc:postgresql://${DATABASE_HOST}:${DATABASE_PORT}/Kafka
	at com.zaxxer.hikari.util.DriverDataSource.<init>(DriverDataSource.java:110) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.initializeDataSource(PoolBase.java:326) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.<init>(PoolBase.java:112) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:93) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:112) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:60) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$scheduleSendingMessagesFromCache$0(DatabaseMessageHandler.java:114) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]

2023-03-17T17:33:45.295+01:00  INFO 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T17:33:45.295+01:00  INFO 23412 --- [pool-2-thread-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T17:33:45.296+01:00  WARN 23412 --- [pool-2-thread-1] org.postgresql.util.PGPropertyUtil       : JDBC URL invalid port number: ${DATABASE_PORT}
2023-03-17T17:33:45.297+01:00 ERROR 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

java.lang.RuntimeException: Driver org.postgresql.Driver claims to not accept jdbcUrl, jdbc:postgresql://${DATABASE_HOST}:${DATABASE_PORT}/Kafka
	at com.zaxxer.hikari.util.DriverDataSource.<init>(DriverDataSource.java:110) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.initializeDataSource(PoolBase.java:326) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.<init>(PoolBase.java:112) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:93) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:112) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:60) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$scheduleSendingMessagesFromCache$0(DatabaseMessageHandler.java:114) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]

2023-03-17T17:33:46.624+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 0, leaderEpoch = 0, offset = 15, CreateTime = 1679070825611, serialized key size = -1, serialized value size = 60, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "50", "callId" : "99"})
2023-03-17T17:33:46.625+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T17:33:46.625+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=50, callId=99  ]
2023-03-17T17:33:46.626+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=START, timestamp=50, callId=99  ]
2023-03-17T17:33:50.298+01:00  INFO 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T17:33:50.298+01:00  INFO 23412 --- [pool-2-thread-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T17:33:50.299+01:00  WARN 23412 --- [pool-2-thread-1] org.postgresql.util.PGPropertyUtil       : JDBC URL invalid port number: ${DATABASE_PORT}
2023-03-17T17:33:50.299+01:00 ERROR 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

java.lang.RuntimeException: Driver org.postgresql.Driver claims to not accept jdbcUrl, jdbc:postgresql://${DATABASE_HOST}:${DATABASE_PORT}/Kafka
	at com.zaxxer.hikari.util.DriverDataSource.<init>(DriverDataSource.java:110) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.initializeDataSource(PoolBase.java:326) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.<init>(PoolBase.java:112) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:93) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:112) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:60) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$scheduleSendingMessagesFromCache$0(DatabaseMessageHandler.java:114) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]

2023-03-17T17:33:50.382+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 0, leaderEpoch = 0, offset = 16, CreateTime = 1679070829375, serialized key size = -1, serialized value size = 59, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "250", "callId" : "99"})
2023-03-17T17:33:50.383+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T17:33:50.384+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=250, callId=99  ]
2023-03-17T17:33:50.384+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T17:33:50.384+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=99, callStartTimestamp=50, callEndTimestamp=250, callDuration=200]
2023-03-17T17:33:50.384+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 99
2023-03-17T17:33:50.385+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : ResponseMsg [callId=99, callStartTimestamp=50, callEndTimestamp=250, callDuration=200]
2023-03-17T17:33:50.385+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Put message to Cache!
2023-03-17T17:33:50.389+01:00  INFO 23412 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : Messages from topic 2 
2023-03-17T17:33:55.295+01:00  INFO 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T17:33:55.295+01:00  INFO 23412 --- [pool-2-thread-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T17:33:55.296+01:00  WARN 23412 --- [pool-2-thread-1] org.postgresql.util.PGPropertyUtil       : JDBC URL invalid port number: ${DATABASE_PORT}
2023-03-17T17:33:55.296+01:00 ERROR 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

java.lang.RuntimeException: Driver org.postgresql.Driver claims to not accept jdbcUrl, jdbc:postgresql://${DATABASE_HOST}:${DATABASE_PORT}/Kafka
	at com.zaxxer.hikari.util.DriverDataSource.<init>(DriverDataSource.java:110) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.initializeDataSource(PoolBase.java:326) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.<init>(PoolBase.java:112) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:93) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:112) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:60) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$scheduleSendingMessagesFromCache$0(DatabaseMessageHandler.java:114) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]

2023-03-17T17:34:00.291+01:00  INFO 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T17:34:00.292+01:00  INFO 23412 --- [pool-2-thread-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T17:34:00.293+01:00  WARN 23412 --- [pool-2-thread-1] org.postgresql.util.PGPropertyUtil       : JDBC URL invalid port number: ${DATABASE_PORT}
2023-03-17T17:34:00.293+01:00 ERROR 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

java.lang.RuntimeException: Driver org.postgresql.Driver claims to not accept jdbcUrl, jdbc:postgresql://${DATABASE_HOST}:${DATABASE_PORT}/Kafka
	at com.zaxxer.hikari.util.DriverDataSource.<init>(DriverDataSource.java:110) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.initializeDataSource(PoolBase.java:326) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.<init>(PoolBase.java:112) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:93) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:112) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:60) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$scheduleSendingMessagesFromCache$0(DatabaseMessageHandler.java:114) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]

2023-03-17T17:34:05.291+01:00  INFO 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T17:34:05.291+01:00  INFO 23412 --- [pool-2-thread-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T17:34:05.292+01:00  WARN 23412 --- [pool-2-thread-1] org.postgresql.util.PGPropertyUtil       : JDBC URL invalid port number: ${DATABASE_PORT}
2023-03-17T17:34:05.292+01:00 ERROR 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

java.lang.RuntimeException: Driver org.postgresql.Driver claims to not accept jdbcUrl, jdbc:postgresql://${DATABASE_HOST}:${DATABASE_PORT}/Kafka
	at com.zaxxer.hikari.util.DriverDataSource.<init>(DriverDataSource.java:110) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.initializeDataSource(PoolBase.java:326) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.<init>(PoolBase.java:112) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:93) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:112) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:60) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$scheduleSendingMessagesFromCache$0(DatabaseMessageHandler.java:114) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]

2023-03-17T17:34:10.291+01:00  INFO 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T17:34:10.291+01:00  INFO 23412 --- [pool-2-thread-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T17:34:10.292+01:00  WARN 23412 --- [pool-2-thread-1] org.postgresql.util.PGPropertyUtil       : JDBC URL invalid port number: ${DATABASE_PORT}
2023-03-17T17:34:10.292+01:00 ERROR 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

java.lang.RuntimeException: Driver org.postgresql.Driver claims to not accept jdbcUrl, jdbc:postgresql://${DATABASE_HOST}:${DATABASE_PORT}/Kafka
	at com.zaxxer.hikari.util.DriverDataSource.<init>(DriverDataSource.java:110) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.initializeDataSource(PoolBase.java:326) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.<init>(PoolBase.java:112) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:93) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:112) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:60) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$scheduleSendingMessagesFromCache$0(DatabaseMessageHandler.java:114) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]

2023-03-17T17:34:15.294+01:00  INFO 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T17:34:15.295+01:00  INFO 23412 --- [pool-2-thread-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T17:34:15.295+01:00  WARN 23412 --- [pool-2-thread-1] org.postgresql.util.PGPropertyUtil       : JDBC URL invalid port number: ${DATABASE_PORT}
2023-03-17T17:34:15.295+01:00 ERROR 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

java.lang.RuntimeException: Driver org.postgresql.Driver claims to not accept jdbcUrl, jdbc:postgresql://${DATABASE_HOST}:${DATABASE_PORT}/Kafka
	at com.zaxxer.hikari.util.DriverDataSource.<init>(DriverDataSource.java:110) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.initializeDataSource(PoolBase.java:326) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.<init>(PoolBase.java:112) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:93) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:112) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:60) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$scheduleSendingMessagesFromCache$0(DatabaseMessageHandler.java:114) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]

2023-03-17T17:34:20.298+01:00  INFO 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T17:34:20.298+01:00  INFO 23412 --- [pool-2-thread-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T17:34:20.299+01:00  WARN 23412 --- [pool-2-thread-1] org.postgresql.util.PGPropertyUtil       : JDBC URL invalid port number: ${DATABASE_PORT}
2023-03-17T17:34:20.299+01:00 ERROR 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

java.lang.RuntimeException: Driver org.postgresql.Driver claims to not accept jdbcUrl, jdbc:postgresql://${DATABASE_HOST}:${DATABASE_PORT}/Kafka
	at com.zaxxer.hikari.util.DriverDataSource.<init>(DriverDataSource.java:110) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.initializeDataSource(PoolBase.java:326) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.<init>(PoolBase.java:112) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:93) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:112) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:60) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$scheduleSendingMessagesFromCache$0(DatabaseMessageHandler.java:114) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]

2023-03-17T17:34:25.291+01:00  INFO 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T17:34:25.291+01:00  INFO 23412 --- [pool-2-thread-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T17:34:25.292+01:00  WARN 23412 --- [pool-2-thread-1] org.postgresql.util.PGPropertyUtil       : JDBC URL invalid port number: ${DATABASE_PORT}
2023-03-17T17:34:25.292+01:00 ERROR 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

java.lang.RuntimeException: Driver org.postgresql.Driver claims to not accept jdbcUrl, jdbc:postgresql://${DATABASE_HOST}:${DATABASE_PORT}/Kafka
	at com.zaxxer.hikari.util.DriverDataSource.<init>(DriverDataSource.java:110) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.initializeDataSource(PoolBase.java:326) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.<init>(PoolBase.java:112) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:93) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:112) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:60) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$scheduleSendingMessagesFromCache$0(DatabaseMessageHandler.java:114) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]

2023-03-17T17:34:30.291+01:00  INFO 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T17:34:30.291+01:00  INFO 23412 --- [pool-2-thread-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T17:34:30.292+01:00  WARN 23412 --- [pool-2-thread-1] org.postgresql.util.PGPropertyUtil       : JDBC URL invalid port number: ${DATABASE_PORT}
2023-03-17T17:34:30.292+01:00 ERROR 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

java.lang.RuntimeException: Driver org.postgresql.Driver claims to not accept jdbcUrl, jdbc:postgresql://${DATABASE_HOST}:${DATABASE_PORT}/Kafka
	at com.zaxxer.hikari.util.DriverDataSource.<init>(DriverDataSource.java:110) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.initializeDataSource(PoolBase.java:326) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.<init>(PoolBase.java:112) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:93) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:112) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:60) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$scheduleSendingMessagesFromCache$0(DatabaseMessageHandler.java:114) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]

2023-03-17T17:34:35.286+01:00  INFO 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T17:34:35.287+01:00  INFO 23412 --- [pool-2-thread-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T17:34:35.287+01:00  WARN 23412 --- [pool-2-thread-1] org.postgresql.util.PGPropertyUtil       : JDBC URL invalid port number: ${DATABASE_PORT}
2023-03-17T17:34:35.287+01:00 ERROR 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

java.lang.RuntimeException: Driver org.postgresql.Driver claims to not accept jdbcUrl, jdbc:postgresql://${DATABASE_HOST}:${DATABASE_PORT}/Kafka
	at com.zaxxer.hikari.util.DriverDataSource.<init>(DriverDataSource.java:110) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.initializeDataSource(PoolBase.java:326) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.<init>(PoolBase.java:112) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:93) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:112) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:60) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$scheduleSendingMessagesFromCache$0(DatabaseMessageHandler.java:114) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]

2023-03-17T17:34:40.288+01:00  INFO 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T17:34:40.289+01:00  INFO 23412 --- [pool-2-thread-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T17:34:40.290+01:00  WARN 23412 --- [pool-2-thread-1] org.postgresql.util.PGPropertyUtil       : JDBC URL invalid port number: ${DATABASE_PORT}
2023-03-17T17:34:40.290+01:00 ERROR 23412 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

java.lang.RuntimeException: Driver org.postgresql.Driver claims to not accept jdbcUrl, jdbc:postgresql://${DATABASE_HOST}:${DATABASE_PORT}/Kafka
	at com.zaxxer.hikari.util.DriverDataSource.<init>(DriverDataSource.java:110) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.initializeDataSource(PoolBase.java:326) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.<init>(PoolBase.java:112) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:93) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:112) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:60) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$scheduleSendingMessagesFromCache$0(DatabaseMessageHandler.java:114) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]

