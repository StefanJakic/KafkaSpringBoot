2023-03-17T00:02:14.381+01:00  INFO 12504 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T00:02:14.626+01:00  INFO 12504 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T00:02:39.462+01:00  INFO 12504 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient   : [Producer clientId=producer-1] Node -1 disconnected.
2023-03-17T00:04:34.424+01:00  INFO 16904 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 16904 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T00:04:34.427+01:00  INFO 16904 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T00:04:34.895+01:00  INFO 16904 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T00:04:34.916+01:00  INFO 16904 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T00:04:35.960+01:00  INFO 16904 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T00:04:36.107+01:00  INFO 16904 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:04:36.108+01:00  INFO 16904 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:04:36.108+01:00  INFO 16904 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679007876105
2023-03-17T00:04:36.354+01:00  INFO 16904 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T00:04:36.358+01:00  INFO 16904 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T00:04:36.358+01:00  INFO 16904 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T00:04:36.358+01:00  INFO 16904 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T00:04:36.363+01:00  INFO 16904 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T00:04:36.364+01:00  INFO 16904 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T00:04:36.365+01:00  INFO 16904 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T00:04:36.387+01:00  INFO 16904 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T00:04:36.420+01:00  INFO 16904 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:04:36.420+01:00  INFO 16904 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:04:36.420+01:00  INFO 16904 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679007876419
2023-03-17T00:04:36.421+01:00  INFO 16904 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T00:04:36.428+01:00  INFO 16904 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T00:04:36.434+01:00  INFO 16904 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:04:36.435+01:00  INFO 16904 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:04:36.435+01:00  INFO 16904 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679007876434
2023-03-17T00:04:36.436+01:00  INFO 16904 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T00:04:36.450+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:04:36.450+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T00:04:36.450+01:00  INFO 16904 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.425 seconds (process running for 2.767)
2023-03-17T00:04:36.451+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:04:36.452+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:04:36.452+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:04:36.454+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:04:36.454+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:04:36.457+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:04:36.457+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:04:36.475+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-ef3e8a8c-5200-465d-b52b-7daccee661fe
2023-03-17T00:04:36.475+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-80162b53-eadc-4f3c-8a2f-3af440503608
2023-03-17T00:04:36.476+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T00:04:36.476+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T00:04:36.476+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:04:36.476+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:05:13.946+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=11, memberId='consumer-springkafkatask33;-1-80162b53-eadc-4f3c-8a2f-3af440503608', protocol='range'}
2023-03-17T00:05:13.946+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=11, memberId='consumer-springkafkatask33;-2-ef3e8a8c-5200-465d-b52b-7daccee661fe', protocol='range'}
2023-03-17T00:05:13.951+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T00:05:13.955+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Finished assignment for group at generation 11: {consumer-springkafkatask33;-2-ef3e8a8c-5200-465d-b52b-7daccee661fe=Assignment(partitions=[topicTask1-0, topicTask1-1]), consumer-springkafkatask33;-1-80162b53-eadc-4f3c-8a2f-3af440503608=Assignment(partitions=[topicTask2-0])}
2023-03-17T00:05:13.960+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=11, memberId='consumer-springkafkatask33;-2-ef3e8a8c-5200-465d-b52b-7daccee661fe', protocol='range'}
2023-03-17T00:05:13.960+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=11, memberId='consumer-springkafkatask33;-1-80162b53-eadc-4f3c-8a2f-3af440503608', protocol='range'}
2023-03-17T00:05:13.961+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T00:05:13.961+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T00:05:13.969+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T00:05:13.969+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T00:05:13.979+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=39, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:05:13.979+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:05:13.980+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=28, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:05:13.981+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T00:05:13.981+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T00:05:14.010+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 28, CreateTime = 1679007887110, serialized key size = -1, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e3)
2023-03-17T00:05:14.019+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:05:14.019+01:00 ERROR 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:05:14.024+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-03-17T00:05:14.032+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-03-17T00:05:14.047+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:05:14.048+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:05:14.048+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679007914047
2023-03-17T00:05:14.053+01:00  INFO 16904 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:05:14.053+01:00  INFO 16904 --- [kafka-producer-network-thread | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 9 with epoch 0
2023-03-17T00:05:14.057+01:00  INFO 16904 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T00:05:14.064+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 29, CreateTime = 1679007891327, serialized key size = -1, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e4)
2023-03-17T00:05:14.065+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:05:14.065+01:00 ERROR 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:05:14.073+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 39, CreateTime = 1679007914059, serialized key size = 5, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = e3)
2023-03-17T00:05:14.076+01:00  INFO 16904 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 40, CreateTime = 1679007914065, serialized key size = 5, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = e4)
2023-03-17T00:11:26.896+01:00  INFO 13432 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 13432 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T00:11:26.898+01:00  INFO 13432 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T00:11:27.357+01:00  INFO 13432 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T00:11:27.376+01:00  INFO 13432 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T00:11:28.371+01:00  INFO 13432 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T00:11:28.528+01:00  INFO 13432 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:11:28.530+01:00  INFO 13432 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:11:28.530+01:00  INFO 13432 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679008288527
2023-03-17T00:11:28.783+01:00  INFO 13432 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T00:11:28.787+01:00  INFO 13432 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T00:11:28.787+01:00  INFO 13432 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T00:11:28.787+01:00  INFO 13432 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T00:11:28.793+01:00  INFO 13432 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T00:11:28.793+01:00  INFO 13432 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T00:11:28.794+01:00  INFO 13432 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T00:11:28.820+01:00  INFO 13432 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T00:11:28.870+01:00  INFO 13432 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:11:28.871+01:00  INFO 13432 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:11:28.871+01:00  INFO 13432 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679008288870
2023-03-17T00:11:28.873+01:00  INFO 13432 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T00:11:28.886+01:00  INFO 13432 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T00:11:28.892+01:00  INFO 13432 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:11:28.893+01:00  INFO 13432 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:11:28.893+01:00  INFO 13432 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679008288892
2023-03-17T00:11:28.894+01:00  INFO 13432 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T00:11:28.905+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T00:11:28.905+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:11:28.906+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:11:28.909+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:11:28.909+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:11:28.910+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:11:28.910+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:11:28.910+01:00  INFO 13432 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.414 seconds (process running for 2.773)
2023-03-17T00:11:28.913+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:11:28.913+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:11:28.931+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-69707598-e678-4ce9-9256-00329c819ee7
2023-03-17T00:11:28.931+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-b84629d7-f4d4-407f-8f26-75d22818c21e
2023-03-17T00:11:28.932+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T00:11:28.932+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T00:11:28.932+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:11:28.932+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:11:35.874+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=12, memberId='consumer-springkafkatask33;-1-69707598-e678-4ce9-9256-00329c819ee7', protocol='range'}
2023-03-17T00:11:35.874+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=12, memberId='consumer-springkafkatask33;-2-b84629d7-f4d4-407f-8f26-75d22818c21e', protocol='range'}
2023-03-17T00:11:35.879+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T00:11:35.882+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Finished assignment for group at generation 12: {consumer-springkafkatask33;-1-69707598-e678-4ce9-9256-00329c819ee7=Assignment(partitions=[topicTask1-0, topicTask1-1]), consumer-springkafkatask33;-2-b84629d7-f4d4-407f-8f26-75d22818c21e=Assignment(partitions=[topicTask2-0])}
2023-03-17T00:11:35.887+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=12, memberId='consumer-springkafkatask33;-1-69707598-e678-4ce9-9256-00329c819ee7', protocol='range'}
2023-03-17T00:11:35.887+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=12, memberId='consumer-springkafkatask33;-2-b84629d7-f4d4-407f-8f26-75d22818c21e', protocol='range'}
2023-03-17T00:11:35.888+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T00:11:35.888+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T00:11:35.891+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T00:11:35.891+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T00:11:35.899+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=41, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:11:35.899+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:11:35.900+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=30, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:11:35.901+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T00:11:35.901+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T00:11:38.994+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 30, CreateTime = 1679008297964, serialized key size = -1, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e6)
2023-03-17T00:11:39.003+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:11:39.003+01:00 ERROR 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:11:39.008+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-03-17T00:11:39.017+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-03-17T00:11:39.028+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:11:39.028+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:11:39.028+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679008299028
2023-03-17T00:11:39.036+01:00  INFO 13432 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T00:11:39.036+01:00  INFO 13432 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:11:39.037+01:00  INFO 13432 --- [kafka-producer-network-thread | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 10 with epoch 0
2023-03-17T00:11:39.059+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 41, CreateTime = 1679008299037, serialized key size = 5, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = e6)
2023-03-17T00:11:46.797+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 31, CreateTime = 1679008305787, serialized key size = -1, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 67)
2023-03-17T00:11:46.825+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:11:46.825+01:00 ERROR 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:11:46.829+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 42, CreateTime = 1679008306825, serialized key size = 5, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = 67)
2023-03-17T00:15:43.114+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 32, CreateTime = 1679008542099, serialized key size = -1, serialized value size = 73, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "-50", "callId" : "nesto777777777"})
2023-03-17T00:15:43.116+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:15:43.116+01:00 ERROR 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:15:43.120+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 43, CreateTime = 1679008543116, serialized key size = 5, serialized value size = 73, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = {"callStatus": "START", "timestamp" : "-50", "callId" : "nesto777777777"})
2023-03-17T00:17:06.427+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 33, CreateTime = 1679008625416, serialized key size = -1, serialized value size = 69, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "660", "callId" : "nesto88888"})
2023-03-17T00:17:06.428+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:17:06.432+01:00  INFO 13432 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 44, CreateTime = 1679008626428, serialized key size = 5, serialized value size = 69, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = {"callStatus": "START", "timestamp" : "660", "callId" : "nesto88888"})
2023-03-17T00:19:14.466+01:00  INFO 4928 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 4928 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T00:19:14.469+01:00  INFO 4928 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T00:19:14.932+01:00  INFO 4928 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T00:19:14.952+01:00  INFO 4928 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T00:19:15.963+01:00  INFO 4928 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T00:19:16.111+01:00  INFO 4928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:19:16.112+01:00  INFO 4928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:19:16.112+01:00  INFO 4928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679008756110
2023-03-17T00:19:16.368+01:00  INFO 4928 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T00:19:16.372+01:00  INFO 4928 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T00:19:16.373+01:00  INFO 4928 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T00:19:16.373+01:00  INFO 4928 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T00:19:16.377+01:00  INFO 4928 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T00:19:16.378+01:00  INFO 4928 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T00:19:16.378+01:00  INFO 4928 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T00:19:16.402+01:00  INFO 4928 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T00:19:16.438+01:00  INFO 4928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:19:16.438+01:00  INFO 4928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:19:16.438+01:00  INFO 4928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679008756438
2023-03-17T00:19:16.440+01:00  INFO 4928 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T00:19:16.449+01:00  INFO 4928 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T00:19:16.457+01:00  INFO 4928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:19:16.458+01:00  INFO 4928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:19:16.458+01:00  INFO 4928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679008756457
2023-03-17T00:19:16.458+01:00  INFO 4928 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T00:19:16.468+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:19:16.468+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T00:19:16.469+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:19:16.471+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:19:16.471+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:19:16.474+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:19:16.474+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:19:16.478+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:19:16.478+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:19:16.479+01:00  INFO 4928 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.404 seconds (process running for 2.754)
2023-03-17T00:19:16.501+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-73a6d5e4-70b1-4642-b09b-f1944a693525
2023-03-17T00:19:16.502+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-bf335151-0c8d-42c2-a7fa-c7b28854bb23
2023-03-17T00:19:16.502+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T00:19:16.502+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T00:19:16.502+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:19:16.502+01:00  INFO 4928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:19:33.908+01:00  INFO 9132 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 9132 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T00:19:33.910+01:00  INFO 9132 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T00:19:34.402+01:00  INFO 9132 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T00:19:34.424+01:00  INFO 9132 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T00:19:35.453+01:00  INFO 9132 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T00:19:35.617+01:00  INFO 9132 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:19:35.619+01:00  INFO 9132 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:19:35.619+01:00  INFO 9132 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679008775616
2023-03-17T00:19:35.879+01:00  INFO 9132 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T00:19:35.882+01:00  INFO 9132 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T00:19:35.882+01:00  INFO 9132 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T00:19:35.882+01:00  INFO 9132 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T00:19:35.887+01:00  INFO 9132 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T00:19:35.888+01:00  INFO 9132 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T00:19:35.888+01:00  INFO 9132 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T00:19:35.912+01:00  INFO 9132 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T00:19:35.947+01:00  INFO 9132 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:19:35.947+01:00  INFO 9132 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:19:35.947+01:00  INFO 9132 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679008775947
2023-03-17T00:19:35.949+01:00  INFO 9132 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T00:19:35.957+01:00  INFO 9132 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T00:19:35.964+01:00  INFO 9132 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:19:35.964+01:00  INFO 9132 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:19:35.965+01:00  INFO 9132 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679008775964
2023-03-17T00:19:35.966+01:00  INFO 9132 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T00:19:35.972+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T00:19:35.972+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:19:35.973+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:19:35.974+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:19:35.974+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:19:35.975+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:19:35.976+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:19:35.979+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:19:35.979+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:19:35.980+01:00  INFO 9132 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.48 seconds (process running for 2.819)
2023-03-17T00:19:36.000+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-3435bd85-2229-4e3c-83a5-a802f289be98
2023-03-17T00:19:36.001+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-41d1e74e-f500-4666-b736-166c0bb58fcc
2023-03-17T00:19:36.001+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T00:19:36.001+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T00:19:36.001+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:19:36.001+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:19:49.154+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=13, memberId='consumer-springkafkatask33;-1-3435bd85-2229-4e3c-83a5-a802f289be98', protocol='range'}
2023-03-17T00:19:49.154+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=13, memberId='consumer-springkafkatask33;-2-41d1e74e-f500-4666-b736-166c0bb58fcc', protocol='range'}
2023-03-17T00:20:19.180+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Disconnecting from node 2147483647 due to request timeout.
2023-03-17T00:20:19.183+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cancelled in-flight SYNC_GROUP request with correlation id 6 due to node 2147483647 being disconnected (elapsed time since creation: 30025ms, elapsed time since send: 30025ms, request timeout: 30000ms)
2023-03-17T00:20:19.183+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 7 due to node 2147483647 being disconnected (elapsed time since creation: 27011ms, elapsed time since send: 27011ms, request timeout: 30000ms)
2023-03-17T00:20:19.183+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 8 due to node 2147483647 being disconnected (elapsed time since creation: 24000ms, elapsed time since send: 24000ms, request timeout: 30000ms)
2023-03-17T00:20:19.183+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 9 due to node 2147483647 being disconnected (elapsed time since creation: 20989ms, elapsed time since send: 20989ms, request timeout: 30000ms)
2023-03-17T00:20:19.184+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 10 due to node 2147483647 being disconnected (elapsed time since creation: 17982ms, elapsed time since send: 17982ms, request timeout: 30000ms)
2023-03-17T00:20:19.184+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 11 due to node 2147483647 being disconnected (elapsed time since creation: 14976ms, elapsed time since send: 14976ms, request timeout: 30000ms)
2023-03-17T00:20:19.184+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 12 due to node 2147483647 being disconnected (elapsed time since creation: 11961ms, elapsed time since send: 11961ms, request timeout: 30000ms)
2023-03-17T00:20:19.185+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 13 due to node 2147483647 being disconnected (elapsed time since creation: 8952ms, elapsed time since send: 8952ms, request timeout: 30000ms)
2023-03-17T00:20:19.185+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 14 due to node 2147483647 being disconnected (elapsed time since creation: 5936ms, elapsed time since send: 5936ms, request timeout: 30000ms)
2023-03-17T00:20:19.185+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 15 due to node 2147483647 being disconnected (elapsed time since creation: 2935ms, elapsed time since send: 2935ms, request timeout: 30000ms)
2023-03-17T00:20:19.188+01:00  INFO 9132 --- [kafka-coordinator-heartbeat-thread | springkafkatask33;] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: null. isDisconnected: true. Rediscovery will be attempted.
2023-03-17T00:20:19.191+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:20:19.191+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
2023-03-17T00:20:19.192+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Requesting disconnect from last known coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:20:19.196+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Disconnecting from node 2147483647 due to request timeout.
2023-03-17T00:20:19.196+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cancelled in-flight SYNC_GROUP request with correlation id 6 due to node 2147483647 being disconnected (elapsed time since creation: 30041ms, elapsed time since send: 30040ms, request timeout: 30000ms)
2023-03-17T00:20:19.196+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 7 due to node 2147483647 being disconnected (elapsed time since creation: 27027ms, elapsed time since send: 27027ms, request timeout: 30000ms)
2023-03-17T00:20:19.197+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 8 due to node 2147483647 being disconnected (elapsed time since creation: 24016ms, elapsed time since send: 24016ms, request timeout: 30000ms)
2023-03-17T00:20:19.197+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 9 due to node 2147483647 being disconnected (elapsed time since creation: 21005ms, elapsed time since send: 21005ms, request timeout: 30000ms)
2023-03-17T00:20:19.197+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 10 due to node 2147483647 being disconnected (elapsed time since creation: 17998ms, elapsed time since send: 17998ms, request timeout: 30000ms)
2023-03-17T00:20:19.197+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 11 due to node 2147483647 being disconnected (elapsed time since creation: 14992ms, elapsed time since send: 14992ms, request timeout: 30000ms)
2023-03-17T00:20:19.197+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 12 due to node 2147483647 being disconnected (elapsed time since creation: 11977ms, elapsed time since send: 11977ms, request timeout: 30000ms)
2023-03-17T00:20:19.197+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 13 due to node 2147483647 being disconnected (elapsed time since creation: 8968ms, elapsed time since send: 8968ms, request timeout: 30000ms)
2023-03-17T00:20:19.198+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 14 due to node 2147483647 being disconnected (elapsed time since creation: 5952ms, elapsed time since send: 5952ms, request timeout: 30000ms)
2023-03-17T00:20:19.198+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cancelled in-flight HEARTBEAT request with correlation id 15 due to node 2147483647 being disconnected (elapsed time since creation: 2951ms, elapsed time since send: 2951ms, request timeout: 30000ms)
2023-03-17T00:20:19.199+01:00  INFO 9132 --- [kafka-coordinator-heartbeat-thread | springkafkatask33;] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: null. isDisconnected: true. Rediscovery will be attempted.
2023-03-17T00:20:19.202+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:20:19.202+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
2023-03-17T00:20:19.202+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Requesting disconnect from last known coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:20:19.307+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:20:19.307+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:20:19.308+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'null' (DisconnectException)
2023-03-17T00:20:19.308+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'null' (DisconnectException)
2023-03-17T00:20:19.308+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:20:19.308+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:20:19.311+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=13, memberId='consumer-springkafkatask33;-2-41d1e74e-f500-4666-b736-166c0bb58fcc', protocol='range'}
2023-03-17T00:20:19.311+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=13, memberId='consumer-springkafkatask33;-1-3435bd85-2229-4e3c-83a5-a802f289be98', protocol='range'}
2023-03-17T00:20:34.166+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=13, memberId='consumer-springkafkatask33;-1-3435bd85-2229-4e3c-83a5-a802f289be98', protocol='range'}
2023-03-17T00:20:34.166+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=13, memberId='consumer-springkafkatask33;-2-41d1e74e-f500-4666-b736-166c0bb58fcc', protocol='range'}
2023-03-17T00:20:34.166+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting generation due to: encountered REBALANCE_IN_PROGRESS from SYNC_GROUP response
2023-03-17T00:20:34.167+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting generation due to: encountered REBALANCE_IN_PROGRESS from SYNC_GROUP response
2023-03-17T00:20:34.167+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: encountered REBALANCE_IN_PROGRESS from SYNC_GROUP response
2023-03-17T00:20:34.167+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: encountered REBALANCE_IN_PROGRESS from SYNC_GROUP response
2023-03-17T00:20:34.167+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group is rebalancing, so a rejoin is needed.' (RebalanceInProgressException)
2023-03-17T00:20:34.167+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group is rebalancing, so a rejoin is needed.' (RebalanceInProgressException)
2023-03-17T00:20:34.167+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:20:34.168+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:20:34.169+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=14, memberId='consumer-springkafkatask33;-1-3435bd85-2229-4e3c-83a5-a802f289be98', protocol='range'}
2023-03-17T00:20:34.169+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=14, memberId='consumer-springkafkatask33;-2-41d1e74e-f500-4666-b736-166c0bb58fcc', protocol='range'}
2023-03-17T00:20:34.171+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:20:34.171+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:20:34.178+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Finished assignment for group at generation 14: {consumer-springkafkatask33;-2-41d1e74e-f500-4666-b736-166c0bb58fcc=Assignment(partitions=[topicTask2-0]), consumer-springkafkatask33;-1-3435bd85-2229-4e3c-83a5-a802f289be98=Assignment(partitions=[topicTask1-0, topicTask1-1])}
2023-03-17T00:20:34.183+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=14, memberId='consumer-springkafkatask33;-1-3435bd85-2229-4e3c-83a5-a802f289be98', protocol='range'}
2023-03-17T00:20:34.183+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=14, memberId='consumer-springkafkatask33;-2-41d1e74e-f500-4666-b736-166c0bb58fcc', protocol='range'}
2023-03-17T00:20:34.183+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T00:20:34.183+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T00:20:34.186+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T00:20:34.186+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T00:20:34.195+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:20:34.195+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=45, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:20:34.195+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:20:34.196+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T00:20:34.196+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T00:20:34.225+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 34, CreateTime = 1679008783433, serialized key size = -1, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e1)
2023-03-17T00:20:34.234+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:20:34.235+01:00 ERROR 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:20:34.239+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-03-17T00:20:34.246+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-03-17T00:20:34.257+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:20:34.257+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:20:34.258+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679008834257
2023-03-17T00:20:34.263+01:00  INFO 9132 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T00:20:34.264+01:00  INFO 9132 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:20:34.264+01:00  INFO 9132 --- [kafka-producer-network-thread | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 11 with epoch 0
2023-03-17T00:20:34.269+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 35, CreateTime = 1679008791522, serialized key size = -1, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e2)
2023-03-17T00:20:34.270+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:20:34.270+01:00 ERROR 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:20:34.270+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 36, CreateTime = 1679008823350, serialized key size = -1, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e4)
2023-03-17T00:20:34.271+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:20:34.271+01:00 ERROR 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:20:34.280+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 45, CreateTime = 1679008834264, serialized key size = 5, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = e1)
2023-03-17T00:20:34.280+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 46, CreateTime = 1679008834270, serialized key size = 5, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = e2)
2023-03-17T00:20:34.280+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 47, CreateTime = 1679008834271, serialized key size = 5, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = e4)
2023-03-17T00:20:34.452+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 37, CreateTime = 1679008833444, serialized key size = -1, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e5)
2023-03-17T00:20:34.452+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:20:34.453+01:00 ERROR 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:20:34.455+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 48, CreateTime = 1679008834453, serialized key size = 5, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = e5)
2023-03-17T00:21:05.211+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 38, CreateTime = 1679008864198, serialized key size = -1, serialized value size = 73, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "-50", "callId" : "nesto777777777"})
2023-03-17T00:21:05.239+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:21:05.239+01:00 ERROR 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:21:05.242+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 49, CreateTime = 1679008865240, serialized key size = 5, serialized value size = 73, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = {"callStatus": "START", "timestamp" : "-50", "callId" : "nesto777777777"})
2023-03-17T00:22:15.649+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 39, CreateTime = 1679008934645, serialized key size = -1, serialized value size = 61, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "50", "callId" : "100"})
2023-03-17T00:22:15.650+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:22:15.654+01:00  INFO 9132 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 50, CreateTime = 1679008935651, serialized key size = 5, serialized value size = 61, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = {"callStatus": "START", "timestamp" : "50", "callId" : "100"})
2023-03-17T00:24:29.304+01:00  INFO 7488 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 7488 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T00:24:29.307+01:00  INFO 7488 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T00:24:29.758+01:00  INFO 7488 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T00:24:29.778+01:00  INFO 7488 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T00:24:30.784+01:00  INFO 7488 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T00:24:30.947+01:00  INFO 7488 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:24:30.948+01:00  INFO 7488 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:24:30.948+01:00  INFO 7488 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679009070946
2023-03-17T00:24:31.195+01:00  INFO 7488 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T00:24:31.199+01:00  INFO 7488 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T00:24:31.199+01:00  INFO 7488 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T00:24:31.199+01:00  INFO 7488 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T00:24:31.203+01:00  INFO 7488 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T00:24:31.204+01:00  INFO 7488 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T00:24:31.205+01:00  INFO 7488 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T00:24:31.227+01:00  INFO 7488 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T00:24:31.265+01:00  INFO 7488 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:24:31.265+01:00  INFO 7488 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:24:31.265+01:00  INFO 7488 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679009071265
2023-03-17T00:24:31.266+01:00  INFO 7488 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T00:24:31.275+01:00  INFO 7488 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T00:24:31.282+01:00  INFO 7488 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:24:31.283+01:00  INFO 7488 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:24:31.283+01:00  INFO 7488 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679009071282
2023-03-17T00:24:31.285+01:00  INFO 7488 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T00:24:31.294+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T00:24:31.294+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:24:31.295+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:24:31.296+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:24:31.296+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:24:31.297+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:24:31.298+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T00:24:31.300+01:00  INFO 7488 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.396 seconds (process running for 2.748)
2023-03-17T00:24:31.300+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:24:31.300+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:24:31.318+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-1dcef807-b515-4c5e-9eeb-e2d36db42b71
2023-03-17T00:24:31.318+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-9121820d-e682-4299-b9b1-710db3bdcf5e
2023-03-17T00:24:31.319+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T00:24:31.319+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T00:24:31.319+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:24:31.319+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T00:24:58.862+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=15, memberId='consumer-springkafkatask33;-1-1dcef807-b515-4c5e-9eeb-e2d36db42b71', protocol='range'}
2023-03-17T00:24:58.862+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=15, memberId='consumer-springkafkatask33;-2-9121820d-e682-4299-b9b1-710db3bdcf5e', protocol='range'}
2023-03-17T00:24:58.866+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:24:58.867+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T00:24:58.871+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Finished assignment for group at generation 15: {consumer-springkafkatask33;-2-9121820d-e682-4299-b9b1-710db3bdcf5e=Assignment(partitions=[topicTask2-0]), consumer-springkafkatask33;-1-1dcef807-b515-4c5e-9eeb-e2d36db42b71=Assignment(partitions=[topicTask1-0, topicTask1-1])}
2023-03-17T00:24:58.876+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=15, memberId='consumer-springkafkatask33;-2-9121820d-e682-4299-b9b1-710db3bdcf5e', protocol='range'}
2023-03-17T00:24:58.876+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=15, memberId='consumer-springkafkatask33;-1-1dcef807-b515-4c5e-9eeb-e2d36db42b71', protocol='range'}
2023-03-17T00:24:58.877+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T00:24:58.877+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T00:24:58.879+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T00:24:58.879+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T00:24:58.889+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=51, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:24:58.889+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:24:58.889+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=40, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T00:24:58.890+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T00:24:58.890+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T00:24:58.919+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 40, CreateTime = 1679009078173, serialized key size = -1, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e3)
2023-03-17T00:24:58.927+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:24:58.928+01:00 ERROR 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:24:58.934+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-03-17T00:24:58.941+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-03-17T00:24:58.952+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T00:24:58.953+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T00:24:58.953+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679009098952
2023-03-17T00:24:58.958+01:00  INFO 7488 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T00:24:58.959+01:00  INFO 7488 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T00:24:58.959+01:00  INFO 7488 --- [kafka-producer-network-thread | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 12 with epoch 0
2023-03-17T00:24:58.965+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 41, CreateTime = 1679009085200, serialized key size = -1, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e4)
2023-03-17T00:24:58.965+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:24:58.965+01:00 ERROR 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:24:58.974+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 51, CreateTime = 1679009098959, serialized key size = 5, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = e3)
2023-03-17T00:24:58.975+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 52, CreateTime = 1679009098966, serialized key size = 5, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = e4)
2023-03-17T00:24:59.596+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 42, CreateTime = 1679009098587, serialized key size = -1, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e5)
2023-03-17T00:24:59.596+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:24:59.598+01:00 ERROR 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:24:59.602+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 53, CreateTime = 1679009099599, serialized key size = 5, serialized value size = 2, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = e5)
2023-03-17T00:25:08.754+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 43, CreateTime = 1679009107736, serialized key size = -1, serialized value size = 73, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "-50", "callId" : "nesto777777777"})
2023-03-17T00:25:08.786+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:25:08.786+01:00 ERROR 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T00:25:08.789+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 54, CreateTime = 1679009108786, serialized key size = 5, serialized value size = 73, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = {"callStatus": "START", "timestamp" : "-50", "callId" : "nesto777777777"})
2023-03-17T00:25:26.782+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 44, CreateTime = 1679009125765, serialized key size = -1, serialized value size = 69, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "660", "callId" : "nesto88888"})
2023-03-17T00:25:26.784+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T00:25:26.787+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 55, CreateTime = 1679009126784, serialized key size = 5, serialized value size = 69, headers = RecordHeaders(headers = [], isReadOnly = false), key = kljuc, value = {"callStatus": "START", "timestamp" : "660", "callId" : "nesto88888"})
2023-03-17T00:33:31.700+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T00:33:31.778+01:00  INFO 7488 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T10:36:49.377+01:00  INFO 11000 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 11000 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T10:36:49.379+01:00  INFO 11000 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T10:36:49.834+01:00  INFO 11000 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T10:36:49.852+01:00  INFO 11000 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T10:36:50.839+01:00  INFO 11000 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T10:36:50.996+01:00  INFO 11000 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T10:36:50.997+01:00  INFO 11000 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T10:36:50.997+01:00  INFO 11000 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679045810995
2023-03-17T10:36:51.239+01:00  INFO 11000 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T10:36:51.242+01:00  INFO 11000 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T10:36:51.243+01:00  INFO 11000 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T10:36:51.243+01:00  INFO 11000 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T10:36:51.247+01:00  INFO 11000 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T10:36:51.248+01:00  INFO 11000 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T10:36:51.248+01:00  INFO 11000 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T10:36:51.278+01:00  INFO 11000 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T10:36:51.318+01:00  INFO 11000 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T10:36:51.319+01:00  INFO 11000 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T10:36:51.319+01:00  INFO 11000 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679045811318
2023-03-17T10:36:51.320+01:00  INFO 11000 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T10:36:51.327+01:00  INFO 11000 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T10:36:51.334+01:00  INFO 11000 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T10:36:51.335+01:00  INFO 11000 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T10:36:51.335+01:00  INFO 11000 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679045811334
2023-03-17T10:36:51.335+01:00  INFO 11000 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T10:36:51.344+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T10:36:51.344+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T10:36:51.346+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T10:36:51.347+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T10:36:51.347+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T10:36:51.349+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T10:36:51.349+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T10:36:51.352+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T10:36:51.352+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T10:36:51.354+01:00  INFO 11000 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.367 seconds (process running for 2.716)
2023-03-17T10:36:51.372+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-fe8b8d18-5aca-4663-b360-a9e9ea161fd0
2023-03-17T10:36:51.372+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-8c198c18-6b95-4824-8d87-46c1271e9a4c
2023-03-17T10:36:51.373+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T10:36:51.373+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T10:36:51.373+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T10:36:51.373+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T10:36:51.378+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=17, memberId='consumer-springkafkatask33;-1-fe8b8d18-5aca-4663-b360-a9e9ea161fd0', protocol='range'}
2023-03-17T10:36:51.378+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=17, memberId='consumer-springkafkatask33;-2-8c198c18-6b95-4824-8d87-46c1271e9a4c', protocol='range'}
2023-03-17T10:36:51.383+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T10:36:51.384+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T10:36:51.388+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Finished assignment for group at generation 17: {consumer-springkafkatask33;-1-fe8b8d18-5aca-4663-b360-a9e9ea161fd0=Assignment(partitions=[topicTask2-0]), consumer-springkafkatask33;-2-8c198c18-6b95-4824-8d87-46c1271e9a4c=Assignment(partitions=[topicTask1-0, topicTask1-1])}
2023-03-17T10:36:51.398+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=17, memberId='consumer-springkafkatask33;-1-fe8b8d18-5aca-4663-b360-a9e9ea161fd0', protocol='range'}
2023-03-17T10:36:51.398+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=17, memberId='consumer-springkafkatask33;-2-8c198c18-6b95-4824-8d87-46c1271e9a4c', protocol='range'}
2023-03-17T10:36:51.398+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T10:36:51.398+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T10:36:51.402+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T10:36:51.402+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T10:36:51.420+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T10:36:51.420+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=56, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T10:36:51.420+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=45, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T10:36:51.422+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T10:36:51.422+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T10:37:05.824+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 45, CreateTime = 1679045824804, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e)
2023-03-17T10:37:05.834+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:37:05.834+01:00 ERROR 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T10:37:21.521+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 46, CreateTime = 1679045840509, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = w)
2023-03-17T10:37:21.522+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:37:21.522+01:00 ERROR 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T10:37:44.540+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 47, CreateTime = 1679045863537, serialized key size = -1, serialized value size = 63, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "660", "callId" : "8888"})
2023-03-17T10:37:44.572+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:37:44.572+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=660, callId=8888  ]
2023-03-17T10:37:44.573+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=START, timestamp=660, callId=8888  ]
2023-03-17T10:38:16.775+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 48, CreateTime = 1679045895772, serialized key size = -1, serialized value size = 61, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "8888"})
2023-03-17T10:38:16.777+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:38:16.777+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=8888  ]
2023-03-17T10:38:16.777+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T10:38:16.777+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=8888, callStartTimestamp=660, callEndTimestamp=700, callDuration=40]
2023-03-17T10:38:16.778+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 8888
2023-03-17T10:38:16.778+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : null
2023-03-17T10:38:16.788+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-03-17T10:38:16.797+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-03-17T10:38:16.809+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T10:38:16.810+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T10:38:16.810+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679045896809
2023-03-17T10:38:16.816+01:00  INFO 11000 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T10:38:16.817+01:00  INFO 11000 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T10:38:16.817+01:00  INFO 11000 --- [kafka-producer-network-thread | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 13 with epoch 0
2023-03-17T10:38:16.832+01:00  INFO 11000 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 56, CreateTime = 1679045896817, serialized key size = -1, serialized value size = 88, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = ResponseMsg [callId=8888, callStartTimestamp=660, callEndTimestamp=700, callDuration=40])
2023-03-17T10:40:17.618+01:00  INFO 26960 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 26960 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T10:40:17.621+01:00  INFO 26960 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T10:40:18.078+01:00  INFO 26960 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T10:40:18.097+01:00  INFO 26960 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T10:40:19.151+01:00  INFO 26960 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T10:40:19.293+01:00  INFO 26960 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T10:40:19.294+01:00  INFO 26960 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T10:40:19.294+01:00  INFO 26960 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679046019292
2023-03-17T10:40:19.552+01:00  INFO 26960 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T10:40:19.555+01:00  INFO 26960 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T10:40:19.556+01:00  INFO 26960 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T10:40:19.556+01:00  INFO 26960 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T10:40:19.560+01:00  INFO 26960 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T10:40:19.560+01:00  INFO 26960 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T10:40:19.561+01:00  INFO 26960 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T10:40:19.586+01:00  INFO 26960 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T10:40:19.623+01:00  INFO 26960 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T10:40:19.623+01:00  INFO 26960 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T10:40:19.623+01:00  INFO 26960 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679046019623
2023-03-17T10:40:19.625+01:00  INFO 26960 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T10:40:19.632+01:00  INFO 26960 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T10:40:19.640+01:00  INFO 26960 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T10:40:19.640+01:00  INFO 26960 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T10:40:19.640+01:00  INFO 26960 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679046019640
2023-03-17T10:40:19.641+01:00  INFO 26960 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T10:40:19.645+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T10:40:19.646+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T10:40:19.646+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T10:40:19.648+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T10:40:19.648+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T10:40:19.649+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T10:40:19.649+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T10:40:19.652+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T10:40:19.652+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T10:40:19.653+01:00  INFO 26960 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.432 seconds (process running for 2.805)
2023-03-17T10:40:19.668+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-40c08228-61c5-4ec1-8caf-6bd2129f2948
2023-03-17T10:40:19.668+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-61127b1d-c920-4e25-ad63-c4cba1064fc9
2023-03-17T10:40:19.668+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T10:40:19.668+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T10:40:19.669+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T10:40:19.669+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T10:40:21.834+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=18, memberId='consumer-springkafkatask33;-2-61127b1d-c920-4e25-ad63-c4cba1064fc9', protocol='range'}
2023-03-17T10:40:21.834+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=18, memberId='consumer-springkafkatask33;-1-40c08228-61c5-4ec1-8caf-6bd2129f2948', protocol='range'}
2023-03-17T10:40:21.838+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T10:40:21.842+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Finished assignment for group at generation 18: {consumer-springkafkatask33;-1-40c08228-61c5-4ec1-8caf-6bd2129f2948=Assignment(partitions=[topicTask1-0, topicTask1-1]), consumer-springkafkatask33;-2-61127b1d-c920-4e25-ad63-c4cba1064fc9=Assignment(partitions=[topicTask2-0])}
2023-03-17T10:40:21.847+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=18, memberId='consumer-springkafkatask33;-1-40c08228-61c5-4ec1-8caf-6bd2129f2948', protocol='range'}
2023-03-17T10:40:21.847+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=18, memberId='consumer-springkafkatask33;-2-61127b1d-c920-4e25-ad63-c4cba1064fc9', protocol='range'}
2023-03-17T10:40:21.848+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T10:40:21.848+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T10:40:21.850+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T10:40:21.850+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T10:40:21.861+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T10:40:21.861+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=57, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T10:40:21.862+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=49, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T10:40:21.863+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T10:40:21.863+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T10:40:29.026+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 49, CreateTime = 1679046027999, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e)
2023-03-17T10:40:29.036+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:40:29.036+01:00 ERROR 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T10:40:40.441+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 50, CreateTime = 1679046039430, serialized key size = -1, serialized value size = 63, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "660", "callId" : "8888"})
2023-03-17T10:40:40.473+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:40:40.473+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=660, callId=8888  ]
2023-03-17T10:40:40.473+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=START, timestamp=660, callId=8888  ]
2023-03-17T10:40:52.139+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 51, CreateTime = 1679046051131, serialized key size = -1, serialized value size = 61, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "8888"})
2023-03-17T10:40:52.140+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:40:52.140+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=8888  ]
2023-03-17T10:40:52.140+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T10:40:52.141+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=8888, callStartTimestamp=660, callEndTimestamp=700, callDuration=40]
2023-03-17T10:40:52.141+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 8888
2023-03-17T10:40:52.141+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : ResponseMsg [callId=8888, callStartTimestamp=660, callEndTimestamp=700, callDuration=40]
2023-03-17T10:40:52.141+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:40:52.152+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T10:40:52.335+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection org.postgresql.jdbc.PgConnection@55ea3b5
2023-03-17T10:40:52.337+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2023-03-17T10:40:52.371+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-03-17T10:40:52.381+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-03-17T10:40:52.396+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T10:40:52.396+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T10:40:52.397+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679046052396
2023-03-17T10:40:52.403+01:00  INFO 26960 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T10:40:52.407+01:00  INFO 26960 --- [kafka-producer-network-thread | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 14 with epoch 0
2023-03-17T10:40:52.409+01:00  INFO 26960 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T10:40:52.431+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 57, CreateTime = 1679046052412, serialized key size = -1, serialized value size = 88, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = ResponseMsg [callId=8888, callStartTimestamp=660, callEndTimestamp=700, callDuration=40])
2023-03-17T10:43:42.205+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 52, CreateTime = 1679046221190, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e)
2023-03-17T10:43:42.206+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:43:42.206+01:00 ERROR 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T10:44:02.716+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 53, CreateTime = 1679046241713, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "200", "callId" : "100"})
2023-03-17T10:44:02.718+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:44:02.718+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=200, callId=100  ]
2023-03-17T10:44:02.718+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=START, timestamp=200, callId=100  ]
2023-03-17T10:44:10.823+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 54, CreateTime = 1679046249813, serialized key size = -1, serialized value size = 60, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "100"})
2023-03-17T10:44:10.824+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:44:10.824+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=100  ]
2023-03-17T10:44:10.825+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T10:44:10.825+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=100, callStartTimestamp=200, callEndTimestamp=700, callDuration=500]
2023-03-17T10:44:10.825+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 100
2023-03-17T10:44:10.825+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : ResponseMsg [callId=100, callStartTimestamp=200, callEndTimestamp=700, callDuration=500]
2023-03-17T10:44:10.825+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:44:10.830+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 58, CreateTime = 1679046250827, serialized key size = -1, serialized value size = 88, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = ResponseMsg [callId=100, callStartTimestamp=200, callEndTimestamp=700, callDuration=500])
2023-03-17T10:45:10.438+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 55, CreateTime = 1679046309426, serialized key size = -1, serialized value size = 60, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "101"})
2023-03-17T10:45:10.439+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:45:10.439+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=101  ]
2023-03-17T10:45:10.439+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : scheduleMessageDelete is called
2023-03-17T10:45:10.440+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=END, timestamp=700, callId=101  ]
2023-03-17T10:45:16.478+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 56, CreateTime = 1679046315468, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "200", "callId" : "101"})
2023-03-17T10:45:16.479+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:45:16.479+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=200, callId=101  ]
2023-03-17T10:45:16.480+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T10:45:16.480+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=101, callStartTimestamp=200, callEndTimestamp=700, callDuration=500]
2023-03-17T10:45:16.480+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 101
2023-03-17T10:45:16.480+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : ResponseMsg [callId=101, callStartTimestamp=200, callEndTimestamp=700, callDuration=500]
2023-03-17T10:45:16.480+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:45:16.486+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 59, CreateTime = 1679046316483, serialized key size = -1, serialized value size = 88, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = ResponseMsg [callId=101, callStartTimestamp=200, callEndTimestamp=700, callDuration=500])
2023-03-17T10:46:37.323+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 57, CreateTime = 1679046396319, serialized key size = -1, serialized value size = 60, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "102"})
2023-03-17T10:46:37.323+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:46:37.324+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=102  ]
2023-03-17T10:46:37.325+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : scheduleMessageDelete is called
2023-03-17T10:46:37.325+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=END, timestamp=700, callId=102  ]
2023-03-17T10:46:40.544+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 58, CreateTime = 1679046399528, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "200", "callId" : "102"})
2023-03-17T10:46:40.546+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:46:40.546+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=200, callId=102  ]
2023-03-17T10:46:40.546+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T10:46:40.546+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=102, callStartTimestamp=200, callEndTimestamp=700, callDuration=500]
2023-03-17T10:46:40.546+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 102
2023-03-17T10:46:40.546+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : ResponseMsg [callId=102, callStartTimestamp=200, callEndTimestamp=700, callDuration=500]
2023-03-17T10:46:40.546+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:46:40.550+01:00  WARN 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Failed to validate connection org.postgresql.jdbc.PgConnection@55ea3b5 (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2023-03-17T10:46:40.551+01:00  WARN 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Failed to validate connection org.postgresql.jdbc.PgConnection@4d802071 (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2023-03-17T10:46:40.552+01:00  WARN 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Failed to validate connection org.postgresql.jdbc.PgConnection@5dc5c5ea (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2023-03-17T10:46:40.553+01:00  WARN 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Failed to validate connection org.postgresql.jdbc.PgConnection@1630871 (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2023-03-17T10:46:40.553+01:00  WARN 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Failed to validate connection org.postgresql.jdbc.PgConnection@2e62ecc8 (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2023-03-17T10:46:40.554+01:00  WARN 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Failed to validate connection org.postgresql.jdbc.PgConnection@62add2dd (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2023-03-17T10:46:40.554+01:00  WARN 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Failed to validate connection org.postgresql.jdbc.PgConnection@11b4b1f7 (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2023-03-17T10:46:40.554+01:00  WARN 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Failed to validate connection org.postgresql.jdbc.PgConnection@88d1330 (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2023-03-17T10:46:40.554+01:00  WARN 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Failed to validate connection org.postgresql.jdbc.PgConnection@3130ba45 (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2023-03-17T10:46:40.555+01:00  WARN 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Failed to validate connection org.postgresql.jdbc.PgConnection@3d87ad84 (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2023-03-17T10:47:10.554+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Put message to Cache!
2023-03-17T10:47:10.555+01:00 ERROR 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Fail to send message to database Failed to obtain JDBC Connection
2023-03-17T10:47:10.558+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 60, CreateTime = 1679046430555, serialized key size = -1, serialized value size = 88, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = ResponseMsg [callId=102, callStartTimestamp=200, callEndTimestamp=700, callDuration=500])
2023-03-17T10:47:10.558+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 59, CreateTime = 1679046426470, serialized key size = -1, serialized value size = 60, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "103"})
2023-03-17T10:47:10.559+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:47:10.560+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=103  ]
2023-03-17T10:47:10.560+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : scheduleMessageDelete is called
2023-03-17T10:47:10.560+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=END, timestamp=700, callId=103  ]
2023-03-17T10:47:10.603+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 60, CreateTime = 1679046429595, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "200", "callId" : "103"})
2023-03-17T10:47:10.604+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:47:10.605+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=200, callId=103  ]
2023-03-17T10:47:10.605+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T10:47:10.605+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=103, callStartTimestamp=200, callEndTimestamp=700, callDuration=500]
2023-03-17T10:47:10.605+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 103
2023-03-17T10:47:10.605+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : ResponseMsg [callId=103, callStartTimestamp=200, callEndTimestamp=700, callDuration=500]
2023-03-17T10:47:10.605+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Put message to Cache!
2023-03-17T10:47:10.609+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 61, CreateTime = 1679046430605, serialized key size = -1, serialized value size = 88, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = ResponseMsg [callId=103, callStartTimestamp=200, callEndTimestamp=700, callDuration=500])
2023-03-17T10:47:13.744+01:00  INFO 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:47:16.544+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 61, CreateTime = 1679046435538, serialized key size = -1, serialized value size = 60, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "104"})
2023-03-17T10:47:16.545+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:47:16.545+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=104  ]
2023-03-17T10:47:16.546+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : scheduleMessageDelete is called
2023-03-17T10:47:16.546+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=END, timestamp=700, callId=104  ]
2023-03-17T10:47:19.093+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 62, CreateTime = 1679046438089, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "200", "callId" : "105"})
2023-03-17T10:47:19.094+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:47:19.094+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=200, callId=105  ]
2023-03-17T10:47:19.094+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=START, timestamp=200, callId=105  ]
2023-03-17T10:47:35.139+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 63, CreateTime = 1679046454135, serialized key size = -1, serialized value size = 60, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "106"})
2023-03-17T10:47:35.140+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:47:35.141+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=106  ]
2023-03-17T10:47:35.141+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : scheduleMessageDelete is called
2023-03-17T10:47:35.142+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=END, timestamp=700, callId=106  ]
2023-03-17T10:47:39.703+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 64, CreateTime = 1679046458695, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "200", "callId" : "106"})
2023-03-17T10:47:39.703+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T10:47:39.704+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=200, callId=106  ]
2023-03-17T10:47:39.704+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T10:47:39.704+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=106, callStartTimestamp=200, callEndTimestamp=700, callDuration=500]
2023-03-17T10:47:39.704+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 106
2023-03-17T10:47:39.705+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : ResponseMsg [callId=106, callStartTimestamp=200, callEndTimestamp=700, callDuration=500]
2023-03-17T10:47:39.705+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Put message to Cache!
2023-03-17T10:47:39.707+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask2, partition = 0, leaderEpoch = 0, offset = 62, CreateTime = 1679046459705, serialized key size = -1, serialized value size = 88, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = ResponseMsg [callId=106, callStartTimestamp=200, callEndTimestamp=700, callDuration=500])
2023-03-17T10:47:43.752+01:00 ERROR 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:83) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:62) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$0(DatabaseMessageHandler.java:116) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: java.sql.SQLTransientConnectionException: HikariPool-1 - Connection is not available, request timed out after 30007ms.
	at com.zaxxer.hikari.pool.HikariPool.createTimeoutException(HikariPool.java:696) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:181) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:146) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:128) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	... 12 common frames omitted
Caused by: org.postgresql.util.PSQLException: Connection to localhost:5432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:319) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.Driver.makeConnection(Driver.java:434) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.Driver.connect(Driver.java:291) ~[postgresql-42.5.1.jar:42.5.1]
	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:138) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:359) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.newPoolEntry(PoolBase.java:201) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.createPoolEntry(HikariPool.java:470) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:733) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:712) ~[HikariCP-5.0.1.jar:na]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	... 3 common frames omitted
Caused by: java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method) ~[na:na]
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672) ~[na:na]
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542) ~[na:na]
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597) ~[na:na]
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327) ~[na:na]
	at java.base/java.net.Socket.connect(Socket.java:633) ~[na:na]
	at org.postgresql.core.PGStream.createSocket(PGStream.java:241) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.PGStream.<init>(PGStream.java:98) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:109) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235) ~[postgresql-42.5.1.jar:42.5.1]
	... 14 common frames omitted

2023-03-17T10:47:43.757+01:00  INFO 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:48:13.762+01:00 ERROR 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:83) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:62) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$0(DatabaseMessageHandler.java:116) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: java.sql.SQLTransientConnectionException: HikariPool-1 - Connection is not available, request timed out after 30003ms.
	at com.zaxxer.hikari.pool.HikariPool.createTimeoutException(HikariPool.java:696) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:181) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:146) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:128) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	... 12 common frames omitted
Caused by: org.postgresql.util.PSQLException: Connection to localhost:5432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:319) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.Driver.makeConnection(Driver.java:434) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.Driver.connect(Driver.java:291) ~[postgresql-42.5.1.jar:42.5.1]
	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:138) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:359) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.newPoolEntry(PoolBase.java:201) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.createPoolEntry(HikariPool.java:470) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:733) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:712) ~[HikariCP-5.0.1.jar:na]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	... 3 common frames omitted
Caused by: java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method) ~[na:na]
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672) ~[na:na]
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542) ~[na:na]
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597) ~[na:na]
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327) ~[na:na]
	at java.base/java.net.Socket.connect(Socket.java:633) ~[na:na]
	at org.postgresql.core.PGStream.createSocket(PGStream.java:241) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.PGStream.<init>(PGStream.java:98) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:109) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235) ~[postgresql-42.5.1.jar:42.5.1]
	... 14 common frames omitted

2023-03-17T10:48:13.762+01:00  INFO 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:48:16.560+01:00  INFO 26960 --- [pool-1-thread-3] c.s.task.cache.EventMessageCache         : Message schedule for delete: EventMessage: [ callStatus=END, timestamp=700, callId=104  ]
2023-03-17T10:48:43.775+01:00 ERROR 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:83) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:62) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$0(DatabaseMessageHandler.java:116) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: java.sql.SQLTransientConnectionException: HikariPool-1 - Connection is not available, request timed out after 30011ms.
	at com.zaxxer.hikari.pool.HikariPool.createTimeoutException(HikariPool.java:696) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:181) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:146) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:128) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	... 12 common frames omitted
Caused by: org.postgresql.util.PSQLException: Connection to localhost:5432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:319) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.Driver.makeConnection(Driver.java:434) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.Driver.connect(Driver.java:291) ~[postgresql-42.5.1.jar:42.5.1]
	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:138) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:359) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.newPoolEntry(PoolBase.java:201) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.createPoolEntry(HikariPool.java:470) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:733) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:712) ~[HikariCP-5.0.1.jar:na]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	... 3 common frames omitted
Caused by: java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method) ~[na:na]
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672) ~[na:na]
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542) ~[na:na]
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597) ~[na:na]
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327) ~[na:na]
	at java.base/java.net.Socket.connect(Socket.java:633) ~[na:na]
	at org.postgresql.core.PGStream.createSocket(PGStream.java:241) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.PGStream.<init>(PGStream.java:98) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:109) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235) ~[postgresql-42.5.1.jar:42.5.1]
	... 14 common frames omitted

2023-03-17T10:48:43.776+01:00  INFO 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:49:13.792+01:00 ERROR 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:83) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:62) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$0(DatabaseMessageHandler.java:116) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: java.sql.SQLTransientConnectionException: HikariPool-1 - Connection is not available, request timed out after 30015ms.
	at com.zaxxer.hikari.pool.HikariPool.createTimeoutException(HikariPool.java:696) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:181) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:146) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:128) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	... 12 common frames omitted
Caused by: org.postgresql.util.PSQLException: Connection to localhost:5432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:319) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.Driver.makeConnection(Driver.java:434) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.Driver.connect(Driver.java:291) ~[postgresql-42.5.1.jar:42.5.1]
	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:138) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:359) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.newPoolEntry(PoolBase.java:201) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.createPoolEntry(HikariPool.java:470) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:733) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:712) ~[HikariCP-5.0.1.jar:na]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	... 3 common frames omitted
Caused by: java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method) ~[na:na]
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672) ~[na:na]
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542) ~[na:na]
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597) ~[na:na]
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327) ~[na:na]
	at java.base/java.net.Socket.connect(Socket.java:633) ~[na:na]
	at org.postgresql.core.PGStream.createSocket(PGStream.java:241) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.PGStream.<init>(PGStream.java:98) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:109) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235) ~[postgresql-42.5.1.jar:42.5.1]
	... 14 common frames omitted

2023-03-17T10:49:13.796+01:00  INFO 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:49:19.903+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T10:49:19.903+01:00  INFO 26960 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Node -1 disconnected.
2023-03-17T10:49:43.803+01:00 ERROR 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : FAILD TO AGAIN SEND TO DB

org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:83) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:646) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:960) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1015) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:1025) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at com.springkafka.task.DatabaseMessageHandler.saveResponseMessageToDatabase(DatabaseMessageHandler.java:62) ~[classes/:na]
	at com.springkafka.task.DatabaseMessageHandler.lambda$0(DatabaseMessageHandler.java:116) ~[classes/:na]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: java.sql.SQLTransientConnectionException: HikariPool-1 - Connection is not available, request timed out after 30006ms.
	at com.zaxxer.hikari.pool.HikariPool.createTimeoutException(HikariPool.java:696) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:181) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:146) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:128) ~[HikariCP-5.0.1.jar:na]
	at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:159) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:117) ~[spring-jdbc-6.0.3.jar:6.0.3]
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80) ~[spring-jdbc-6.0.3.jar:6.0.3]
	... 12 common frames omitted
Caused by: org.postgresql.util.PSQLException: Connection to localhost:5432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:319) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.Driver.makeConnection(Driver.java:434) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.Driver.connect(Driver.java:291) ~[postgresql-42.5.1.jar:42.5.1]
	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:138) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:359) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.PoolBase.newPoolEntry(PoolBase.java:201) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool.createPoolEntry(HikariPool.java:470) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:733) ~[HikariCP-5.0.1.jar:na]
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:712) ~[HikariCP-5.0.1.jar:na]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	... 3 common frames omitted
Caused by: java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method) ~[na:na]
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672) ~[na:na]
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542) ~[na:na]
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597) ~[na:na]
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327) ~[na:na]
	at java.base/java.net.Socket.connect(Socket.java:633) ~[na:na]
	at org.postgresql.core.PGStream.createSocket(PGStream.java:241) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.PGStream.<init>(PGStream.java:98) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:109) ~[postgresql-42.5.1.jar:42.5.1]
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235) ~[postgresql-42.5.1.jar:42.5.1]
	... 14 common frames omitted

2023-03-17T10:49:43.804+01:00  INFO 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:49:51.625+01:00  INFO 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:49:51.626+01:00  INFO 26960 --- [pool-2-thread-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T10:50:09.733+01:00  INFO 26960 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient   : [Producer clientId=producer-1] Node -1 disconnected.
2023-03-17T10:50:16.576+01:00  INFO 26960 --- [pool-1-thread-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 104
2023-03-17T10:50:16.576+01:00  INFO 26960 --- [pool-1-thread-1] c.s.task.cache.EventMessageCache         : Message is deleted via schedule
2023-03-17T11:27:18.134+01:00  INFO 28268 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 28268 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T11:27:18.137+01:00  INFO 28268 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T11:27:18.583+01:00  INFO 28268 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T11:27:18.602+01:00  INFO 28268 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T11:27:19.605+01:00  INFO 28268 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T11:27:19.738+01:00  INFO 28268 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:27:19.740+01:00  INFO 28268 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:27:19.740+01:00  INFO 28268 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679048839737
2023-03-17T11:27:20.008+01:00  INFO 28268 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T11:27:20.012+01:00  INFO 28268 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T11:27:20.013+01:00  INFO 28268 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T11:27:20.013+01:00  INFO 28268 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T11:27:20.018+01:00  INFO 28268 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T11:27:20.019+01:00  INFO 28268 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T11:27:20.020+01:00  INFO 28268 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T11:27:20.051+01:00  INFO 28268 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T11:27:20.099+01:00  INFO 28268 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:27:20.099+01:00  INFO 28268 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:27:20.099+01:00  INFO 28268 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679048840099
2023-03-17T11:27:20.102+01:00  INFO 28268 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T11:27:20.112+01:00  INFO 28268 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T11:27:20.121+01:00  INFO 28268 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:27:20.121+01:00  INFO 28268 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:27:20.121+01:00  INFO 28268 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679048840120
2023-03-17T11:27:20.122+01:00  INFO 28268 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T11:27:20.131+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T11:27:20.130+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T11:27:20.132+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T11:27:20.133+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T11:27:20.133+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T11:27:20.135+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T11:27:20.135+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T11:27:20.138+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:27:20.138+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:27:20.141+01:00  INFO 28268 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.412 seconds (process running for 2.754)
2023-03-17T11:27:20.162+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-9747d040-5d59-4483-9132-94b9ec588b94
2023-03-17T11:27:20.162+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-4ad14594-37df-4d82-a91e-bb4af211e309
2023-03-17T11:27:20.163+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T11:27:20.163+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T11:27:20.164+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:27:20.164+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:27:20.167+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=20, memberId='consumer-springkafkatask33;-1-9747d040-5d59-4483-9132-94b9ec588b94', protocol='range'}
2023-03-17T11:27:20.167+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=20, memberId='consumer-springkafkatask33;-2-4ad14594-37df-4d82-a91e-bb4af211e309', protocol='range'}
2023-03-17T11:27:20.172+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T11:27:20.173+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T11:27:20.177+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Finished assignment for group at generation 20: {consumer-springkafkatask33;-1-9747d040-5d59-4483-9132-94b9ec588b94=Assignment(partitions=[topicTask1-0, topicTask1-1]), consumer-springkafkatask33;-2-4ad14594-37df-4d82-a91e-bb4af211e309=Assignment(partitions=[topicTask2-0])}
2023-03-17T11:27:20.185+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=20, memberId='consumer-springkafkatask33;-1-9747d040-5d59-4483-9132-94b9ec588b94', protocol='range'}
2023-03-17T11:27:20.185+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=20, memberId='consumer-springkafkatask33;-2-4ad14594-37df-4d82-a91e-bb4af211e309', protocol='range'}
2023-03-17T11:27:20.186+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T11:27:20.186+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T11:27:20.188+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T11:27:20.188+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T11:27:20.201+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=63, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T11:27:20.201+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T11:27:20.202+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=65, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T11:27:20.203+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T11:27:20.203+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T11:27:32.104+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 65, CreateTime = 1679048851089, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e)
2023-03-17T11:27:32.111+01:00 ERROR 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : Message need be in JSON format! 
2023-03-17T11:27:32.111+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T11:27:32.111+01:00 ERROR 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T11:27:51.311+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 66, CreateTime = 1679048870300, serialized key size = -1, serialized value size = 63, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "-200", "callId" : "110"})
2023-03-17T11:27:51.339+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T11:27:51.340+01:00 ERROR 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T11:28:02.190+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 67, CreateTime = 1679048881173, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "300", "callId" : "110"})
2023-03-17T11:28:02.192+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T11:28:02.192+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=300, callId=110  ]
2023-03-17T11:28:02.192+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=START, timestamp=300, callId=110  ]
2023-03-17T11:28:23.016+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 68, CreateTime = 1679048902004, serialized key size = -1, serialized value size = 60, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "110"})
2023-03-17T11:28:23.017+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T11:28:23.018+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=110  ]
2023-03-17T11:28:23.018+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T11:28:23.018+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=110, callStartTimestamp=300, callEndTimestamp=700, callDuration=400]
2023-03-17T11:28:23.018+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 110
2023-03-17T11:28:23.018+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : ResponseMsg [callId=110, callStartTimestamp=300, callEndTimestamp=700, callDuration=400]
2023-03-17T11:28:23.018+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T11:28:23.022+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T11:28:23.201+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection org.postgresql.jdbc.PgConnection@875244f
2023-03-17T11:28:23.203+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2023-03-17T11:28:23.226+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-03-17T11:28:23.235+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-03-17T11:28:23.249+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:28:23.250+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:28:23.250+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679048903249
2023-03-17T11:28:23.257+01:00  INFO 28268 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T11:28:23.257+01:00  INFO 28268 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T11:28:23.258+01:00  INFO 28268 --- [kafka-producer-network-thread | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 15 with epoch 0
2023-03-17T11:28:23.276+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : Messages from topic 2 
2023-03-17T11:28:34.770+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 69, CreateTime = 1679048913763, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "300", "callId" : "111"})
2023-03-17T11:28:34.771+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T11:28:34.772+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=300, callId=111  ]
2023-03-17T11:28:34.772+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=START, timestamp=300, callId=111  ]
2023-03-17T11:28:42.346+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 70, CreateTime = 1679048921342, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "301", "callId" : "111"})
2023-03-17T11:28:42.347+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T11:28:42.347+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=301, callId=111  ]
2023-03-17T11:28:42.348+01:00 ERROR 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Receive duplicate event
2023-03-17T11:28:45.522+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 71, CreateTime = 1679048924508, serialized key size = -1, serialized value size = 60, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "111"})
2023-03-17T11:28:45.523+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T11:28:45.524+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=111  ]
2023-03-17T11:28:45.524+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T11:28:45.524+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=111, callStartTimestamp=301, callEndTimestamp=700, callDuration=399]
2023-03-17T11:28:45.524+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 111
2023-03-17T11:28:45.524+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : ResponseMsg [callId=111, callStartTimestamp=301, callEndTimestamp=700, callDuration=399]
2023-03-17T11:28:45.524+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T11:28:45.529+01:00  INFO 28268 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : Messages from topic 2 
2023-03-17T11:37:22.866+01:00  INFO 8076 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 8076 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T11:37:22.869+01:00  INFO 8076 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T11:37:23.339+01:00  INFO 8076 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T11:37:23.359+01:00  INFO 8076 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T11:37:23.903+01:00  INFO 8076 --- [main] com.springkafka.task.EventKafkaFlow      : Message call status need be: [
2023-03-17T11:37:24.376+01:00  INFO 8076 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T11:37:24.512+01:00  INFO 8076 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:37:24.512+01:00  INFO 8076 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:37:24.512+01:00  INFO 8076 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679049444511
2023-03-17T11:37:24.764+01:00  INFO 8076 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T11:37:24.768+01:00  INFO 8076 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T11:37:24.768+01:00  INFO 8076 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T11:37:24.768+01:00  INFO 8076 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T11:37:24.772+01:00  INFO 8076 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T11:37:24.773+01:00  INFO 8076 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T11:37:24.773+01:00  INFO 8076 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T11:37:24.799+01:00  INFO 8076 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T11:37:24.834+01:00  INFO 8076 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:37:24.835+01:00  INFO 8076 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:37:24.835+01:00  INFO 8076 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679049444834
2023-03-17T11:37:24.837+01:00  INFO 8076 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T11:37:24.844+01:00  INFO 8076 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T11:37:24.851+01:00  INFO 8076 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:37:24.852+01:00  INFO 8076 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:37:24.852+01:00  INFO 8076 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679049444851
2023-03-17T11:37:24.853+01:00  INFO 8076 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T11:37:24.859+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T11:37:24.859+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T11:37:24.860+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T11:37:24.861+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T11:37:24.861+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T11:37:24.862+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T11:37:24.862+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T11:37:24.866+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:37:24.866+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:37:24.868+01:00  INFO 8076 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.39 seconds (process running for 2.736)
2023-03-17T11:37:24.887+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-2ec8ed41-df2d-45b3-bcc8-166b7b0294eb
2023-03-17T11:37:24.888+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-b471811d-e0b0-4cd5-83fd-e17dca20b89a
2023-03-17T11:37:24.888+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T11:37:24.888+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T11:37:24.888+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:37:24.888+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:37:24.891+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=22, memberId='consumer-springkafkatask33;-1-b471811d-e0b0-4cd5-83fd-e17dca20b89a', protocol='range'}
2023-03-17T11:37:24.891+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=22, memberId='consumer-springkafkatask33;-2-2ec8ed41-df2d-45b3-bcc8-166b7b0294eb', protocol='range'}
2023-03-17T11:37:24.896+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T11:37:24.899+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Finished assignment for group at generation 22: {consumer-springkafkatask33;-1-b471811d-e0b0-4cd5-83fd-e17dca20b89a=Assignment(partitions=[topicTask1-0, topicTask1-1]), consumer-springkafkatask33;-2-2ec8ed41-df2d-45b3-bcc8-166b7b0294eb=Assignment(partitions=[topicTask2-0])}
2023-03-17T11:37:24.904+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=22, memberId='consumer-springkafkatask33;-1-b471811d-e0b0-4cd5-83fd-e17dca20b89a', protocol='range'}
2023-03-17T11:37:24.904+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=22, memberId='consumer-springkafkatask33;-2-2ec8ed41-df2d-45b3-bcc8-166b7b0294eb', protocol='range'}
2023-03-17T11:37:24.905+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T11:37:24.905+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T11:37:24.907+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T11:37:24.907+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T11:37:24.922+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T11:37:24.922+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=65, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T11:37:24.922+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=72, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T11:37:24.923+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T11:37:24.923+01:00  INFO 8076 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T11:39:28.607+01:00  INFO 29780 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 29780 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T11:39:28.609+01:00  INFO 29780 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T11:39:29.101+01:00  INFO 29780 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T11:39:29.122+01:00  INFO 29780 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T11:39:29.662+01:00  INFO 29780 --- [main] com.springkafka.task.EventKafkaFlow      : Message call status need be: [
2023-03-17T11:39:30.145+01:00  INFO 29780 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T11:39:30.283+01:00  INFO 29780 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:39:30.283+01:00  INFO 29780 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:39:30.283+01:00  INFO 29780 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679049570282
2023-03-17T11:39:30.531+01:00  INFO 29780 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T11:39:30.535+01:00  INFO 29780 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T11:39:30.535+01:00  INFO 29780 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T11:39:30.536+01:00  INFO 29780 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T11:39:30.544+01:00  INFO 29780 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T11:39:30.545+01:00  INFO 29780 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T11:39:30.546+01:00  INFO 29780 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T11:39:30.569+01:00  INFO 29780 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T11:39:30.607+01:00  INFO 29780 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:39:30.608+01:00  INFO 29780 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:39:30.608+01:00  INFO 29780 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679049570607
2023-03-17T11:39:30.610+01:00  INFO 29780 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T11:39:30.617+01:00  INFO 29780 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T11:39:30.624+01:00  INFO 29780 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:39:30.625+01:00  INFO 29780 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:39:30.626+01:00  INFO 29780 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679049570624
2023-03-17T11:39:30.626+01:00  INFO 29780 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T11:39:30.633+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T11:39:30.633+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T11:39:30.634+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T11:39:30.635+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T11:39:30.635+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T11:39:30.637+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T11:39:30.637+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T11:39:30.640+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:39:30.640+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:39:30.640+01:00  INFO 29780 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.446 seconds (process running for 2.806)
2023-03-17T11:39:30.655+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-21fa16d6-0085-48af-98d5-afffaa544962
2023-03-17T11:39:30.655+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-364d96e9-6f06-4a32-88b3-3c77d95bea6f
2023-03-17T11:39:30.656+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T11:39:30.656+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T11:39:30.656+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:39:30.656+01:00  INFO 29780 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:40:03.169+01:00  INFO 30436 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 30436 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T11:40:03.172+01:00  INFO 30436 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T11:40:03.635+01:00  INFO 30436 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T11:40:03.655+01:00  INFO 30436 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T11:40:04.673+01:00  INFO 30436 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T11:40:04.813+01:00  INFO 30436 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:40:04.815+01:00  INFO 30436 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:40:04.815+01:00  INFO 30436 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679049604812
2023-03-17T11:40:05.056+01:00  INFO 30436 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T11:40:05.059+01:00  INFO 30436 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T11:40:05.060+01:00  INFO 30436 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T11:40:05.060+01:00  INFO 30436 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T11:40:05.063+01:00  INFO 30436 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T11:40:05.064+01:00  INFO 30436 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T11:40:05.064+01:00  INFO 30436 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T11:40:05.087+01:00  INFO 30436 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T11:40:05.121+01:00  INFO 30436 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:40:05.122+01:00  INFO 30436 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:40:05.122+01:00  INFO 30436 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679049605121
2023-03-17T11:40:05.123+01:00  INFO 30436 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T11:40:05.131+01:00  INFO 30436 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T11:40:05.138+01:00  INFO 30436 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:40:05.139+01:00  INFO 30436 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:40:05.139+01:00  INFO 30436 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679049605138
2023-03-17T11:40:05.140+01:00  INFO 30436 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T11:40:05.145+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T11:40:05.146+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T11:40:05.147+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T11:40:05.147+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T11:40:05.147+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T11:40:05.148+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T11:40:05.148+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T11:40:05.151+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:40:05.151+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:40:05.156+01:00  INFO 30436 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.408 seconds (process running for 2.772)
2023-03-17T11:40:05.172+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-1ee6d71d-c5dc-4950-a9f2-4453731d5ccd
2023-03-17T11:40:05.172+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-e4de796e-52ce-4f30-9d11-2ec9daf98043
2023-03-17T11:40:05.172+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T11:40:05.172+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T11:40:05.173+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:40:05.173+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:40:10.213+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=23, memberId='consumer-springkafkatask33;-2-e4de796e-52ce-4f30-9d11-2ec9daf98043', protocol='range'}
2023-03-17T11:40:10.213+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=23, memberId='consumer-springkafkatask33;-1-1ee6d71d-c5dc-4950-a9f2-4453731d5ccd', protocol='range'}
2023-03-17T11:40:10.217+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T11:40:10.222+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Finished assignment for group at generation 23: {consumer-springkafkatask33;-2-e4de796e-52ce-4f30-9d11-2ec9daf98043=Assignment(partitions=[topicTask1-1]), consumer-springkafkatask33;-1-364d96e9-6f06-4a32-88b3-3c77d95bea6f=Assignment(partitions=[topicTask1-0]), consumer-springkafkatask33;-2-21fa16d6-0085-48af-98d5-afffaa544962=Assignment(partitions=[]), consumer-springkafkatask33;-1-1ee6d71d-c5dc-4950-a9f2-4453731d5ccd=Assignment(partitions=[topicTask2-0])}
2023-03-17T11:40:10.227+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=23, memberId='consumer-springkafkatask33;-1-1ee6d71d-c5dc-4950-a9f2-4453731d5ccd', protocol='range'}
2023-03-17T11:40:10.227+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=23, memberId='consumer-springkafkatask33;-2-e4de796e-52ce-4f30-9d11-2ec9daf98043', protocol='range'}
2023-03-17T11:40:10.228+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T11:40:10.228+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-1])
2023-03-17T11:40:10.231+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-1
2023-03-17T11:40:10.231+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T11:40:10.240+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=72, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T11:40:10.240+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=65, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T11:40:10.242+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T11:40:10.242+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-1]
2023-03-17T11:40:15.870+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 72, CreateTime = 1679049614846, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e)
2023-03-17T11:40:15.878+01:00 ERROR 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : Message need be in JSON format! 
2023-03-17T11:40:15.879+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T11:40:15.879+01:00 ERROR 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T11:40:23.602+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 73, CreateTime = 1679049622589, serialized key size = -1, serialized value size = 60, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "112"})
2023-03-17T11:40:23.631+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T11:40:23.631+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=112  ]
2023-03-17T11:40:23.632+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.cache.EventMessageCache         : scheduleMessageDelete is called
2023-03-17T11:40:23.632+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=END, timestamp=700, callId=112  ]
2023-03-17T11:40:27.176+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 74, CreateTime = 1679049626162, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "301", "callId" : "112"})
2023-03-17T11:40:27.177+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T11:40:27.177+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=301, callId=112  ]
2023-03-17T11:40:27.178+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T11:40:27.178+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=112, callStartTimestamp=301, callEndTimestamp=700, callDuration=399]
2023-03-17T11:40:27.178+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 112
2023-03-17T11:40:27.178+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : ResponseMsg [callId=112, callStartTimestamp=301, callEndTimestamp=700, callDuration=399]
2023-03-17T11:40:27.178+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T11:40:27.183+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T11:40:27.360+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection org.postgresql.jdbc.PgConnection@74725aac
2023-03-17T11:40:27.362+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2023-03-17T11:40:27.388+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-03-17T11:40:27.397+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-03-17T11:40:27.412+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T11:40:27.412+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T11:40:27.412+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679049627411
2023-03-17T11:40:27.418+01:00  INFO 30436 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T11:40:27.419+01:00  INFO 30436 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T11:40:27.420+01:00  INFO 30436 --- [kafka-producer-network-thread | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 16 with epoch 0
2023-03-17T11:40:27.435+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : Messages from topic 2 
2023-03-17T11:40:55.328+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: group is already rebalancing
2023-03-17T11:40:55.328+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: group is already rebalancing
2023-03-17T11:40:55.329+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Revoke previously assigned partitions topicTask2-0
2023-03-17T11:40:55.329+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Revoke previously assigned partitions topicTask1-1
2023-03-17T11:40:55.330+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions revoked: [topicTask2-0]
2023-03-17T11:40:55.330+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions revoked: [topicTask1-1]
2023-03-17T11:40:55.331+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:40:55.331+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T11:40:55.333+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=24, memberId='consumer-springkafkatask33;-1-1ee6d71d-c5dc-4950-a9f2-4453731d5ccd', protocol='range'}
2023-03-17T11:40:55.333+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=24, memberId='consumer-springkafkatask33;-2-e4de796e-52ce-4f30-9d11-2ec9daf98043', protocol='range'}
2023-03-17T11:40:55.829+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Finished assignment for group at generation 24: {consumer-springkafkatask33;-2-e4de796e-52ce-4f30-9d11-2ec9daf98043=Assignment(partitions=[topicTask1-0, topicTask1-1]), consumer-springkafkatask33;-1-1ee6d71d-c5dc-4950-a9f2-4453731d5ccd=Assignment(partitions=[topicTask2-0])}
2023-03-17T11:40:55.831+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=24, memberId='consumer-springkafkatask33;-2-e4de796e-52ce-4f30-9d11-2ec9daf98043', protocol='range'}
2023-03-17T11:40:55.831+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=24, memberId='consumer-springkafkatask33;-1-1ee6d71d-c5dc-4950-a9f2-4453731d5ccd', protocol='range'}
2023-03-17T11:40:55.832+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T11:40:55.832+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T11:40:55.832+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T11:40:55.832+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T11:40:55.833+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T11:40:55.833+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=66, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T11:40:55.833+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=75, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T11:40:55.833+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T11:40:55.833+01:00  INFO 30436 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T12:24:04.348+01:00  INFO 28424 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 28424 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T12:24:04.351+01:00  INFO 28424 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T12:24:04.813+01:00  INFO 28424 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T12:24:04.832+01:00  INFO 28424 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T12:24:05.866+01:00  INFO 28424 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T12:24:06.015+01:00  INFO 28424 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T12:24:06.016+01:00  INFO 28424 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T12:24:06.016+01:00  INFO 28424 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679052246014
2023-03-17T12:24:06.274+01:00  INFO 28424 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T12:24:06.277+01:00  INFO 28424 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T12:24:06.278+01:00  INFO 28424 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T12:24:06.278+01:00  INFO 28424 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T12:24:06.282+01:00  INFO 28424 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T12:24:06.283+01:00  INFO 28424 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T12:24:06.283+01:00  INFO 28424 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T12:24:06.307+01:00  INFO 28424 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T12:24:06.356+01:00  INFO 28424 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T12:24:06.356+01:00  INFO 28424 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T12:24:06.356+01:00  INFO 28424 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679052246356
2023-03-17T12:24:06.358+01:00  INFO 28424 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T12:24:06.369+01:00  INFO 28424 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T12:24:06.376+01:00  INFO 28424 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T12:24:06.376+01:00  INFO 28424 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T12:24:06.376+01:00  INFO 28424 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679052246376
2023-03-17T12:24:06.377+01:00  INFO 28424 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T12:24:06.390+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T12:24:06.390+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T12:24:06.391+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T12:24:06.392+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T12:24:06.392+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T12:24:06.393+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T12:24:06.393+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T12:24:06.393+01:00  INFO 28424 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.451 seconds (process running for 2.798)
2023-03-17T12:24:06.396+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:24:06.396+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:24:06.414+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-ca8482f7-7ce1-4453-8c28-34addb73d68f
2023-03-17T12:24:06.414+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-ffaaa0bd-a6a0-4bb7-8547-4aab41bc5987
2023-03-17T12:24:06.415+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T12:24:06.415+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T12:24:06.415+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:24:06.415+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:24:06.418+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=26, memberId='consumer-springkafkatask33;-2-ca8482f7-7ce1-4453-8c28-34addb73d68f', protocol='range'}
2023-03-17T12:24:06.418+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=26, memberId='consumer-springkafkatask33;-1-ffaaa0bd-a6a0-4bb7-8547-4aab41bc5987', protocol='range'}
2023-03-17T12:24:06.423+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T12:24:06.427+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Finished assignment for group at generation 26: {consumer-springkafkatask33;-1-ffaaa0bd-a6a0-4bb7-8547-4aab41bc5987=Assignment(partitions=[topicTask1-0, topicTask1-1]), consumer-springkafkatask33;-2-ca8482f7-7ce1-4453-8c28-34addb73d68f=Assignment(partitions=[topicTask2-0])}
2023-03-17T12:24:06.434+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=26, memberId='consumer-springkafkatask33;-1-ffaaa0bd-a6a0-4bb7-8547-4aab41bc5987', protocol='range'}
2023-03-17T12:24:06.434+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=26, memberId='consumer-springkafkatask33;-2-ca8482f7-7ce1-4453-8c28-34addb73d68f', protocol='range'}
2023-03-17T12:24:06.435+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T12:24:06.435+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T12:24:06.439+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T12:24:06.439+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T12:24:06.454+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T12:24:06.454+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=66, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T12:24:06.454+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=75, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T12:24:06.456+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T12:24:06.456+01:00  INFO 28424 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T12:24:16.028+01:00  INFO 30624 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 30624 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T12:24:16.030+01:00  INFO 30624 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T12:24:16.523+01:00  INFO 30624 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T12:24:16.547+01:00  INFO 30624 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T12:24:17.572+01:00  INFO 30624 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T12:24:17.718+01:00  INFO 30624 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T12:24:17.720+01:00  INFO 30624 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T12:24:17.720+01:00  INFO 30624 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679052257717
2023-03-17T12:24:18.006+01:00  INFO 30624 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T12:24:18.011+01:00  INFO 30624 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T12:24:18.012+01:00  INFO 30624 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T12:24:18.012+01:00  INFO 30624 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T12:24:18.016+01:00  INFO 30624 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T12:24:18.017+01:00  INFO 30624 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T12:24:18.018+01:00  INFO 30624 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T12:24:18.047+01:00  INFO 30624 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T12:24:18.099+01:00  INFO 30624 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T12:24:18.099+01:00  INFO 30624 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T12:24:18.099+01:00  INFO 30624 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679052258099
2023-03-17T12:24:18.101+01:00  INFO 30624 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T12:24:18.108+01:00  INFO 30624 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T12:24:18.115+01:00  INFO 30624 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T12:24:18.115+01:00  INFO 30624 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T12:24:18.115+01:00  INFO 30624 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679052258115
2023-03-17T12:24:18.116+01:00  INFO 30624 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T12:24:18.127+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T12:24:18.127+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T12:24:18.128+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T12:24:18.130+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T12:24:18.130+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T12:24:18.131+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T12:24:18.131+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T12:24:18.134+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:24:18.134+01:00  INFO 30624 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.51 seconds (process running for 2.87)
2023-03-17T12:24:18.134+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:24:18.157+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-27c4f741-a230-4b06-9e9e-69fdaa49b3c4
2023-03-17T12:24:18.157+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-818934d9-bfed-4b08-b0f0-794bd21ea8a5
2023-03-17T12:24:18.158+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T12:24:18.158+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T12:24:18.159+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:24:18.159+01:00  INFO 30624 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:26:02.187+01:00  INFO 29996 --- [main] c.s.task.SpringKafkaTaskApplication      : Starting SpringKafkaTaskApplication using Java 17.0.4.1 with PID 29996 (C:\Users\stjakic\tasks-workspace\KafkaSpringBoot\target\classes started by stjakic in C:\Users\stjakic\tasks-workspace\KafkaSpringBoot)
2023-03-17T12:26:02.189+01:00  INFO 29996 --- [main] c.s.task.SpringKafkaTaskApplication      : No active profile set, falling back to 1 default profile: "default"
2023-03-17T12:26:02.680+01:00  INFO 29996 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2023-03-17T12:26:02.701+01:00  INFO 29996 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2023-03-17T12:26:03.743+01:00  INFO 29996 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-17T12:26:03.891+01:00  INFO 29996 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T12:26:03.892+01:00  INFO 29996 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T12:26:03.892+01:00  INFO 29996 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679052363890
2023-03-17T12:26:04.149+01:00  INFO 29996 --- [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2023-03-17T12:26:04.152+01:00  INFO 29996 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-03-17T12:26:04.153+01:00  INFO 29996 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-17T12:26:04.153+01:00  INFO 29996 --- [kafka-admin-client-thread | adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-03-17T12:26:04.157+01:00  INFO 29996 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2023-03-17T12:26:04.158+01:00  INFO 29996 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application.errorChannel' has 1 subscriber(s).
2023-03-17T12:26:04.159+01:00  INFO 29996 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2023-03-17T12:26:04.182+01:00  INFO 29996 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T12:26:04.216+01:00  INFO 29996 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T12:26:04.217+01:00  INFO 29996 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T12:26:04.217+01:00  INFO 29996 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679052364216
2023-03-17T12:26:04.218+01:00  INFO 29996 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Subscribed to topic(s): topicTask1
2023-03-17T12:26:04.226+01:00  INFO 29996 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-springkafkatask33;-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = springkafkatask33;
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-03-17T12:26:04.232+01:00  INFO 29996 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T12:26:04.233+01:00  INFO 29996 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T12:26:04.233+01:00  INFO 29996 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679052364232
2023-03-17T12:26:04.234+01:00  INFO 29996 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Subscribed to topic(s): topicTask2
2023-03-17T12:26:04.242+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T12:26:04.242+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T12:26:04.242+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T12:26:04.243+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T12:26:04.243+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T12:26:04.244+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T12:26:04.245+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2023-03-17T12:26:04.246+01:00  INFO 29996 --- [main] c.s.task.SpringKafkaTaskApplication      : Started SpringKafkaTaskApplication in 2.482 seconds (process running for 2.887)
2023-03-17T12:26:04.247+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:26:04.247+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:26:04.268+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-1-d55b2cd4-3e77-4f52-8405-95fa4b4d3745
2023-03-17T12:26:04.268+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: need to re-join with the given member-id: consumer-springkafkatask33;-2-42a00d09-af82-467e-9e73-32c426ac65b7
2023-03-17T12:26:04.269+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T12:26:04.269+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:26:04.269+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-03-17T12:26:04.269+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] (Re-)joining group
2023-03-17T12:26:04.271+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=29, memberId='consumer-springkafkatask33;-1-d55b2cd4-3e77-4f52-8405-95fa4b4d3745', protocol='range'}
2023-03-17T12:26:04.271+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully joined group with generation Generation{generationId=29, memberId='consumer-springkafkatask33;-2-42a00d09-af82-467e-9e73-32c426ac65b7', protocol='range'}
2023-03-17T12:26:04.276+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-0 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T12:26:04.276+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Resetting the last seen epoch of partition topicTask1-1 to 0 since the associated topicId changed from null to fd4vOPB3T9CiP1d2Epi0Lw
2023-03-17T12:26:04.279+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Finished assignment for group at generation 29: {consumer-springkafkatask33;-1-d55b2cd4-3e77-4f52-8405-95fa4b4d3745=Assignment(partitions=[topicTask1-0, topicTask1-1]), consumer-springkafkatask33;-2-42a00d09-af82-467e-9e73-32c426ac65b7=Assignment(partitions=[topicTask2-0])}
2023-03-17T12:26:04.284+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=29, memberId='consumer-springkafkatask33;-2-42a00d09-af82-467e-9e73-32c426ac65b7', protocol='range'}
2023-03-17T12:26:04.284+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Successfully synced group in generation Generation{generationId=29, memberId='consumer-springkafkatask33;-1-d55b2cd4-3e77-4f52-8405-95fa4b4d3745', protocol='range'}
2023-03-17T12:26:04.285+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask1-0, topicTask1-1])
2023-03-17T12:26:04.285+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Notifying assignor about the new Assignment(partitions=[topicTask2-0])
2023-03-17T12:26:04.287+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask2-0
2023-03-17T12:26:04.287+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Adding newly assigned partitions: topicTask1-0, topicTask1-1
2023-03-17T12:26:04.302+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-2, groupId=springkafkatask33;] Setting offset for partition topicTask2-0 to the committed offset FetchPosition{offset=66, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T12:26:04.302+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T12:26:04.303+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-springkafkatask33;-1, groupId=springkafkatask33;] Setting offset for partition topicTask1-1 to the committed offset FetchPosition{offset=75, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2023-03-17T12:26:04.305+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask1-0, topicTask1-1]
2023-03-17T12:26:04.305+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : springkafkatask33;: partitions assigned: [topicTask2-0]
2023-03-17T12:26:11.472+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 75, CreateTime = 1679052370447, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = e)
2023-03-17T12:26:11.480+01:00 ERROR 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : Message need be in JSON format! 
2023-03-17T12:26:11.481+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T12:26:11.481+01:00 ERROR 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : Invalid message inputs!
2023-03-17T12:26:26.854+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 76, CreateTime = 1679052385843, serialized key size = -1, serialized value size = 60, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "END", "timestamp" : "700", "callId" : "200"})
2023-03-17T12:26:26.886+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T12:26:26.886+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=END, timestamp=700, callId=200  ]
2023-03-17T12:26:26.886+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : scheduleMessageDelete is called
2023-03-17T12:26:26.887+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Received message: EventMessage: [ callStatus=END, timestamp=700, callId=200  ]
2023-03-17T12:26:30.592+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.SpringKafkaTaskApplication      : ConsumerRecord(topic = topicTask1, partition = 1, leaderEpoch = 0, offset = 77, CreateTime = 1679052389575, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"callStatus": "START", "timestamp" : "301", "callId" : "200"})
2023-03-17T12:26:30.594+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.springkafka.task.EventKafkaFilter    : FILTER !
2023-03-17T12:26:30.594+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Message from handleMessage : EventMessage: [ callStatus=START, timestamp=301, callId=200  ]
2023-03-17T12:26:30.594+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Sending response to topic2
2023-03-17T12:26:30.595+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.springkafka.task.EventMessageHandler   : Topic2 Received ResponseMesg.json: ResponseMsg [callId=200, callStartTimestamp=301, callEndTimestamp=700, callDuration=399]
2023-03-17T12:26:30.595+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.cache.EventMessageCache         : Clean cache for callId 200
2023-03-17T12:26:30.595+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : Response message from handleMessage for database! : ResponseMsg [callId=200, callStartTimestamp=301, callEndTimestamp=700, callDuration=399]
2023-03-17T12:26:30.595+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.s.task.DatabaseMessageHandler          : TRYING INSERT INTO kafka_messages MESSAGE --> 
2023-03-17T12:26:30.599+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2023-03-17T12:26:30.784+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection org.postgresql.jdbc.PgConnection@39faa4a4
2023-03-17T12:26:30.788+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2023-03-17T12:26:30.811+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-03-17T12:26:30.820+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-03-17T12:26:30.834+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.1
2023-03-17T12:26:30.834+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e23c59d00e687ff5
2023-03-17T12:26:30.834+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1679052390834
2023-03-17T12:26:30.842+01:00  INFO 29996 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition topicTask2-0 to 0 since the associated topicId changed from null to fP5FeDXtREarfdKfWe2h3Q
2023-03-17T12:26:30.843+01:00  INFO 29996 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: DCKNfptMQ82ihbYja0cMrg
2023-03-17T12:26:30.843+01:00  INFO 29996 --- [kafka-producer-network-thread | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 17 with epoch 0
2023-03-17T12:26:30.864+01:00  INFO 29996 --- [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.s.task.SpringKafkaTaskApplication      : Messages from topic 2 
